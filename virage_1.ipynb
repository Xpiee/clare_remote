{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dated Changed: 2021-10-21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, '../../IDEaSv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import neurokit2 as nk\n",
    "from scipy.stats import skew, kurtosis, iqr\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from feat_functions.main_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation of ECG and EDA signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "level_1\n",
      "level_2\n",
      "level_3\n",
      "level_4\n",
      "level_5\n",
      "level_6\n",
      "level_7\n",
      "error!\n",
      "error!\n",
      "1868\n",
      "level_1\n",
      "level_2\n",
      "level_3\n",
      "level_4\n",
      "level_5\n",
      "level_6\n",
      "level_7\n",
      "error!\n",
      "error!\n",
      "1892\n",
      "level_1\n",
      "level_2\n",
      "level_3\n",
      "level_4\n",
      "level_5\n",
      "level_6\n",
      "level_7\n",
      "level_8\n",
      "level_9\n",
      "1953\n",
      "level_1\n",
      "level_2\n",
      "level_3\n",
      "level_4\n",
      "level_5\n",
      "level_6\n",
      "level_7\n",
      "level_8\n",
      "level_9\n"
     ]
    }
   ],
   "source": [
    "# fixing flaw of missing values in ECG that will be dropped in above case but ideally should not be dropped.\n",
    "from distutils.log import error\n",
    "\n",
    "\n",
    "main_path = r\"X:\\IDEaS\\Driving Simulator\\Signals_cp\"\n",
    "\n",
    "ecg_sample_rt = 512\n",
    "subjects_id = ['1744', '1868', '1892', '1953'] # os.listdir(main_path)\n",
    "\n",
    "exp_id = ['level_' + str(x) for x in range(1, 10)]\n",
    "\n",
    "rd_cols = ['Timestamp', 'ECG LL-RA CAL']\n",
    "for sub_id in range(len(subjects_id)):\n",
    "    \n",
    "    subject_path = os.path.join(main_path, subjects_id[sub_id]) # subjects_id[sub_id]\n",
    "\n",
    "    print(subjects_id[sub_id])\n",
    "    # print('1323')\n",
    "\n",
    "    for xid in exp_id:\n",
    "        try:\n",
    "            read_path = os.path.join(subject_path, '{}.csv'.format(xid))\n",
    "            df = pd.read_csv(read_path, dtype='object', encoding = \"ISO-8859-1\")\n",
    "            print(xid)\n",
    "            if df.columns[0] == '#INFO':\n",
    "                df = pd.read_csv(read_path, skiprows = 32, skipinitialspace=True, usecols=rd_cols, encoding = \"ISO-8859-1\")\n",
    "            else: \n",
    "                df = pd.read_csv(read_path, usecols=rd_cols, encoding = \"ISO-8859-1\")\n",
    "\n",
    "            \n",
    "            df.dropna(inplace=True) # removing all the nan rows\n",
    "\n",
    "            if len(df) == 0:\n",
    "                print('Subject {} does not have signal data for session: {}'.format(sub_id, xid))\n",
    "                continue\n",
    "            # df.drop(columns = ['Row', 'SampleNumber'], inplace = True) # dropping unnecessary columns from the dataframe\n",
    "            df.reset_index(drop=True, inplace=True) # resetting the index after dropping nan rows\n",
    "            df['Timestamp'] = df['Timestamp'].astype('float') # converting the timestamps to float to make the data consistent\n",
    "\n",
    "            # creating a list of all timestamps that should have been there if there was no missing datapoints.\n",
    "            time_list = ([df.loc[0, 'Timestamp'] + (x * (1000/ecg_sample_rt)) for x in range(0, int((df.loc[df.index[-1], 'Timestamp'] - df.loc[0, 'Timestamp'])/(1000/ecg_sample_rt)) + 1)])\n",
    "            \n",
    "            # creating a dataframe from the time_list that has all the timestamps (missing + not missing)\n",
    "            df_ecg = pd.DataFrame(time_list, columns = ['timestamp'])\n",
    "\n",
    "            # rounding the timestamps to 1 place decimal as then it would be more easier to compare timestamps!\n",
    "            df_ecg['timestamp'] = df_ecg['timestamp'].round(decimals = 1)\n",
    "            df_ecg.index = df_ecg['timestamp'] # shifting the timestamps to index\n",
    "\n",
    "            df['Timestamp'] = df['Timestamp'].round(decimals = 1)\n",
    "            df.index = df['Timestamp']\n",
    "\n",
    "            df_new = pd.concat([df_ecg, df], axis = 1)\n",
    "            df_new.drop(columns = ['Timestamp'], inplace=True)\n",
    "            df_new.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "            num_drops = df_new['ECG LL-RA CAL'].isna().sum()\n",
    "\n",
    "            if num_drops > len(df_new) * 0.05:\n",
    "                print(xid)\n",
    "                continue\n",
    "\n",
    "            df_ecg_new = impute_ecg(df_new.copy())\n",
    "            # cleaning the ECG signals\n",
    "            df_ecg_new_1 = ecg_cleaner(df_ecg_new.copy(), sample_rate=512.)\n",
    "            ecg = downsample_me(df_ecg_new_1['ECG LL-RA CAL'], 512, 256)\n",
    "\n",
    "            dfEcgDown = pd.DataFrame(ecg, columns=['ECG LL-RA'])\n",
    "\n",
    "            csv_path = r'X:\\Thesis\\driving_simulator\\ECG_EDA\\{}'.format(subjects_id[sub_id])\n",
    "          \n",
    "            mk_dirs(csv_path)\n",
    "            dfEcgDown.to_csv(os.path.join(csv_path, 'ecg_{}.csv'.format(xid)), index=False)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # exp_3 for subject 1674 was not recorded :(\n",
    "            print('error!')\n",
    "            continue\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n",
      "1105\n",
      "1106\n",
      "1241\n",
      "1271\n",
      "1314\n",
      "1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\acii\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 6 does not have signal data for session: level_6\n",
      "1337\n",
      "1372\n",
      "1417\n",
      "1434\n",
      "1544\n",
      "1547\n",
      "1595\n",
      "1629\n",
      "1716\n",
      "1717\n",
      "1744\n",
      "1868\n",
      "1892\n",
      "1953\n"
     ]
    }
   ],
   "source": [
    "# fixing flaw of missing values in ECG that will be dropped in above case but ideally should not be dropped.\n",
    "\n",
    "main_path = r\"X:\\IDEaS\\Driving Simulator\\Signals_cp\"\n",
    "subjects_id = os.listdir(main_path)\n",
    "eda_sample_rt = 128\n",
    "\n",
    "exp_id = ['level_' + str(x) for x in range(1, 10)]\n",
    "rd_cols = ['Timestamp', 'GSR Conductance CAL']\n",
    "for sub_id in range(len(subjects_id)):\n",
    "    \n",
    "    subject_path = os.path.join(main_path, subjects_id[sub_id])\n",
    "    print(subjects_id[sub_id])\n",
    "\n",
    "    for xid in exp_id:\n",
    "        try:\n",
    "            read_path = os.path.join(subject_path, '{}.csv'.format(xid))\n",
    "            df = pd.read_csv(read_path, dtype='object', encoding = \"ISO-8859-1\")\n",
    "            if df.columns[0] == '#INFO':\n",
    "                df = pd.read_csv(read_path, skiprows = 32, skipinitialspace=True, usecols=rd_cols, encoding = \"ISO-8859-1\")\n",
    "            else: \n",
    "                df = pd.read_csv(read_path, usecols=rd_cols, encoding = \"ISO-8859-1\")\n",
    "            \n",
    "            df.dropna(inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            df['Timestamp'] = df['Timestamp'].astype('float')\n",
    "\n",
    "            if len(df) == 0:\n",
    "                print('Subject {} does not have signal data for session: {}'.format(sub_id, xid))\n",
    "                continue\n",
    "\n",
    "            time_list = ([df.loc[0, 'Timestamp'] + (x * (1000/eda_sample_rt)) for x in range(0, int((df.loc[df.index[-1], 'Timestamp'] - df.loc[0, 'Timestamp'])/(1000/eda_sample_rt)) + 1)])\n",
    "            \n",
    "            df_eda = pd.DataFrame(time_list, columns = ['timestamp'])\n",
    "            df_eda['timestamp'] = df_eda['timestamp'].round(decimals = 1)\n",
    "            df_eda.index = df_eda['timestamp']\n",
    "\n",
    "            df['Timestamp'] = df['Timestamp'].round(decimals = 1)\n",
    "            df.index = df['Timestamp']\n",
    "\n",
    "            df_new = pd.concat([df_eda, df], axis = 1)\n",
    "            df_new.drop(columns = ['Timestamp'], inplace=True)\n",
    "            df_new.reset_index(inplace=True, drop=True)\n",
    "\n",
    "            num_drops = df_new['GSR Conductance CAL'].isna().sum()\n",
    "\n",
    "            if num_drops > len(df_new) * 0.05:\n",
    "                print(xid)\n",
    "                continue\n",
    "\n",
    "            df_eda_new = impute_eda(df_new.copy())\n",
    "            # cleaning the EDA signals\n",
    "            \n",
    "            df_eda_new_1 = eda_cleaner(df_eda_new.copy(),sample_rate=eda_sample_rt)\n",
    "            eda = downsample_me(df_eda_new_1['GSR Conductance CAL'], 128, 256)\n",
    "            df_eda_new_2 = eda_decom(pd.DataFrame(eda, columns=['GSR Conductance CAL']), sample_rate=256.)\n",
    "            \n",
    "            csv_path = r'X:\\Thesis\\driving_simulator\\ECG_EDA\\{}'.format(subjects_id[sub_id])\n",
    "            \n",
    "            mk_dirs(csv_path)\n",
    "            df_eda_new_2.to_csv(os.path.join(csv_path, 'eda_{}.csv'.format(xid)), index=False)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowSegments(signal:pd.DataFrame, fs:float, window_size_sec:int, signal_col:str='ecg_'):\n",
    "    \"\"\"\n",
    "    perform cropped signals of window_size seconds for the whole signal\n",
    "    overlap input is in percentage of window_size\n",
    "    window_size is in seconds \"\"\"\n",
    "    \n",
    "    window_size = fs * window_size_sec\n",
    "    start = 0\n",
    "    counter = 10\n",
    "    signal.reset_index(inplace=True, drop=False)\n",
    "    while(start+window_size <= len(signal)):\n",
    "        signal.loc[start:start+window_size, 'index'] = counter\n",
    "        start = start + window_size\n",
    "        counter += 10\n",
    "    \n",
    "    return signal[:start+1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelMean(signal:pd.DataFrame, window_size:int):\n",
    "    \"\"\"\n",
    "    perform cropped signals of window_size seconds for the whole signal\n",
    "    overlap input is in percentage of window_size\n",
    "    window_size is in seconds \"\"\"\n",
    "    \n",
    "    # start = 0\n",
    "    # counter = 10\n",
    "    signal.reset_index(inplace=True, drop=False)\n",
    "    for x in range(0, 54, 6):\n",
    "        signal.loc[x:x+6, 'index'] = np.round(signal.iloc[x:x+6]['label'].mean())\n",
    "    signal.rename(columns={'index':'meanLabel'}, inplace=True)    \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "1105\n",
      "1106\n",
      "1175\n",
      "1194\n",
      "1337\n",
      "1390\n",
      "1400\n",
      "1419\n",
      "1517\n",
      "File is not present. Skipping to next!\n",
      "1544\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "1624\n",
      "File is not present. Skipping to next!\n",
      "1629\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "1674\n",
      "File is not present. Skipping to next!\n",
      "1688\n",
      "1717\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "1765\n",
      "File is not present. Skipping to next!\n",
      "1818\n",
      "1892\n",
      "1929\n",
      "1933\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "1936\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "1953\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "1981\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n",
      "File is not present. Skipping to next!\n"
     ]
    }
   ],
   "source": [
    "# combining ECG and EDA into signle file and then combining the experiments into a single file\n",
    "# normalize based on subject instead of experiment.\n",
    "\n",
    "readPath = r'X:/Thesis/matb2/ECG_EDA'\n",
    "listDirs = os.listdir(readPath)\n",
    "exp_id = ['exp_0', 'exp_1', 'exp_2', 'exp_3']\n",
    "labelPath = r'X:\\IDEaS_2\\MatBII\\Data\\New_Labels_2'\n",
    "\n",
    "for subs in listDirs:\n",
    "# for subs in ['1105']:\n",
    "    subPath = os.path.join(readPath, subs)\n",
    "    subDirs = os.listdir(subPath)\n",
    "    print(subs)\n",
    "    # try:\n",
    "    dfLabel = pd.read_csv(os.path.join(labelPath, f'{subs}.csv'))\n",
    "    # break\n",
    "    dfCombine = pd.DataFrame()\n",
    "    for xid in exp_id:\n",
    "        labelColumns = ['time', f'{xid}', f'com_{xid}']\n",
    "        ecgPath = os.path.join(subPath, f'ecg_{xid}.csv')\n",
    "        edaPath = os.path.join(subPath, f'eda_{xid}.csv')\n",
    "        \n",
    "        try:\n",
    "            dfEcg = pd.read_csv(ecgPath)\n",
    "            dfEda = pd.read_csv(edaPath)\n",
    "\n",
    "            # Combining ecg and eda into a single dataframe\n",
    "            df = pd.concat([dfEcg, dfEda], axis=1)\n",
    "            df.dropna(inplace=True)\n",
    "            df = windowSegments(df, fs=256, window_size_sec=10)\n",
    "            df.rename(columns={'index':'time'}, inplace=True)\n",
    "            expLabelDF = dfLabel[labelColumns].copy()\n",
    "        \n",
    "            expLabelDF.columns = ['time', 'label', 'complexity']\n",
    "            expLabelDF = labelMean(expLabelDF, 10)\n",
    "            df = pd.merge(df.copy(), expLabelDF, on='time')\n",
    "            df['exp'] = xid\n",
    "            dfCombine = pd.concat([dfCombine, df], ignore_index=True)\n",
    "            # break\n",
    "            csv_path = r'X:\\Thesis\\matb2\\ECG_EDA_Combined\\{}'.format(subs)\n",
    "            mk_dirs(csv_path)\n",
    "            df.to_csv(os.path.join(csv_path, '{}.csv'.format(xid)), index=False)\n",
    "        except FileNotFoundError as e:\n",
    "            print('File is not present. Skipping to next!')\n",
    "            continue\n",
    "\n",
    "    if not dfCombine.empty:\n",
    "        dfCombine['ECG LL-RA'] = nk.standardize(dfCombine['ECG LL-RA'])\n",
    "        dfCombine['GSR Conductance CAL'] = nk.standardize(dfCombine['GSR Conductance CAL'])\n",
    "        dfCombine['EDA_Tonic'] = nk.standardize(dfCombine['EDA_Tonic'])\n",
    "        dfCombine['EDA_Phasic'] = nk.standardize(dfCombine['EDA_Phasic'])\n",
    "        dfCombine.to_csv(os.path.join(csv_path, '{}.csv'.format(subs)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_window_for_ECGEDA(signal:np.ndarray, fs:float, overlap:int, window_size_sec:int) -> np.ndarray:\n",
    "    \"\"\" perform cropped signals of window_size seconds for the whole signal\n",
    "    overlap input is in percentage of window_size\n",
    "    window_size is in seconds \"\"\"\n",
    "    \n",
    "    window_size = fs * window_size_sec\n",
    "    overlap     = int(window_size * (overlap / 100))\n",
    "    start       = 0\n",
    "    segmented   = np.zeros((1, window_size, signal.shape[1]), dtype = int)\n",
    "    while(start+window_size <= len(signal)):\n",
    "        segment     = signal[start:start+window_size]\n",
    "        segment     = segment.reshape(1, len(segment), signal.shape[1])\n",
    "        segmented   = np.append(segmented, segment, axis=0)\n",
    "        start       = start + window_size - overlap\n",
    "    return segmented[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows_1min(df:pd.DataFrame, fs:float, overlap:int, window_size_sec:int):\n",
    "    numSec = 60 #seconds\n",
    "    start = 0\n",
    "    windowSize = fs * numSec\n",
    "    winSizeArr = fs * window_size_sec\n",
    "\n",
    "    ecgSegments   = np.zeros((1, winSizeArr, 1), dtype = int)\n",
    "    edaSegments   = np.zeros((1, winSizeArr, 3), dtype = int)\n",
    "    labelSegments = []\n",
    "\n",
    "    while(start+windowSize <= len(df)):\n",
    "        dfOnemin = df[start:windowSize+start]\n",
    "        start = start + windowSize\n",
    "        ecgOne = dfOnemin['ECG LL-RA'].values\n",
    "        ecgOne = np.expand_dims(ecgOne, axis=1)\n",
    "        edaOne = dfOnemin[['GSR Conductance CAL', 'EDA_Tonic', 'EDA_Phasic']].values\n",
    "        labelOne = dfOnemin['meanLabel'].mean()\n",
    "        ecgArr = make_window_for_ECGEDA(ecgOne, fs, overlap, window_size_sec)\n",
    "        edaArr = make_window_for_ECGEDA(edaOne, fs, overlap, window_size_sec)\n",
    "\n",
    "        labels = [labelOne] * ecgArr.shape[0]\n",
    "        ecgSegments = np.append(ecgSegments, ecgArr, axis=0)\n",
    "        edaSegments = np.append(edaSegments, edaArr, axis=0)\n",
    "        labelSegments = labelSegments + labels\n",
    "    return ecgSegments[1:], edaSegments[1:], labelSegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainPath = r'X:\\Thesis\\matb2\\ECG_EDA_Combined'\n",
    "listDir = os.listdir(mainPath)\n",
    "samplingRate=256\n",
    "numSec = 60 #seconds\n",
    "overlapValue = 60\n",
    "windowSegLength = 10\n",
    "ecgSamples = {}\n",
    "edaSamples = {}\n",
    "labelSamples = {}\n",
    "for subs in listDir:\n",
    "    csvPath = os.path.join(mainPath, f'{subs}', f'{subs}.csv')\n",
    "    try:\n",
    "        dfMain = pd.read_csv(csvPath)\n",
    "        # consider each experiment separately\n",
    "        grp = dfMain.groupby(by='exp')\n",
    "        grpList = grp.groups.keys()\n",
    "        ecgSegs = []\n",
    "        edaSegs = []\n",
    "        labelSegs = []\n",
    "        for grp in grpList:\n",
    "            df = dfMain.groupby(by='exp').get_group(grp)\n",
    "            # selecting 1 min of session and creating overlapping samples from makewindow function\n",
    "            ## selecting 1 min of session\n",
    "            ecgSegments, edaSegments, labelSegments = make_windows_1min(df, samplingRate, overlapValue, windowSegLength)\n",
    "            ecgSegs.append(ecgSegments)\n",
    "            edaSegs.append(edaSegments)\n",
    "            labelSegs.append(labelSegments)\n",
    "        \n",
    "        ecgSamples[subs] = ecgSegs\n",
    "        edaSamples[subs] = edaSegs\n",
    "        labelSamples[subs] = labelSegs\n",
    "            \n",
    "    except FileExistsError as e:\n",
    "        print('File Not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pickle = r'X:\\Thesis\\matb2\\Processed_Data'\n",
    "\n",
    "mk_dirs(path_pickle)\n",
    "\n",
    "with open(os.path.join(path_pickle, 'cola_ecg.pickle'), 'wb') as handle:\n",
    "    pickle.dump(ecgSamples, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(os.path.join(path_pickle, 'cola_eda.pickle'), 'wb') as handle:\n",
    "    pickle.dump(edaSamples, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(os.path.join(path_pickle, 'cola_labels.pickle'), 'wb') as handle:\n",
    "    pickle.dump(labelSamples, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c41fe492cbb3e2d2993e3503946ae65db6019f21b1a1e8b01a5507fb3ac5759c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
