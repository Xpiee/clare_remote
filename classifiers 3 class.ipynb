{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import lightgbm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "# import main_utils_1\n",
    "import utils\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config2 import SELECTCOLS, ECG_SELECTCOLS, EDA_SELECTCOLS, SELECTFOUR\n",
    "\n",
    "import config2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(EDA_SELECTCOLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network  import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs_for_matbii = [\n",
    "    (RandomForestClassifier , {'n_estimators': 1000,\n",
    "                                'min_samples_split': 5,\n",
    "                                'min_samples_leaf': 1,\n",
    "                                'max_features': 'auto',\n",
    "                                'max_depth': 30,\n",
    "                                'bootstrap': False, 'random_state': 24, 'class_weight': 'balanced'}),\n",
    "    (LinearDiscriminantAnalysis, {'solver': 'lsqr'}), \n",
    "    (GradientBoostingClassifier, {'max_depth': 3, 'n_estimators': 300, 'max_features': 'auto'}), \n",
    "    (MLPClassifier, {'hidden_layer_sizes': (100, 10), 'learning_rate': 'adaptive', 'max_iter': 1000}),\n",
    "    (LogisticRegression, {'C': 1, 'max_iter': 400}),\n",
    "    (SVC , {'class_weight': 'balanced', 'C': 10}), \n",
    "    (xgb.XGBClassifier, {'n_estimators': 300, 'learning_rate': 0.01, \n",
    "                         'use_label_encoder': False, \n",
    "                         'booster': 'dart', 'n_jobs': 4,\n",
    "                         'reg_lambda': 0.0001, 'random_state': 24}),\n",
    "    (lightgbm.LGBMClassifier, {'num_leaves': 100,\n",
    "                                'n_estimators': 2000,\n",
    "                                'learning_rate': 0.001,\n",
    "                                'importance_type': 'gains',\n",
    "                                'boosting_type': 'gbdt',\n",
    "                                'class_weight': 'balanced',\n",
    "                                'random_state': 24})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loso(dr_feat_path):\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    xtrainDriv = pd.DataFrame()\n",
    "    for subTrain in subjects:\n",
    "        train = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(subTrain)))\n",
    "        train[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        if np.isinf(train).values.sum():\n",
    "            cinf = np.isinf(train).values.sum()\n",
    "            print(\"Train Dataframe contains {} values\".format(cinf))\n",
    "        train.replace([np.inf], 9999, inplace=True)        \n",
    "        train.replace([-np.inf], -9999, inplace=True)        \n",
    "\n",
    "        train['scrNumPeaks'] = train['scrNumPeaks'].values.astype(int)\n",
    "        train['scrNumPeaks'] = train['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "\n",
    "        train.dropna(inplace=True)\n",
    "        xtrainDriv = xtrainDriv.append(train)\n",
    "        xtrainDriv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return xtrainDriv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dataset, folder, basefolder):\n",
    "    dr_feat_path = r'X:\\All Modes\\{}\\ECG EDA\\Combined\\{}'.format(dataset, folder) # ECG_EDA_Features_Combined_scld\n",
    "    bs_feat_path = r'X:\\All Modes\\{}\\ECG EDA\\Combined\\{}'.format(dataset, basefolder) # ECG_EDA_Base2_Features_Combined\n",
    "\n",
    "    XtrainDriv = make_loso(dr_feat_path)\n",
    "    XtrainBase = make_loso(bs_feat_path)\n",
    "\n",
    "    XtrainDriv = XtrainDriv[SELECTCOLS].copy()\n",
    "    ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "\n",
    "    XtrainBase = XtrainBase[SELECTCOLS[:-3]].copy()\n",
    "    ytrainBase = XtrainBase.shape[0] * [0]\n",
    "\n",
    "    XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "    XtrainDriv = XtrainDriv.append(XtrainBase)\n",
    "\n",
    "    ytrain = ytrainDriv + ytrainBase\n",
    "\n",
    "    X = XtrainDriv.values\n",
    "    \n",
    "    X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "    for idx, val in enumerate(ytrain):\n",
    "        if val <= 4:\n",
    "            ytrain[idx] = 0\n",
    "        else: ytrain[idx] = 1\n",
    "\n",
    "    return X, ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_training_data(dr_feat_path, sdriv):\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    xtrainDriv = pd.DataFrame()\n",
    "\n",
    "    for subTrain in subjects:\n",
    "        if subTrain != sdriv:\n",
    "            train = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(subTrain)))\n",
    "\n",
    "            train[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "            if np.isinf(train).values.sum():\n",
    "                cinf = np.isinf(train).values.sum()\n",
    "                print(\"Train Dataframe contains {} values\".format(cinf))\n",
    "            train.replace([np.inf], 9999, inplace=True)        \n",
    "            train.replace([-np.inf], -9999, inplace=True)        \n",
    "\n",
    "            train['scrNumPeaks'] = train['scrNumPeaks'].values.astype(int)\n",
    "            train['scrNumPeaks'] = train['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "\n",
    "            train.dropna(inplace=True)\n",
    "            xtrainDriv = xtrainDriv.append(train)\n",
    "            xtrainDriv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return xtrainDriv.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losoValidation(dataset, folder, basefolder, paramsSELECTCOLS):\n",
    "    dr_feat_path = r'X:\\All Modes\\All\\{}\\Combine'.format(dataset) # ECG_EDA_Features_Combined_scld\n",
    "    bs_feat_path = r'X:\\All Modes\\{}\\ECG EDA\\Combined\\{}'.format(dataset, basefolder) # ECG_EDA_Base2_Features_Combined\n",
    "    date_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "    print(\"Saved Directory: {}\".format(date_time))\n",
    "    savePath_0 = f\"X:/All Modes/Data Files/{date_time}\"\n",
    "    utils.mk_dirs(savePath_0)\n",
    "    savePath1 = os.path.join(savePath_0, f'{dataset}')\n",
    "    utils.mk_dirs(savePath1)\n",
    "    savePath = os.path.join(savePath1, 'ECG EDA')\n",
    "    utils.mk_dirs(savePath)\n",
    "\n",
    "    mycls = {}\n",
    "\n",
    "    if dataset == 'MatbII':\n",
    "        parameter_list = funcs_for_matbii\n",
    "    # elif dataset == 'Virage':\n",
    "    #     parameter_list = funcs_for_virage\n",
    "\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    results_df = pd.DataFrame(columns=['dataset', 'method', 'test_subject', 'test_acc', 'test_f1'])\n",
    "    for sdriv in subjects:\n",
    "        utils.mk_dirs(os.path.join(savePath, sdriv))\n",
    "\n",
    "        xtestDriv = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(sdriv)))\n",
    "        xtestDriv[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        if np.isinf(xtestDriv).values.sum():\n",
    "            cinf = np.isinf(xtestDriv).values.sum()\n",
    "            print(\"Dataframe contains {} values\".format(cinf))\n",
    "\n",
    "        xtestDriv.replace([np.inf], 9999, inplace=True)\n",
    "        xtestDriv.replace([-np.inf], -9999, inplace=True)\n",
    "\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.astype(int)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "        xtestDriv.dropna(inplace=True) # .reset_index(drop=True, inplace=True)\n",
    "\n",
    "        ytestDriv = list(xtestDriv['scaled label'].copy()) \n",
    "\n",
    "        XtrainDriv = mk_training_data(dr_feat_path, sdriv)\n",
    "        # XtrainBase = mk_training_data(bs_feat_path, sdriv)\n",
    "\n",
    "        XtrainDriv = XtrainDriv[paramsSELECTCOLS].copy()\n",
    "        XtestDriv = xtestDriv[paramsSELECTCOLS].copy()  ### Look out for small x and X\n",
    "        # XtrainBase = XtrainBase[SELECTCOLS[:-3]].copy()\n",
    "\n",
    "        ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "        # ytrainBase = XtrainBase.shape[0] * [0]\n",
    "\n",
    "        XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "        XtestDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "\n",
    "        ytrain = ytrainDriv #+ ytrainBase\n",
    "        # XtrainDriv = XtrainDriv.append(XtrainBase)\n",
    "\n",
    "        X = XtrainDriv.values\n",
    "        X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "        for idx, val in enumerate(ytrain):\n",
    "            if val <= 4:\n",
    "                ytrain[idx] = 0\n",
    "            else: ytrain[idx] = 1\n",
    "\n",
    "        for idx, val in enumerate(ytestDriv):\n",
    "            if val <= 4:\n",
    "                ytestDriv[idx] = 0\n",
    "            else: ytestDriv[idx] = 1\n",
    "\n",
    "        # training different classifier for all subjects and saving them in different dictionnaries\n",
    "        mycls = {}\n",
    "        for cls_modl, cls_parameters in parameter_list:\n",
    "            print(\"--------------------------------------------\")\n",
    "            print(f\"---- Training classifier {cls_modl.__name__} for subject: {sdriv} ---\")\n",
    "\n",
    "            classifier_save_path = os.path.join(savePath, sdriv, cls_modl.__name__)\n",
    "            utils.mk_dirs(classifier_save_path)\n",
    "\n",
    "            classifier_report = os.path.join(classifier_save_path, 'report')\n",
    "            classifier_sav = os.path.join(classifier_save_path, 'classifier')\n",
    "            utils.mk_dirs(classifier_report)\n",
    "            utils.mk_dirs(classifier_sav)\n",
    "\n",
    "            if cls_modl.__name__ in ['LogisticRegression', 'SVC', 'LGBMClassifier', 'XGBClassifier']:\n",
    "                scaler = StandardScaler()\n",
    "                X = scaler.fit_transform(X)\n",
    "                XtestDriv = scaler.transform(XtestDriv)\n",
    "            clf = cls_modl(**cls_parameters)\n",
    "            hist = clf.fit(X, ytrain)\n",
    "\n",
    "            yPred = hist.predict(XtestDriv)\n",
    "\n",
    "            test_accuray = accuracy_score(ytestDriv, yPred)\n",
    "            test_f1 = f1_score(ytestDriv, yPred, average='macro')\n",
    "            \n",
    "            results_df = results_df.append({'dataset': folder,\n",
    "                                            'method':cls_modl.__name__,\n",
    "                                            'test_subject': sdriv,\n",
    "                                            'test_acc': test_accuray,\n",
    "                                            'test_f1':test_f1}, ignore_index=True)\n",
    "            print('Test Subject: {}'.format(sdriv))\n",
    "\n",
    "            mycls[sdriv] = classification_report(ytestDriv, yPred, zero_division=1, output_dict=True)\n",
    "            print(\"----- Classification Report ------\")\n",
    "            print(f\"Test accuracy for {sdriv} is: {test_accuray} and f1 score is: {test_f1}\\n\")\n",
    "\n",
    "            print(classification_report(ytestDriv, yPred, zero_division=1))\n",
    "            with open(os.path.join(classifier_report, 'Test_fold_{}_report.pickle'.format(sdriv)), 'wb') as handle:\n",
    "                pickle.dump(mycls, handle, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            with open(os.path.join(classifier_sav, 'Test_fold_{}_report.sav'.format(sdriv)), 'wb') as handle:\n",
    "                pickle.dump(hist, handle, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        # estimatorPath = os.path.join(savePath, '{}.sav'.format(saveName))\n",
    "        # pickle.dump(hist, open(estimatorPath, 'wb'))\n",
    "\n",
    "    results_df.to_csv(os.path.join(savePath, 'results.csv'), index=False)\n",
    "    return\n",
    "    # return XtrainDriv, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Directory: 2022_08_10_22_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1105.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5432692307692307 and f1 score is: 0.43515421776291335\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.12      0.19        95\n",
      "           1       0.55      0.90      0.68       113\n",
      "\n",
      "    accuracy                           0.54       208\n",
      "   macro avg       0.52      0.51      0.44       208\n",
      "weighted avg       0.53      0.54      0.46       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1105.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.40865384615384615 and f1 score is: 0.40699534107502955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.39      0.38        95\n",
      "           1       0.45      0.42      0.44       113\n",
      "\n",
      "    accuracy                           0.41       208\n",
      "   macro avg       0.41      0.41      0.41       208\n",
      "weighted avg       0.41      0.41      0.41       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1105.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.39903846153846156 and f1 score is: 0.39499709133216987\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.53      0.44        95\n",
      "           1       0.42      0.29      0.35       113\n",
      "\n",
      "    accuracy                           0.40       208\n",
      "   macro avg       0.40      0.41      0.39       208\n",
      "weighted avg       0.41      0.40      0.39       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1105.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5096153846153846 and f1 score is: 0.49447197865040027\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.37      0.41        95\n",
      "           1       0.54      0.63      0.58       113\n",
      "\n",
      "    accuracy                           0.51       208\n",
      "   macro avg       0.50      0.50      0.49       208\n",
      "weighted avg       0.50      0.51      0.50       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.4182692307692308 and f1 score is: 0.4182557843885075\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.45      0.42        95\n",
      "           1       0.46      0.39      0.42       113\n",
      "\n",
      "    accuracy                           0.42       208\n",
      "   macro avg       0.42      0.42      0.42       208\n",
      "weighted avg       0.42      0.42      0.42       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1105.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5048076923076923 and f1 score is: 0.5028657616892911\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.48      0.47        95\n",
      "           1       0.55      0.52      0.53       113\n",
      "\n",
      "    accuracy                           0.50       208\n",
      "   macro avg       0.50      0.50      0.50       208\n",
      "weighted avg       0.51      0.50      0.51       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1105.csv ---\n",
      "[22:16:52] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5048076923076923 and f1 score is: 0.45821004981918423\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.23      0.30        95\n",
      "           1       0.53      0.73      0.62       113\n",
      "\n",
      "    accuracy                           0.50       208\n",
      "   macro avg       0.48      0.48      0.46       208\n",
      "weighted avg       0.48      0.50      0.47       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1105.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.3701923076923077 and f1 score is: 0.36772247360482657\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.34      0.33        95\n",
      "           1       0.42      0.40      0.41       113\n",
      "\n",
      "    accuracy                           0.37       208\n",
      "   macro avg       0.37      0.37      0.37       208\n",
      "weighted avg       0.37      0.37      0.37       208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1106.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8027210884353742 and f1 score is: 0.47712498466822034\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.06      0.06        16\n",
      "           1       0.89      0.89      0.89       131\n",
      "\n",
      "    accuracy                           0.80       147\n",
      "   macro avg       0.48      0.48      0.48       147\n",
      "weighted avg       0.80      0.80      0.80       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1106.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.5102040816326531 and f1 score is: 0.37179487179487175\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.19      0.08        16\n",
      "           1       0.85      0.55      0.67       131\n",
      "\n",
      "    accuracy                           0.51       147\n",
      "   macro avg       0.45      0.37      0.37       147\n",
      "weighted avg       0.76      0.51      0.60       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1106.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.6326530612244898 and f1 score is: 0.43461538461538457\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.19      0.10        16\n",
      "           1       0.87      0.69      0.77       131\n",
      "\n",
      "    accuracy                           0.63       147\n",
      "   macro avg       0.47      0.44      0.43       147\n",
      "weighted avg       0.79      0.63      0.70       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1106.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.5850340136054422 and f1 score is: 0.4441827310481621\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.38      0.16        16\n",
      "           1       0.89      0.61      0.72       131\n",
      "\n",
      "    accuracy                           0.59       147\n",
      "   macro avg       0.50      0.49      0.44       147\n",
      "weighted avg       0.80      0.59      0.66       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.5850340136054422 and f1 score is: 0.41041488592280884\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.19      0.09        16\n",
      "           1       0.86      0.63      0.73       131\n",
      "\n",
      "    accuracy                           0.59       147\n",
      "   macro avg       0.46      0.41      0.41       147\n",
      "weighted avg       0.78      0.59      0.66       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1106.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.4217687074829932 and f1 score is: 0.36486555177146346\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.56      0.17        16\n",
      "           1       0.88      0.40      0.55       131\n",
      "\n",
      "    accuracy                           0.42       147\n",
      "   macro avg       0.49      0.48      0.36       147\n",
      "weighted avg       0.80      0.42      0.51       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1106.csv ---\n",
      "[22:18:41] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.782312925170068 and f1 score is: 0.46787330316742076\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.06      0.06        16\n",
      "           1       0.88      0.87      0.88       131\n",
      "\n",
      "    accuracy                           0.78       147\n",
      "   macro avg       0.47      0.47      0.47       147\n",
      "weighted avg       0.79      0.78      0.79       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1106.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7210884353741497 and f1 score is: 0.48083383581703854\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.19      0.13        16\n",
      "           1       0.89      0.79      0.83       131\n",
      "\n",
      "    accuracy                           0.72       147\n",
      "   macro avg       0.49      0.49      0.48       147\n",
      "weighted avg       0.80      0.72      0.76       147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1175.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.536723163841808 and f1 score is: 0.3702707393266227\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.05        84\n",
      "           1       0.53      1.00      0.69        93\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.77      0.51      0.37       177\n",
      "weighted avg       0.75      0.54      0.39       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4463276836158192 and f1 score is: 0.44489247311827956\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.52      0.47        84\n",
      "           1       0.47      0.38      0.42        93\n",
      "\n",
      "    accuracy                           0.45       177\n",
      "   macro avg       0.45      0.45      0.44       177\n",
      "weighted avg       0.45      0.45      0.44       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1175.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5480225988700564 and f1 score is: 0.519674355495251\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.32      0.40        84\n",
      "           1       0.55      0.75      0.64        93\n",
      "\n",
      "    accuracy                           0.55       177\n",
      "   macro avg       0.55      0.54      0.52       177\n",
      "weighted avg       0.55      0.55      0.53       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1175.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.519774011299435 and f1 score is: 0.5135633224481878\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57        84\n",
      "           1       0.56      0.39      0.46        93\n",
      "\n",
      "    accuracy                           0.52       177\n",
      "   macro avg       0.53      0.53      0.51       177\n",
      "weighted avg       0.53      0.52      0.51       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4124293785310734 and f1 score is: 0.39126984126984127\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.63      0.50        84\n",
      "           1       0.39      0.22      0.28        93\n",
      "\n",
      "    accuracy                           0.41       177\n",
      "   macro avg       0.41      0.42      0.39       177\n",
      "weighted avg       0.41      0.41      0.39       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1175.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4350282485875706 and f1 score is: 0.402995143011333\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.70      0.54        84\n",
      "           1       0.42      0.19      0.26        93\n",
      "\n",
      "    accuracy                           0.44       177\n",
      "   macro avg       0.43      0.45      0.40       177\n",
      "weighted avg       0.43      0.44      0.40       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1175.csv ---\n",
      "[22:20:28] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.536723163841808 and f1 score is: 0.5313226556445363\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48        84\n",
      "           1       0.55      0.61      0.58        93\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.53      0.53      0.53       177\n",
      "weighted avg       0.53      0.54      0.53       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1175.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4858757062146893 and f1 score is: 0.48528424887354993\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.55      0.50        84\n",
      "           1       0.51      0.43      0.47        93\n",
      "\n",
      "    accuracy                           0.49       177\n",
      "   macro avg       0.49      0.49      0.49       177\n",
      "weighted avg       0.49      0.49      0.48       177\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1337.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6018518518518519 and f1 score is: 0.6006191950464397\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58       113\n",
      "           1       0.57      0.69      0.62       103\n",
      "\n",
      "    accuracy                           0.60       216\n",
      "   macro avg       0.61      0.61      0.60       216\n",
      "weighted avg       0.61      0.60      0.60       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5601851851851852 and f1 score is: 0.5509355509355509\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.67      0.62       113\n",
      "           1       0.55      0.44      0.49       103\n",
      "\n",
      "    accuracy                           0.56       216\n",
      "   macro avg       0.56      0.55      0.55       216\n",
      "weighted avg       0.56      0.56      0.55       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1337.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5925925925925926 and f1 score is: 0.5875000000000001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.67      0.63       113\n",
      "           1       0.58      0.50      0.54       103\n",
      "\n",
      "    accuracy                           0.59       216\n",
      "   macro avg       0.59      0.59      0.59       216\n",
      "weighted avg       0.59      0.59      0.59       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1337.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6388888888888888 and f1 score is: 0.636896551724138\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.66       113\n",
      "           1       0.63      0.59      0.61       103\n",
      "\n",
      "    accuracy                           0.64       216\n",
      "   macro avg       0.64      0.64      0.64       216\n",
      "weighted avg       0.64      0.64      0.64       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5879629629629629 and f1 score is: 0.5792975161396214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.70      0.64       113\n",
      "           1       0.59      0.47      0.52       103\n",
      "\n",
      "    accuracy                           0.59       216\n",
      "   macro avg       0.59      0.58      0.58       216\n",
      "weighted avg       0.59      0.59      0.58       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1337.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.47685185185185186 and f1 score is: 0.47675091645765\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.47      0.48       113\n",
      "           1       0.45      0.49      0.47       103\n",
      "\n",
      "    accuracy                           0.48       216\n",
      "   macro avg       0.48      0.48      0.48       216\n",
      "weighted avg       0.48      0.48      0.48       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1337.csv ---\n",
      "[22:22:16] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5833333333333334 and f1 score is: 0.5804195804195804\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62       113\n",
      "           1       0.57      0.52      0.55       103\n",
      "\n",
      "    accuracy                           0.58       216\n",
      "   macro avg       0.58      0.58      0.58       216\n",
      "weighted avg       0.58      0.58      0.58       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1337.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5138888888888888 and f1 score is: 0.49571984435797667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.67      0.59       113\n",
      "           1       0.49      0.34      0.40       103\n",
      "\n",
      "    accuracy                           0.51       216\n",
      "   macro avg       0.51      0.51      0.50       216\n",
      "weighted avg       0.51      0.51      0.50       216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1390.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5305164319248826 and f1 score is: 0.46803196803196806\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.21      0.29        95\n",
      "           1       0.55      0.79      0.65       118\n",
      "\n",
      "    accuracy                           0.53       213\n",
      "   macro avg       0.50      0.50      0.47       213\n",
      "weighted avg       0.50      0.53      0.49       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1390.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5727699530516432 and f1 score is: 0.5066055746468118\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.23      0.33        95\n",
      "           1       0.58      0.85      0.69       118\n",
      "\n",
      "    accuracy                           0.57       213\n",
      "   macro avg       0.56      0.54      0.51       213\n",
      "weighted avg       0.57      0.57      0.53       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1390.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5305164319248826 and f1 score is: 0.5287610619469028\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.53      0.50        95\n",
      "           1       0.58      0.53      0.56       118\n",
      "\n",
      "    accuracy                           0.53       213\n",
      "   macro avg       0.53      0.53      0.53       213\n",
      "weighted avg       0.54      0.53      0.53       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1390.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.568075117370892 and f1 score is: 0.5347578347578348\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.34      0.41        95\n",
      "           1       0.59      0.75      0.66       118\n",
      "\n",
      "    accuracy                           0.57       213\n",
      "   macro avg       0.56      0.55      0.53       213\n",
      "weighted avg       0.56      0.57      0.55       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5539906103286385 and f1 score is: 0.4763876310001294\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.19      0.27        95\n",
      "           1       0.56      0.85      0.68       118\n",
      "\n",
      "    accuracy                           0.55       213\n",
      "   macro avg       0.53      0.52      0.48       213\n",
      "weighted avg       0.54      0.55      0.50       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1390.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5868544600938967 and f1 score is: 0.5864077669902913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.69      0.60        95\n",
      "           1       0.67      0.50      0.57       118\n",
      "\n",
      "    accuracy                           0.59       213\n",
      "   macro avg       0.60      0.60      0.59       213\n",
      "weighted avg       0.61      0.59      0.58       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1390.csv ---\n",
      "[22:24:03] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5305164319248826 and f1 score is: 0.46407004830917875\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.20      0.28        95\n",
      "           1       0.55      0.80      0.65       118\n",
      "\n",
      "    accuracy                           0.53       213\n",
      "   macro avg       0.50      0.50      0.46       213\n",
      "weighted avg       0.50      0.53      0.48       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1390.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5446009389671361 and f1 score is: 0.4962329017628557\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.26      0.34        95\n",
      "           1       0.57      0.77      0.65       118\n",
      "\n",
      "    accuracy                           0.54       213\n",
      "   macro avg       0.52      0.52      0.50       213\n",
      "weighted avg       0.53      0.54      0.51       213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1400.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6333333333333333 and f1 score is: 0.411122036490768\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.96      0.77       136\n",
      "           1       0.29      0.03      0.05        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.47      0.50      0.41       210\n",
      "weighted avg       0.52      0.63      0.52       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1400.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5571428571428572 and f1 score is: 0.40952380952380957\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.70       136\n",
      "           1       0.19      0.08      0.11        74\n",
      "\n",
      "    accuracy                           0.56       210\n",
      "   macro avg       0.41      0.45      0.41       210\n",
      "weighted avg       0.47      0.56      0.50       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1400.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6333333333333333 and f1 score is: 0.44185564875220046\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.94      0.77       136\n",
      "           1       0.38      0.07      0.11        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.52      0.50      0.44       210\n",
      "weighted avg       0.56      0.63      0.54       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1400.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5142857142857142 and f1 score is: 0.5012108792846498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.52      0.58       136\n",
      "           1       0.36      0.50      0.42        74\n",
      "\n",
      "    accuracy                           0.51       210\n",
      "   macro avg       0.51      0.51      0.50       210\n",
      "weighted avg       0.55      0.51      0.53       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1400.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5904761904761905 and f1 score is: 0.3919191919191919\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.90      0.74       136\n",
      "           1       0.12      0.03      0.04        74\n",
      "\n",
      "    accuracy                           0.59       210\n",
      "   macro avg       0.38      0.46      0.39       210\n",
      "weighted avg       0.45      0.59      0.49       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1400.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5952380952380952 and f1 score is: 0.5016611295681063\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.79      0.72       136\n",
      "           1       0.38      0.23      0.29        74\n",
      "\n",
      "    accuracy                           0.60       210\n",
      "   macro avg       0.52      0.51      0.50       210\n",
      "weighted avg       0.56      0.60      0.57       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1400.csv ---\n",
      "[22:25:52] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.638095238095238 and f1 score is: 0.43452380952380953\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.96      0.77       136\n",
      "           1       0.40      0.05      0.10        74\n",
      "\n",
      "    accuracy                           0.64       210\n",
      "   macro avg       0.53      0.50      0.43       210\n",
      "weighted avg       0.56      0.64      0.53       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1400.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6333333333333333 and f1 score is: 0.3877551020408163\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.78       136\n",
      "           1       0.00      0.00      0.00        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.32      0.49      0.39       210\n",
      "weighted avg       0.42      0.63      0.50       210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1419.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.4392523364485981 and f1 score is: 0.4392033542976939\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.48      0.43        95\n",
      "           1       0.49      0.40      0.44       119\n",
      "\n",
      "    accuracy                           0.44       214\n",
      "   macro avg       0.44      0.44      0.44       214\n",
      "weighted avg       0.45      0.44      0.44       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.411214953271028 and f1 score is: 0.3493243243243243\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.81      0.55        95\n",
      "           1       0.38      0.09      0.15       119\n",
      "\n",
      "    accuracy                           0.41       214\n",
      "   macro avg       0.40      0.45      0.35       214\n",
      "weighted avg       0.40      0.41      0.33       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1419.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.4719626168224299 and f1 score is: 0.47139703149933326\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.57      0.49        95\n",
      "           1       0.53      0.39      0.45       119\n",
      "\n",
      "    accuracy                           0.47       214\n",
      "   macro avg       0.48      0.48      0.47       214\n",
      "weighted avg       0.49      0.47      0.47       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1419.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.514018691588785 and f1 score is: 0.502903600464576\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.75      0.58        95\n",
      "           1       0.62      0.33      0.43       119\n",
      "\n",
      "    accuracy                           0.51       214\n",
      "   macro avg       0.54      0.54      0.50       214\n",
      "weighted avg       0.55      0.51      0.49       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.40186915887850466 and f1 score is: 0.34311750599520385\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.79      0.54        95\n",
      "           1       0.35      0.09      0.15       119\n",
      "\n",
      "    accuracy                           0.40       214\n",
      "   macro avg       0.38      0.44      0.34       214\n",
      "weighted avg       0.38      0.40      0.32       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1419.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5 and f1 score is: 0.4991140763425571\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.52      0.48        95\n",
      "           1       0.56      0.49      0.52       119\n",
      "\n",
      "    accuracy                           0.50       214\n",
      "   macro avg       0.50      0.50      0.50       214\n",
      "weighted avg       0.51      0.50      0.50       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1419.csv ---\n",
      "[22:27:38] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.4719626168224299 and f1 score is: 0.4693555111803559\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.45      0.43        95\n",
      "           1       0.53      0.49      0.51       119\n",
      "\n",
      "    accuracy                           0.47       214\n",
      "   macro avg       0.47      0.47      0.47       214\n",
      "weighted avg       0.48      0.47      0.47       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1419.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.46261682242990654 and f1 score is: 0.46251119313342215\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.51      0.45        95\n",
      "           1       0.52      0.43      0.47       119\n",
      "\n",
      "    accuracy                           0.46       214\n",
      "   macro avg       0.47      0.47      0.46       214\n",
      "weighted avg       0.47      0.46      0.46       214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1517.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.2716049382716049 and f1 score is: 0.24203013481363997\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.05      0.09       122\n",
      "           1       0.25      0.95      0.39        40\n",
      "\n",
      "    accuracy                           0.27       162\n",
      "   macro avg       0.50      0.50      0.24       162\n",
      "weighted avg       0.63      0.27      0.17       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1517.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.35185185185185186 and f1 score is: 0.34765100671140936\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.18      0.30       122\n",
      "           1       0.26      0.88      0.40        40\n",
      "\n",
      "    accuracy                           0.35       162\n",
      "   macro avg       0.54      0.53      0.35       162\n",
      "weighted avg       0.68      0.35      0.32       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1517.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.3395061728395062 and f1 score is: 0.33522531160115054\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.17      0.28       122\n",
      "           1       0.25      0.85      0.39        40\n",
      "\n",
      "    accuracy                           0.34       162\n",
      "   macro avg       0.51      0.51      0.34       162\n",
      "weighted avg       0.65      0.34      0.31       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1517.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.36419753086419754 and f1 score is: 0.3639794168096055\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.25      0.38       122\n",
      "           1       0.24      0.70      0.35        40\n",
      "\n",
      "    accuracy                           0.36       162\n",
      "   macro avg       0.48      0.48      0.36       162\n",
      "weighted avg       0.60      0.36      0.37       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.3765432098765432 and f1 score is: 0.3759487394637476\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.23      0.36       122\n",
      "           1       0.26      0.82      0.40        40\n",
      "\n",
      "    accuracy                           0.38       162\n",
      "   macro avg       0.53      0.53      0.38       162\n",
      "weighted avg       0.67      0.38      0.37       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1517.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.35185185185185186 and f1 score is: 0.34624697336561744\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.17      0.29       122\n",
      "           1       0.26      0.90      0.41        40\n",
      "\n",
      "    accuracy                           0.35       162\n",
      "   macro avg       0.55      0.54      0.35       162\n",
      "weighted avg       0.70      0.35      0.32       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1517.csv ---\n",
      "[22:29:26] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.3395061728395062 and f1 score is: 0.33379453476305776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.16      0.27       122\n",
      "           1       0.26      0.88      0.40        40\n",
      "\n",
      "    accuracy                           0.34       162\n",
      "   macro avg       0.53      0.52      0.33       162\n",
      "weighted avg       0.67      0.34      0.30       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1517.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.30246913580246915 and f1 score is: 0.29054761074293683\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.11      0.20       122\n",
      "           1       0.24      0.88      0.38        40\n",
      "\n",
      "    accuracy                           0.30       162\n",
      "   macro avg       0.49      0.49      0.29       162\n",
      "weighted avg       0.62      0.30      0.24       162\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1544.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6304347826086957 and f1 score is: 0.47551978537894035\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.20      0.19        10\n",
      "           1       0.77      0.75      0.76        36\n",
      "\n",
      "    accuracy                           0.63        46\n",
      "   macro avg       0.48      0.47      0.48        46\n",
      "weighted avg       0.64      0.63      0.64        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1544.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.13043478260869565 and f1 score is: 0.12380952380952381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.50      0.20        10\n",
      "           1       0.17      0.03      0.05        36\n",
      "\n",
      "    accuracy                           0.13        46\n",
      "   macro avg       0.15      0.26      0.12        46\n",
      "weighted avg       0.16      0.13      0.08        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1544.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.717391304347826 and f1 score is: 0.5688536409516943\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.30      0.32        10\n",
      "           1       0.81      0.83      0.82        36\n",
      "\n",
      "    accuracy                           0.72        46\n",
      "   macro avg       0.57      0.57      0.57        46\n",
      "weighted avg       0.71      0.72      0.71        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1544.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6521739130434783 and f1 score is: 0.6043010752688172\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.70      0.47        10\n",
      "           1       0.88      0.64      0.74        36\n",
      "\n",
      "    accuracy                           0.65        46\n",
      "   macro avg       0.62      0.67      0.60        46\n",
      "weighted avg       0.77      0.65      0.68        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.21739130434782608 and f1 score is: 0.17857142857142855\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36        10\n",
      "           1       1.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.22        46\n",
      "   macro avg       0.61      0.50      0.18        46\n",
      "weighted avg       0.83      0.22      0.08        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1544.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6521739130434783 and f1 score is: 0.44744744744744747\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.10      0.11        10\n",
      "           1       0.76      0.81      0.78        36\n",
      "\n",
      "    accuracy                           0.65        46\n",
      "   macro avg       0.44      0.45      0.45        46\n",
      "weighted avg       0.62      0.65      0.64        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1544.csv ---\n",
      "[22:31:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.45652173913043476 and f1 score is: 0.3918561607615018\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.30      0.19        10\n",
      "           1       0.72      0.50      0.59        36\n",
      "\n",
      "    accuracy                           0.46        46\n",
      "   macro avg       0.43      0.40      0.39        46\n",
      "weighted avg       0.59      0.46      0.50        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1544.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.41304347826086957 and f1 score is: 0.362095531587057\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.30      0.18        10\n",
      "           1       0.70      0.44      0.54        36\n",
      "\n",
      "    accuracy                           0.41        46\n",
      "   macro avg       0.41      0.37      0.36        46\n",
      "weighted avg       0.57      0.41      0.46        46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1624.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.559748427672956 and f1 score is: 0.49991013659237954\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.23      0.33        73\n",
      "           1       0.56      0.84      0.67        86\n",
      "\n",
      "    accuracy                           0.56       159\n",
      "   macro avg       0.56      0.54      0.50       159\n",
      "weighted avg       0.56      0.56      0.51       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1624.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.6415094339622641 and f1 score is: 0.6263758914952384\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.48      0.55        73\n",
      "           1       0.64      0.78      0.70        86\n",
      "\n",
      "    accuracy                           0.64       159\n",
      "   macro avg       0.64      0.63      0.63       159\n",
      "weighted avg       0.64      0.64      0.63       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1624.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.4528301886792453 and f1 score is: 0.4232645403377111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.25      0.29        73\n",
      "           1       0.50      0.63      0.55        86\n",
      "\n",
      "    accuracy                           0.45       159\n",
      "   macro avg       0.43      0.44      0.42       159\n",
      "weighted avg       0.43      0.45      0.43       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1624.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5031446540880503 and f1 score is: 0.4821700952302428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.33      0.38        73\n",
      "           1       0.53      0.65      0.59        86\n",
      "\n",
      "    accuracy                           0.50       159\n",
      "   macro avg       0.49      0.49      0.48       159\n",
      "weighted avg       0.49      0.50      0.49       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.6163522012578616 and f1 score is: 0.584536303276933\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.37      0.47        73\n",
      "           1       0.61      0.83      0.70        86\n",
      "\n",
      "    accuracy                           0.62       159\n",
      "   macro avg       0.62      0.60      0.58       159\n",
      "weighted avg       0.62      0.62      0.59       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1624.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5786163522012578 and f1 score is: 0.5731458107945666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.51      0.52        73\n",
      "           1       0.60      0.64      0.62        86\n",
      "\n",
      "    accuracy                           0.58       159\n",
      "   macro avg       0.57      0.57      0.57       159\n",
      "weighted avg       0.58      0.58      0.58       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1624.csv ---\n",
      "[22:33:09] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5660377358490566 and f1 score is: 0.557567447675122\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50        73\n",
      "           1       0.59      0.65      0.62        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.56      0.56      0.56       159\n",
      "weighted avg       0.56      0.57      0.56       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1624.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5094339622641509 and f1 score is: 0.4969987021414666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.38      0.42        73\n",
      "           1       0.54      0.62      0.58        86\n",
      "\n",
      "    accuracy                           0.51       159\n",
      "   macro avg       0.50      0.50      0.50       159\n",
      "weighted avg       0.50      0.51      0.50       159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1688.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6629834254143646 and f1 score is: 0.39867109634551495\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.66       181\n",
      "   macro avg       0.33      0.50      0.40       181\n",
      "weighted avg       0.45      0.66      0.53       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1688.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6685082872928176 and f1 score is: 0.41612903225806447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.02      0.03        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.59      0.50      0.42       181\n",
      "weighted avg       0.61      0.67      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1688.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6519337016574586 and f1 score is: 0.43596972844635706\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.05      0.09        60\n",
      "           1       0.67      0.95      0.78       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.50      0.50      0.44       181\n",
      "weighted avg       0.56      0.65      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1688.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6629834254143646 and f1 score is: 0.476655448641987\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.10      0.16        60\n",
      "           1       0.68      0.94      0.79       121\n",
      "\n",
      "    accuracy                           0.66       181\n",
      "   macro avg       0.57      0.52      0.48       181\n",
      "weighted avg       0.61      0.66      0.58       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6629834254143646 and f1 score is: 0.39867109634551495\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.66       181\n",
      "   macro avg       0.33      0.50      0.40       181\n",
      "weighted avg       0.45      0.66      0.53       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1688.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6464088397790055 and f1 score is: 0.43326810176125247\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.05      0.09        60\n",
      "           1       0.67      0.94      0.78       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.48      0.50      0.43       181\n",
      "weighted avg       0.55      0.65      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1688.csv ---\n",
      "[22:34:58] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6850828729281768 and f1 score is: 0.5876004317064396\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.30      0.39        60\n",
      "           1       0.72      0.88      0.79       121\n",
      "\n",
      "    accuracy                           0.69       181\n",
      "   macro avg       0.63      0.59      0.59       181\n",
      "weighted avg       0.66      0.69      0.66       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1688.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6353591160220995 and f1 score is: 0.5733571428571429\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.38      0.41        60\n",
      "           1       0.71      0.76      0.74       121\n",
      "\n",
      "    accuracy                           0.64       181\n",
      "   macro avg       0.58      0.57      0.57       181\n",
      "weighted avg       0.62      0.64      0.63       181\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1717.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6944444444444444 and f1 score is: 0.5032752613240418\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.12      0.20        34\n",
      "           1       0.70      0.96      0.81        74\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.64      0.54      0.50       108\n",
      "weighted avg       0.66      0.69      0.62       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.37037037037037035 and f1 score is: 0.37037037037037035\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.59      0.37        34\n",
      "           1       0.59      0.27      0.37        74\n",
      "\n",
      "    accuracy                           0.37       108\n",
      "   macro avg       0.43      0.43      0.37       108\n",
      "weighted avg       0.49      0.37      0.37       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1717.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5277777777777778 and f1 score is: 0.4853779314210969\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.38      0.34        34\n",
      "           1       0.68      0.59      0.63        74\n",
      "\n",
      "    accuracy                           0.53       108\n",
      "   macro avg       0.49      0.49      0.49       108\n",
      "weighted avg       0.56      0.53      0.54       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1717.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5833333333333334 and f1 score is: 0.5048395313295976\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.29      0.31        34\n",
      "           1       0.69      0.72      0.70        74\n",
      "\n",
      "    accuracy                           0.58       108\n",
      "   macro avg       0.51      0.51      0.50       108\n",
      "weighted avg       0.57      0.58      0.58       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.39814814814814814 and f1 score is: 0.39768339768339767\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.68      0.41        34\n",
      "           1       0.65      0.27      0.38        74\n",
      "\n",
      "    accuracy                           0.40       108\n",
      "   macro avg       0.47      0.47      0.40       108\n",
      "weighted avg       0.54      0.40      0.39       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1717.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5462962962962963 and f1 score is: 0.5373721479150275\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.65      0.47        34\n",
      "           1       0.76      0.50      0.60        74\n",
      "\n",
      "    accuracy                           0.55       108\n",
      "   macro avg       0.56      0.57      0.54       108\n",
      "weighted avg       0.63      0.55      0.56       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1717.csv ---\n",
      "[22:36:45] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6296296296296297 and f1 score is: 0.5178571428571428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.24      0.29        34\n",
      "           1       0.70      0.81      0.75        74\n",
      "\n",
      "    accuracy                           0.63       108\n",
      "   macro avg       0.53      0.52      0.52       108\n",
      "weighted avg       0.59      0.63      0.60       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1717.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5740740740740741 and f1 score is: 0.49818181818181817\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.29      0.30        34\n",
      "           1       0.68      0.70      0.69        74\n",
      "\n",
      "    accuracy                           0.57       108\n",
      "   macro avg       0.50      0.50      0.50       108\n",
      "weighted avg       0.57      0.57      0.57       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1765.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5432098765432098 and f1 score is: 0.5166129032258064\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.29      0.40        86\n",
      "           1       0.51      0.83      0.63        76\n",
      "\n",
      "    accuracy                           0.54       162\n",
      "   macro avg       0.58      0.56      0.52       162\n",
      "weighted avg       0.59      0.54      0.51       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1765.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5 and f1 score is: 0.47835420393559924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.28      0.37        86\n",
      "           1       0.48      0.75      0.58        76\n",
      "\n",
      "    accuracy                           0.50       162\n",
      "   macro avg       0.52      0.51      0.48       162\n",
      "weighted avg       0.52      0.50      0.47       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1765.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5 and f1 score is: 0.46210288993646237\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.22      0.32        86\n",
      "           1       0.48      0.82      0.60        76\n",
      "\n",
      "    accuracy                           0.50       162\n",
      "   macro avg       0.53      0.52      0.46       162\n",
      "weighted avg       0.53      0.50      0.45       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1765.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5123456790123457 and f1 score is: 0.47897243822008706\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.24      0.35        86\n",
      "           1       0.49      0.82      0.61        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.54      0.53      0.48       162\n",
      "weighted avg       0.55      0.51      0.47       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5493827160493827 and f1 score is: 0.5464621284755513\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.44      0.51        86\n",
      "           1       0.52      0.67      0.58        76\n",
      "\n",
      "    accuracy                           0.55       162\n",
      "   macro avg       0.56      0.56      0.55       162\n",
      "weighted avg       0.56      0.55      0.54       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1765.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5370370370370371 and f1 score is: 0.5257426129044849\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.36      0.45        86\n",
      "           1       0.50      0.74      0.60        76\n",
      "\n",
      "    accuracy                           0.54       162\n",
      "   macro avg       0.56      0.55      0.53       162\n",
      "weighted avg       0.56      0.54      0.52       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1765.csv ---\n",
      "[22:38:36] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5185185185185185 and f1 score is: 0.4762931034482758\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.22      0.33        86\n",
      "           1       0.49      0.86      0.62        76\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.56      0.54      0.48       162\n",
      "weighted avg       0.57      0.52      0.47       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1765.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5185185185185185 and f1 score is: 0.5077138849929873\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.35      0.43        86\n",
      "           1       0.49      0.71      0.58        76\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.53      0.53      0.51       162\n",
      "weighted avg       0.54      0.52      0.50       162\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1818.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8773584905660378 and f1 score is: 0.5336717428087987\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.12      0.13        16\n",
      "           1       0.93      0.94      0.93       196\n",
      "\n",
      "    accuracy                           0.88       212\n",
      "   macro avg       0.54      0.53      0.53       212\n",
      "weighted avg       0.87      0.88      0.87       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1818.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6462264150943396 and f1 score is: 0.49872316277310136\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.69      0.23        16\n",
      "           1       0.96      0.64      0.77       196\n",
      "\n",
      "    accuracy                           0.65       212\n",
      "   macro avg       0.55      0.67      0.50       212\n",
      "weighted avg       0.90      0.65      0.73       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1818.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7641509433962265 and f1 score is: 0.5006595063124176\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.25      0.14        16\n",
      "           1       0.93      0.81      0.86       196\n",
      "\n",
      "    accuracy                           0.76       212\n",
      "   macro avg       0.51      0.53      0.50       212\n",
      "weighted avg       0.87      0.76      0.81       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1818.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7830188679245284 and f1 score is: 0.5534798534798535\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.44      0.23        16\n",
      "           1       0.95      0.81      0.87       196\n",
      "\n",
      "    accuracy                           0.78       212\n",
      "   macro avg       0.55      0.62      0.55       212\n",
      "weighted avg       0.89      0.78      0.83       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8679245283018868 and f1 score is: 0.4978003384094754\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.06      0.07        16\n",
      "           1       0.92      0.93      0.93       196\n",
      "\n",
      "    accuracy                           0.87       212\n",
      "   macro avg       0.50      0.50      0.50       212\n",
      "weighted avg       0.86      0.87      0.86       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1818.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7783018867924528 and f1 score is: 0.4762130053093624\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.12      0.08        16\n",
      "           1       0.92      0.83      0.87       196\n",
      "\n",
      "    accuracy                           0.78       212\n",
      "   macro avg       0.49      0.48      0.48       212\n",
      "weighted avg       0.86      0.78      0.81       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1818.csv ---\n",
      "[22:40:24] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6556603773584906 and f1 score is: 0.4429687218802865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.25      0.10        16\n",
      "           1       0.92      0.69      0.79       196\n",
      "\n",
      "    accuracy                           0.66       212\n",
      "   macro avg       0.49      0.47      0.44       212\n",
      "weighted avg       0.85      0.66      0.74       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1818.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7264150943396226 and f1 score is: 0.45214756727856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.12      0.06        16\n",
      "           1       0.92      0.78      0.84       196\n",
      "\n",
      "    accuracy                           0.73       212\n",
      "   macro avg       0.48      0.45      0.45       212\n",
      "weighted avg       0.85      0.73      0.78       212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1892.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5416666666666666 and f1 score is: 0.4749429125641466\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.60      0.66       162\n",
      "           1       0.24      0.37      0.29        54\n",
      "\n",
      "    accuracy                           0.54       216\n",
      "   macro avg       0.49      0.48      0.47       216\n",
      "weighted avg       0.61      0.54      0.57       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.3888888888888889 and f1 score is: 0.38841698841698846\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.28      0.41       162\n",
      "           1       0.25      0.72      0.37        54\n",
      "\n",
      "    accuracy                           0.39       216\n",
      "   macro avg       0.50      0.50      0.39       216\n",
      "weighted avg       0.62      0.39      0.40       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1892.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.49537037037037035 and f1 score is: 0.4655771195097038\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.49      0.59       162\n",
      "           1       0.25      0.52      0.34        54\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.50      0.50      0.47       216\n",
      "weighted avg       0.63      0.50      0.53       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1892.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5231481481481481 and f1 score is: 0.4949948927477018\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.51      0.61       162\n",
      "           1       0.28      0.57      0.38        54\n",
      "\n",
      "    accuracy                           0.52       216\n",
      "   macro avg       0.53      0.54      0.49       216\n",
      "weighted avg       0.66      0.52      0.55       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.41203703703703703 and f1 score is: 0.41101449275362323\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.30      0.44       162\n",
      "           1       0.26      0.74      0.39        54\n",
      "\n",
      "    accuracy                           0.41       216\n",
      "   macro avg       0.52      0.52      0.41       216\n",
      "weighted avg       0.65      0.41      0.42       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1892.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.49074074074074076 and f1 score is: 0.4540441176470588\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.50      0.60       162\n",
      "           1       0.24      0.46      0.31        54\n",
      "\n",
      "    accuracy                           0.49       216\n",
      "   macro avg       0.49      0.48      0.45       216\n",
      "weighted avg       0.61      0.49      0.52       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1892.csv ---\n",
      "[22:42:13] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.48148148148148145 and f1 score is: 0.4521242866201649\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.48      0.58       162\n",
      "           1       0.24      0.50      0.33        54\n",
      "\n",
      "    accuracy                           0.48       216\n",
      "   macro avg       0.49      0.49      0.45       216\n",
      "weighted avg       0.62      0.48      0.52       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1892.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5416666666666666 and f1 score is: 0.4825658770295449\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66       162\n",
      "           1       0.25      0.41      0.31        54\n",
      "\n",
      "    accuracy                           0.54       216\n",
      "   macro avg       0.50      0.50      0.48       216\n",
      "weighted avg       0.62      0.54      0.57       216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1929.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6084905660377359 and f1 score is: 0.5048262276628676\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.25      0.28        65\n",
      "           1       0.70      0.77      0.73       147\n",
      "\n",
      "    accuracy                           0.61       212\n",
      "   macro avg       0.51      0.51      0.50       212\n",
      "weighted avg       0.58      0.61      0.59       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1929.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6933962264150944 and f1 score is: 0.5717171717171717\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.26      0.34        65\n",
      "           1       0.73      0.88      0.80       147\n",
      "\n",
      "    accuracy                           0.69       212\n",
      "   macro avg       0.62      0.57      0.57       212\n",
      "weighted avg       0.66      0.69      0.66       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1929.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5566037735849056 and f1 score is: 0.4912173202614379\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.32      0.31        65\n",
      "           1       0.69      0.66      0.67       147\n",
      "\n",
      "    accuracy                           0.56       212\n",
      "   macro avg       0.49      0.49      0.49       212\n",
      "weighted avg       0.57      0.56      0.56       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1929.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.47641509433962265 and f1 score is: 0.46174432169079804\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.51      0.37        65\n",
      "           1       0.68      0.46      0.55       147\n",
      "\n",
      "    accuracy                           0.48       212\n",
      "   macro avg       0.49      0.49      0.46       212\n",
      "weighted avg       0.56      0.48      0.50       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6509433962264151 and f1 score is: 0.5158024691358025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.20      0.26        65\n",
      "           1       0.71      0.85      0.77       147\n",
      "\n",
      "    accuracy                           0.65       212\n",
      "   macro avg       0.54      0.53      0.52       212\n",
      "weighted avg       0.60      0.65      0.61       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1929.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.45754716981132076 and f1 score is: 0.4295074295074295\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.38      0.30        65\n",
      "           1       0.64      0.49      0.56       147\n",
      "\n",
      "    accuracy                           0.46       212\n",
      "   macro avg       0.45      0.44      0.43       212\n",
      "weighted avg       0.52      0.46      0.48       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1929.csv ---\n",
      "[22:44:00] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6698113207547169 and f1 score is: 0.604772557792692\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.43      0.44        65\n",
      "           1       0.75      0.78      0.77       147\n",
      "\n",
      "    accuracy                           0.67       212\n",
      "   macro avg       0.61      0.60      0.60       212\n",
      "weighted avg       0.66      0.67      0.67       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1929.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5660377358490566 and f1 score is: 0.509456740442656\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.37      0.34        65\n",
      "           1       0.70      0.65      0.68       147\n",
      "\n",
      "    accuracy                           0.57       212\n",
      "   macro avg       0.51      0.51      0.51       212\n",
      "weighted avg       0.58      0.57      0.57       212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\3635406624.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  xtrainDriv = xtrainDriv.append(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1933.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5816326530612245 and f1 score is: 0.5652926539002489\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.53      0.48        36\n",
      "           1       0.69      0.61      0.65        62\n",
      "\n",
      "    accuracy                           0.58        98\n",
      "   macro avg       0.57      0.57      0.57        98\n",
      "weighted avg       0.60      0.58      0.59        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6020408163265306 and f1 score is: 0.5896940418679549\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.58      0.52        36\n",
      "           1       0.72      0.61      0.66        62\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.59      0.60      0.59        98\n",
      "weighted avg       0.63      0.60      0.61        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1933.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5510204081632653 and f1 score is: 0.5223748338502437\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.42      0.41        36\n",
      "           1       0.65      0.63      0.64        62\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.52      0.52      0.52        98\n",
      "weighted avg       0.56      0.55      0.55        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1933.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n",
      "c:\\Users\\Anubhav\\anaconda3\\envs\\cogl\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5204081632653061 and f1 score is: 0.45029239766081874\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.22      0.25        36\n",
      "           1       0.61      0.69      0.65        62\n",
      "\n",
      "    accuracy                           0.52        98\n",
      "   macro avg       0.45      0.46      0.45        98\n",
      "weighted avg       0.49      0.52      0.50        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6020408163265306 and f1 score is: 0.5896940418679549\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.58      0.52        36\n",
      "           1       0.72      0.61      0.66        62\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.59      0.60      0.59        98\n",
      "weighted avg       0.63      0.60      0.61        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1933.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.4897959183673469 and f1 score is: 0.43704044117647056\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.25      0.26        36\n",
      "           1       0.59      0.63      0.61        62\n",
      "\n",
      "    accuracy                           0.49        98\n",
      "   macro avg       0.44      0.44      0.44        98\n",
      "weighted avg       0.48      0.49      0.48        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1933.csv ---\n",
      "[22:45:50] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5612244897959183 and f1 score is: 0.5506983686960231\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.56      0.48        36\n",
      "           1       0.69      0.56      0.62        62\n",
      "\n",
      "    accuracy                           0.56        98\n",
      "   macro avg       0.56      0.56      0.55        98\n",
      "weighted avg       0.59      0.56      0.57        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1933.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_42152\\4009010777.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'dataset': folder,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5510204081632653 and f1 score is: 0.5387248609328199\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.53      0.46        36\n",
      "           1       0.67      0.56      0.61        62\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.54      0.55      0.54        98\n",
      "weighted avg       0.58      0.55      0.56        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losoValidation('MatbII', 'ECG_EDA_Features_Combined_scld', 'ECG_EDA_Base2_Features_Combined', config2.SELECTEEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losoValidation1(dataset, folder, basefolder, paramsSELECTCOLS):\n",
    "    dr_feat_path = r'X:\\All Modes\\All\\{}\\Combine'.format(dataset) # ECG_EDA_Features_Combined_scld\n",
    "    bs_feat_path = r'X:\\All Modes\\All\\{}\\Combine'.format(dataset) # ECG_EDA_Base2_Features_Combined\n",
    "    date_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "    print(\"Saved Directory: {}\".format(date_time))\n",
    "    savePath_0 = f\"X:/All Modes/Data Files/{date_time}\"\n",
    "    utils.mk_dirs(savePath_0)\n",
    "    savePath1 = os.path.join(savePath_0, f'{dataset}')\n",
    "    utils.mk_dirs(savePath1)\n",
    "    savePath = os.path.join(savePath1, 'ECG EDA')\n",
    "    utils.mk_dirs(savePath)\n",
    "\n",
    "    mycls = {}\n",
    "\n",
    "    if dataset == 'MatbII':\n",
    "        parameter_list = funcs_for_matbii\n",
    "    # elif dataset == 'Virage':\n",
    "    #     parameter_list = funcs_for_virage\n",
    "\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    results_df = pd.DataFrame(columns=['dataset', 'method', 'test_subject', 'test_acc', 'test_f1', 'wgt_test_f1'])\n",
    "    for sdriv in subjects:\n",
    "        utils.mk_dirs(os.path.join(savePath, sdriv))\n",
    "\n",
    "        xtestDriv = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(sdriv)))\n",
    "        xtestDriv[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        if np.isinf(xtestDriv).values.sum():\n",
    "            cinf = np.isinf(xtestDriv).values.sum()\n",
    "            print(\"Dataframe contains {} values\".format(cinf))\n",
    "\n",
    "        xtestDriv.replace([np.inf], 9999, inplace=True)\n",
    "        xtestDriv.replace([-np.inf], -9999, inplace=True)\n",
    "\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.astype(int)\n",
    "        xtestDriv['scrNumPeaks'] = xtestDriv['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "        xtestDriv.dropna(inplace=True) # .reset_index(drop=True, inplace=True)\n",
    "\n",
    "        ytestDriv = list(xtestDriv['scaled label'].copy()) \n",
    "\n",
    "        XtrainDriv = mk_training_data(dr_feat_path, sdriv)\n",
    "        # XtrainBase = mk_training_data(bs_feat_path, sdriv)\n",
    "\n",
    "        XtrainDriv = XtrainDriv[paramsSELECTCOLS].copy()\n",
    "        XtestDriv = xtestDriv[paramsSELECTCOLS].copy()  ### Look out for small x and X\n",
    "        # XtrainBase = XtrainBase[SELECTCOLS[:-3]].copy()\n",
    "\n",
    "        ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "        # ytrainBase = XtrainBase.shape[0] * [0]\n",
    "\n",
    "        XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "        XtestDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "\n",
    "        ytrain = ytrainDriv #+ ytrainBase\n",
    "        # XtrainDriv = XtrainDriv.append(XtrainBase)\n",
    "\n",
    "        X = XtrainDriv.values\n",
    "        X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "        for idx, val in enumerate(ytrain):\n",
    "            if val <= 4:\n",
    "                ytrain[idx] = 0\n",
    "            else: ytrain[idx] = 1\n",
    "\n",
    "        for idx, val in enumerate(ytestDriv):\n",
    "            if val <= 4:\n",
    "                ytestDriv[idx] = 0\n",
    "            else: ytestDriv[idx] = 1\n",
    "\n",
    "        # training different classifier for all subjects and saving them in different dictionnaries\n",
    "        mycls = {}\n",
    "        for cls_modl, cls_parameters in parameter_list:\n",
    "            print(\"--------------------------------------------\")\n",
    "            print(f\"---- Training classifier {cls_modl.__name__} for subject: {sdriv} ---\")\n",
    "\n",
    "            classifier_save_path = os.path.join(savePath, sdriv, cls_modl.__name__)\n",
    "            utils.mk_dirs(classifier_save_path)\n",
    "\n",
    "            classifier_report = os.path.join(classifier_save_path, 'report')\n",
    "            classifier_sav = os.path.join(classifier_save_path, 'classifier')\n",
    "            utils.mk_dirs(classifier_report)\n",
    "            utils.mk_dirs(classifier_sav)\n",
    "\n",
    "            if cls_modl.__name__ in ['LogisticRegression', 'SVC', 'LGBMClassifier', 'XGBClassifier']:\n",
    "                scaler = StandardScaler()\n",
    "                X = scaler.fit_transform(X)\n",
    "                XtestDriv = scaler.transform(XtestDriv)\n",
    "            clf = cls_modl(**cls_parameters)\n",
    "            hist = clf.fit(X, ytrain)\n",
    "\n",
    "            yPred = hist.predict(XtestDriv)\n",
    "\n",
    "            test_accuray = accuracy_score(ytestDriv, yPred)\n",
    "            test_f1 = f1_score(ytestDriv, yPred, average='macro')\n",
    "            wgt_test_f1 = f1_score(ytestDriv, yPred, average='weighted')\n",
    "\n",
    "            results_df = results_df.append({'dataset': folder,\n",
    "                                            'method':cls_modl.__name__,\n",
    "                                            'test_subject': sdriv,\n",
    "                                            'test_acc': test_accuray,\n",
    "                                            'test_f1':test_f1, 'wgt_test_f1': wgt_test_f1}, ignore_index=True)\n",
    "            print('Test Subject: {}'.format(sdriv))\n",
    "\n",
    "            mycls[sdriv] = classification_report(ytestDriv, yPred, zero_division=1, output_dict=True)\n",
    "            print(\"----- Classification Report ------\")\n",
    "            print(f\"Test accuracy for {sdriv} is: {test_accuray} and f1 score is: {test_f1}\\n\")\n",
    "\n",
    "            print(classification_report(ytestDriv, yPred, zero_division=1))\n",
    "            with open(os.path.join(classifier_report, 'Test_fold_{}_report.pickle'.format(sdriv)), 'wb') as handle:\n",
    "                pickle.dump(mycls, handle, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            with open(os.path.join(classifier_sav, 'Test_fold_{}_report.sav'.format(sdriv)), 'wb') as handle:\n",
    "                pickle.dump(hist, handle, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        # estimatorPath = os.path.join(savePath, '{}.sav'.format(saveName))\n",
    "        # pickle.dump(hist, open(estimatorPath, 'wb'))\n",
    "\n",
    "    results_df.to_csv(os.path.join(savePath, 'results.csv'), index=False)\n",
    "    return\n",
    "    # return XtrainDriv, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Directory: 2022_08_10_22_52\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5432692307692307 and f1 score is: 0.43515421776291335\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.12      0.19        95\n",
      "           1       0.55      0.90      0.68       113\n",
      "\n",
      "    accuracy                           0.54       208\n",
      "   macro avg       0.52      0.51      0.44       208\n",
      "weighted avg       0.53      0.54      0.46       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.40865384615384615 and f1 score is: 0.40699534107502955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.39      0.38        95\n",
      "           1       0.45      0.42      0.44       113\n",
      "\n",
      "    accuracy                           0.41       208\n",
      "   macro avg       0.41      0.41      0.41       208\n",
      "weighted avg       0.41      0.41      0.41       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.3942307692307692 and f1 score is: 0.38965999068467627\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.53      0.44        95\n",
      "           1       0.42      0.28      0.34       113\n",
      "\n",
      "    accuracy                           0.39       208\n",
      "   macro avg       0.40      0.40      0.39       208\n",
      "weighted avg       0.40      0.39      0.39       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.47115384615384615 and f1 score is: 0.4439583940896277\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.27      0.32        95\n",
      "           1       0.51      0.64      0.57       113\n",
      "\n",
      "    accuracy                           0.47       208\n",
      "   macro avg       0.45      0.46      0.44       208\n",
      "weighted avg       0.45      0.47      0.45       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.4182692307692308 and f1 score is: 0.4182557843885075\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.45      0.42        95\n",
      "           1       0.46      0.39      0.42       113\n",
      "\n",
      "    accuracy                           0.42       208\n",
      "   macro avg       0.42      0.42      0.42       208\n",
      "weighted avg       0.42      0.42      0.42       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5048076923076923 and f1 score is: 0.5028657616892911\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.48      0.47        95\n",
      "           1       0.55      0.52      0.53       113\n",
      "\n",
      "    accuracy                           0.50       208\n",
      "   macro avg       0.50      0.50      0.50       208\n",
      "weighted avg       0.51      0.50      0.51       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1105.csv ---\n",
      "[22:54:01] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5048076923076923 and f1 score is: 0.45821004981918423\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.23      0.30        95\n",
      "           1       0.53      0.73      0.62       113\n",
      "\n",
      "    accuracy                           0.50       208\n",
      "   macro avg       0.48      0.48      0.46       208\n",
      "weighted avg       0.48      0.50      0.47       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.3701923076923077 and f1 score is: 0.36772247360482657\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.34      0.33        95\n",
      "           1       0.42      0.40      0.41       113\n",
      "\n",
      "    accuracy                           0.37       208\n",
      "   macro avg       0.37      0.37      0.37       208\n",
      "weighted avg       0.37      0.37      0.37       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8027210884353742 and f1 score is: 0.47712498466822034\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.06      0.06        16\n",
      "           1       0.89      0.89      0.89       131\n",
      "\n",
      "    accuracy                           0.80       147\n",
      "   macro avg       0.48      0.48      0.48       147\n",
      "weighted avg       0.80      0.80      0.80       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.5102040816326531 and f1 score is: 0.37179487179487175\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.19      0.08        16\n",
      "           1       0.85      0.55      0.67       131\n",
      "\n",
      "    accuracy                           0.51       147\n",
      "   macro avg       0.45      0.37      0.37       147\n",
      "weighted avg       0.76      0.51      0.60       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.6326530612244898 and f1 score is: 0.43461538461538457\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.19      0.10        16\n",
      "           1       0.87      0.69      0.77       131\n",
      "\n",
      "    accuracy                           0.63       147\n",
      "   macro avg       0.47      0.44      0.43       147\n",
      "weighted avg       0.79      0.63      0.70       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7074829931972789 and f1 score is: 0.5441038586368554\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.27        16\n",
      "           1       0.92      0.73      0.82       131\n",
      "\n",
      "    accuracy                           0.71       147\n",
      "   macro avg       0.55      0.62      0.54       147\n",
      "weighted avg       0.84      0.71      0.76       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.5850340136054422 and f1 score is: 0.41041488592280884\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.19      0.09        16\n",
      "           1       0.86      0.63      0.73       131\n",
      "\n",
      "    accuracy                           0.59       147\n",
      "   macro avg       0.46      0.41      0.41       147\n",
      "weighted avg       0.78      0.59      0.66       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.4217687074829932 and f1 score is: 0.36486555177146346\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.56      0.17        16\n",
      "           1       0.88      0.40      0.55       131\n",
      "\n",
      "    accuracy                           0.42       147\n",
      "   macro avg       0.49      0.48      0.36       147\n",
      "weighted avg       0.80      0.42      0.51       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1106.csv ---\n",
      "[22:55:52] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.782312925170068 and f1 score is: 0.46787330316742076\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.06      0.06        16\n",
      "           1       0.88      0.87      0.88       131\n",
      "\n",
      "    accuracy                           0.78       147\n",
      "   macro avg       0.47      0.47      0.47       147\n",
      "weighted avg       0.79      0.78      0.79       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7210884353741497 and f1 score is: 0.48083383581703854\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.19      0.13        16\n",
      "           1       0.89      0.79      0.83       131\n",
      "\n",
      "    accuracy                           0.72       147\n",
      "   macro avg       0.49      0.49      0.48       147\n",
      "weighted avg       0.80      0.72      0.76       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.536723163841808 and f1 score is: 0.3702707393266227\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.05        84\n",
      "           1       0.53      1.00      0.69        93\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.77      0.51      0.37       177\n",
      "weighted avg       0.75      0.54      0.39       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4463276836158192 and f1 score is: 0.44489247311827956\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.52      0.47        84\n",
      "           1       0.47      0.38      0.42        93\n",
      "\n",
      "    accuracy                           0.45       177\n",
      "   macro avg       0.45      0.45      0.44       177\n",
      "weighted avg       0.45      0.45      0.44       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5480225988700564 and f1 score is: 0.519674355495251\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.32      0.40        84\n",
      "           1       0.55      0.75      0.64        93\n",
      "\n",
      "    accuracy                           0.55       177\n",
      "   macro avg       0.55      0.54      0.52       177\n",
      "weighted avg       0.55      0.55      0.53       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5028248587570622 and f1 score is: 0.5001283697047496\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.61      0.54        84\n",
      "           1       0.54      0.41      0.46        93\n",
      "\n",
      "    accuracy                           0.50       177\n",
      "   macro avg       0.51      0.51      0.50       177\n",
      "weighted avg       0.51      0.50      0.50       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4124293785310734 and f1 score is: 0.39126984126984127\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.63      0.50        84\n",
      "           1       0.39      0.22      0.28        93\n",
      "\n",
      "    accuracy                           0.41       177\n",
      "   macro avg       0.41      0.42      0.39       177\n",
      "weighted avg       0.41      0.41      0.39       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4350282485875706 and f1 score is: 0.402995143011333\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.70      0.54        84\n",
      "           1       0.42      0.19      0.26        93\n",
      "\n",
      "    accuracy                           0.44       177\n",
      "   macro avg       0.43      0.45      0.40       177\n",
      "weighted avg       0.43      0.44      0.40       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1175.csv ---\n",
      "[22:57:39] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.536723163841808 and f1 score is: 0.5313226556445363\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48        84\n",
      "           1       0.55      0.61      0.58        93\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.53      0.53      0.53       177\n",
      "weighted avg       0.53      0.54      0.53       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4858757062146893 and f1 score is: 0.48528424887354993\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.55      0.50        84\n",
      "           1       0.51      0.43      0.47        93\n",
      "\n",
      "    accuracy                           0.49       177\n",
      "   macro avg       0.49      0.49      0.49       177\n",
      "weighted avg       0.49      0.49      0.48       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6018518518518519 and f1 score is: 0.6006191950464397\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58       113\n",
      "           1       0.57      0.69      0.62       103\n",
      "\n",
      "    accuracy                           0.60       216\n",
      "   macro avg       0.61      0.61      0.60       216\n",
      "weighted avg       0.61      0.60      0.60       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5601851851851852 and f1 score is: 0.5509355509355509\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.67      0.62       113\n",
      "           1       0.55      0.44      0.49       103\n",
      "\n",
      "    accuracy                           0.56       216\n",
      "   macro avg       0.56      0.55      0.55       216\n",
      "weighted avg       0.56      0.56      0.55       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5879629629629629 and f1 score is: 0.5823684039017184\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.67      0.63       113\n",
      "           1       0.58      0.50      0.53       103\n",
      "\n",
      "    accuracy                           0.59       216\n",
      "   macro avg       0.59      0.58      0.58       216\n",
      "weighted avg       0.59      0.59      0.58       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.625 and f1 score is: 0.6231827873618918\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65       113\n",
      "           1       0.61      0.58      0.60       103\n",
      "\n",
      "    accuracy                           0.62       216\n",
      "   macro avg       0.62      0.62      0.62       216\n",
      "weighted avg       0.62      0.62      0.62       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5879629629629629 and f1 score is: 0.5792975161396214\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.70      0.64       113\n",
      "           1       0.59      0.47      0.52       103\n",
      "\n",
      "    accuracy                           0.59       216\n",
      "   macro avg       0.59      0.58      0.58       216\n",
      "weighted avg       0.59      0.59      0.58       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.47685185185185186 and f1 score is: 0.47675091645765\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.47      0.48       113\n",
      "           1       0.45      0.49      0.47       103\n",
      "\n",
      "    accuracy                           0.48       216\n",
      "   macro avg       0.48      0.48      0.48       216\n",
      "weighted avg       0.48      0.48      0.48       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1337.csv ---\n",
      "[22:59:26] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5833333333333334 and f1 score is: 0.5804195804195804\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62       113\n",
      "           1       0.57      0.52      0.55       103\n",
      "\n",
      "    accuracy                           0.58       216\n",
      "   macro avg       0.58      0.58      0.58       216\n",
      "weighted avg       0.58      0.58      0.58       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5138888888888888 and f1 score is: 0.49571984435797667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.67      0.59       113\n",
      "           1       0.49      0.34      0.40       103\n",
      "\n",
      "    accuracy                           0.51       216\n",
      "   macro avg       0.51      0.51      0.50       216\n",
      "weighted avg       0.51      0.51      0.50       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5305164319248826 and f1 score is: 0.46803196803196806\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.21      0.29        95\n",
      "           1       0.55      0.79      0.65       118\n",
      "\n",
      "    accuracy                           0.53       213\n",
      "   macro avg       0.50      0.50      0.47       213\n",
      "weighted avg       0.50      0.53      0.49       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5727699530516432 and f1 score is: 0.5066055746468118\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.23      0.33        95\n",
      "           1       0.58      0.85      0.69       118\n",
      "\n",
      "    accuracy                           0.57       213\n",
      "   macro avg       0.56      0.54      0.51       213\n",
      "weighted avg       0.57      0.57      0.53       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5352112676056338 and f1 score is: 0.5337313432835821\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.54      0.51        95\n",
      "           1       0.59      0.53      0.56       118\n",
      "\n",
      "    accuracy                           0.54       213\n",
      "   macro avg       0.53      0.54      0.53       213\n",
      "weighted avg       0.54      0.54      0.54       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5446009389671361 and f1 score is: 0.5081299845256517\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.31      0.37        95\n",
      "           1       0.57      0.74      0.64       118\n",
      "\n",
      "    accuracy                           0.54       213\n",
      "   macro avg       0.53      0.52      0.51       213\n",
      "weighted avg       0.53      0.54      0.52       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5539906103286385 and f1 score is: 0.4763876310001294\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.19      0.27        95\n",
      "           1       0.56      0.85      0.68       118\n",
      "\n",
      "    accuracy                           0.55       213\n",
      "   macro avg       0.53      0.52      0.48       213\n",
      "weighted avg       0.54      0.55      0.50       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5868544600938967 and f1 score is: 0.5864077669902913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.69      0.60        95\n",
      "           1       0.67      0.50      0.57       118\n",
      "\n",
      "    accuracy                           0.59       213\n",
      "   macro avg       0.60      0.60      0.59       213\n",
      "weighted avg       0.61      0.59      0.58       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1390.csv ---\n",
      "[23:01:11] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5305164319248826 and f1 score is: 0.46407004830917875\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.20      0.28        95\n",
      "           1       0.55      0.80      0.65       118\n",
      "\n",
      "    accuracy                           0.53       213\n",
      "   macro avg       0.50      0.50      0.46       213\n",
      "weighted avg       0.50      0.53      0.48       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5446009389671361 and f1 score is: 0.4962329017628557\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.26      0.34        95\n",
      "           1       0.57      0.77      0.65       118\n",
      "\n",
      "    accuracy                           0.54       213\n",
      "   macro avg       0.52      0.52      0.50       213\n",
      "weighted avg       0.53      0.54      0.51       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6333333333333333 and f1 score is: 0.411122036490768\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.96      0.77       136\n",
      "           1       0.29      0.03      0.05        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.47      0.50      0.41       210\n",
      "weighted avg       0.52      0.63      0.52       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5571428571428572 and f1 score is: 0.40952380952380957\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.70       136\n",
      "           1       0.19      0.08      0.11        74\n",
      "\n",
      "    accuracy                           0.56       210\n",
      "   macro avg       0.41      0.45      0.41       210\n",
      "weighted avg       0.47      0.56      0.50       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6285714285714286 and f1 score is: 0.43934830230010957\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.93      0.77       136\n",
      "           1       0.36      0.07      0.11        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.50      0.50      0.44       210\n",
      "weighted avg       0.55      0.63      0.54       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5428571428571428 and f1 score is: 0.4819611470860315\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66       136\n",
      "           1       0.33      0.28      0.30        74\n",
      "\n",
      "    accuracy                           0.54       210\n",
      "   macro avg       0.48      0.48      0.48       210\n",
      "weighted avg       0.53      0.54      0.53       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5904761904761905 and f1 score is: 0.3919191919191919\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.90      0.74       136\n",
      "           1       0.12      0.03      0.04        74\n",
      "\n",
      "    accuracy                           0.59       210\n",
      "   macro avg       0.38      0.46      0.39       210\n",
      "weighted avg       0.45      0.59      0.49       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5952380952380952 and f1 score is: 0.5016611295681063\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.79      0.72       136\n",
      "           1       0.38      0.23      0.29        74\n",
      "\n",
      "    accuracy                           0.60       210\n",
      "   macro avg       0.52      0.51      0.50       210\n",
      "weighted avg       0.56      0.60      0.57       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1400.csv ---\n",
      "[23:02:58] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.638095238095238 and f1 score is: 0.43452380952380953\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.96      0.77       136\n",
      "           1       0.40      0.05      0.10        74\n",
      "\n",
      "    accuracy                           0.64       210\n",
      "   macro avg       0.53      0.50      0.43       210\n",
      "weighted avg       0.56      0.64      0.53       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6333333333333333 and f1 score is: 0.3877551020408163\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.98      0.78       136\n",
      "           1       0.00      0.00      0.00        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.32      0.49      0.39       210\n",
      "weighted avg       0.42      0.63      0.50       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.4392523364485981 and f1 score is: 0.4392033542976939\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.48      0.43        95\n",
      "           1       0.49      0.40      0.44       119\n",
      "\n",
      "    accuracy                           0.44       214\n",
      "   macro avg       0.44      0.44      0.44       214\n",
      "weighted avg       0.45      0.44      0.44       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.411214953271028 and f1 score is: 0.3493243243243243\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.81      0.55        95\n",
      "           1       0.38      0.09      0.15       119\n",
      "\n",
      "    accuracy                           0.41       214\n",
      "   macro avg       0.40      0.45      0.35       214\n",
      "weighted avg       0.40      0.41      0.33       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.4766355140186916 and f1 score is: 0.4762237762237762\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.57      0.49        95\n",
      "           1       0.54      0.40      0.46       119\n",
      "\n",
      "    accuracy                           0.48       214\n",
      "   macro avg       0.49      0.49      0.48       214\n",
      "weighted avg       0.49      0.48      0.47       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.49065420560747663 and f1 score is: 0.4599837944206505\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.82      0.59        95\n",
      "           1       0.61      0.23      0.33       119\n",
      "\n",
      "    accuracy                           0.49       214\n",
      "   macro avg       0.54      0.52      0.46       214\n",
      "weighted avg       0.54      0.49      0.45       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.40186915887850466 and f1 score is: 0.34311750599520385\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.79      0.54        95\n",
      "           1       0.35      0.09      0.15       119\n",
      "\n",
      "    accuracy                           0.40       214\n",
      "   macro avg       0.38      0.44      0.34       214\n",
      "weighted avg       0.38      0.40      0.32       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5 and f1 score is: 0.4991140763425571\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.52      0.48        95\n",
      "           1       0.56      0.49      0.52       119\n",
      "\n",
      "    accuracy                           0.50       214\n",
      "   macro avg       0.50      0.50      0.50       214\n",
      "weighted avg       0.51      0.50      0.50       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1419.csv ---\n",
      "[23:04:43] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.4719626168224299 and f1 score is: 0.4693555111803559\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.45      0.43        95\n",
      "           1       0.53      0.49      0.51       119\n",
      "\n",
      "    accuracy                           0.47       214\n",
      "   macro avg       0.47      0.47      0.47       214\n",
      "weighted avg       0.48      0.47      0.47       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.46261682242990654 and f1 score is: 0.46251119313342215\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.51      0.45        95\n",
      "           1       0.52      0.43      0.47       119\n",
      "\n",
      "    accuracy                           0.46       214\n",
      "   macro avg       0.47      0.47      0.46       214\n",
      "weighted avg       0.47      0.46      0.46       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.2716049382716049 and f1 score is: 0.24203013481363997\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.05      0.09       122\n",
      "           1       0.25      0.95      0.39        40\n",
      "\n",
      "    accuracy                           0.27       162\n",
      "   macro avg       0.50      0.50      0.24       162\n",
      "weighted avg       0.63      0.27      0.17       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.35185185185185186 and f1 score is: 0.34765100671140936\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.18      0.30       122\n",
      "           1       0.26      0.88      0.40        40\n",
      "\n",
      "    accuracy                           0.35       162\n",
      "   macro avg       0.54      0.53      0.35       162\n",
      "weighted avg       0.68      0.35      0.32       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.3395061728395062 and f1 score is: 0.33379453476305776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.16      0.27       122\n",
      "           1       0.26      0.88      0.40        40\n",
      "\n",
      "    accuracy                           0.34       162\n",
      "   macro avg       0.53      0.52      0.33       162\n",
      "weighted avg       0.67      0.34      0.30       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.345679012345679 and f1 score is: 0.345679012345679\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.23      0.35       122\n",
      "           1       0.23      0.70      0.35        40\n",
      "\n",
      "    accuracy                           0.35       162\n",
      "   macro avg       0.46      0.46      0.35       162\n",
      "weighted avg       0.58      0.35      0.35       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.3765432098765432 and f1 score is: 0.3759487394637476\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.23      0.36       122\n",
      "           1       0.26      0.82      0.40        40\n",
      "\n",
      "    accuracy                           0.38       162\n",
      "   macro avg       0.53      0.53      0.38       162\n",
      "weighted avg       0.67      0.38      0.37       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.35185185185185186 and f1 score is: 0.34624697336561744\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.17      0.29       122\n",
      "           1       0.26      0.90      0.41        40\n",
      "\n",
      "    accuracy                           0.35       162\n",
      "   macro avg       0.55      0.54      0.35       162\n",
      "weighted avg       0.70      0.35      0.32       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1517.csv ---\n",
      "[23:06:31] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.3395061728395062 and f1 score is: 0.33379453476305776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.16      0.27       122\n",
      "           1       0.26      0.88      0.40        40\n",
      "\n",
      "    accuracy                           0.34       162\n",
      "   macro avg       0.53      0.52      0.33       162\n",
      "weighted avg       0.67      0.34      0.30       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.30246913580246915 and f1 score is: 0.29054761074293683\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.11      0.20       122\n",
      "           1       0.24      0.88      0.38        40\n",
      "\n",
      "    accuracy                           0.30       162\n",
      "   macro avg       0.49      0.49      0.29       162\n",
      "weighted avg       0.62      0.30      0.24       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6304347826086957 and f1 score is: 0.47551978537894035\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.20      0.19        10\n",
      "           1       0.77      0.75      0.76        36\n",
      "\n",
      "    accuracy                           0.63        46\n",
      "   macro avg       0.48      0.47      0.48        46\n",
      "weighted avg       0.64      0.63      0.64        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.13043478260869565 and f1 score is: 0.12380952380952381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.50      0.20        10\n",
      "           1       0.17      0.03      0.05        36\n",
      "\n",
      "    accuracy                           0.13        46\n",
      "   macro avg       0.15      0.26      0.12        46\n",
      "weighted avg       0.16      0.13      0.08        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6956521739130435 and f1 score is: 0.5527777777777778\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.30      0.30        10\n",
      "           1       0.81      0.81      0.81        36\n",
      "\n",
      "    accuracy                           0.70        46\n",
      "   macro avg       0.55      0.55      0.55        46\n",
      "weighted avg       0.70      0.70      0.70        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6086956521739131 and f1 score is: 0.5379464285714285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.50      0.36        10\n",
      "           1       0.82      0.64      0.72        36\n",
      "\n",
      "    accuracy                           0.61        46\n",
      "   macro avg       0.55      0.57      0.54        46\n",
      "weighted avg       0.70      0.61      0.64        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.21739130434782608 and f1 score is: 0.17857142857142855\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36        10\n",
      "           1       1.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.22        46\n",
      "   macro avg       0.61      0.50      0.18        46\n",
      "weighted avg       0.83      0.22      0.08        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6521739130434783 and f1 score is: 0.44744744744744747\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.10      0.11        10\n",
      "           1       0.76      0.81      0.78        36\n",
      "\n",
      "    accuracy                           0.65        46\n",
      "   macro avg       0.44      0.45      0.45        46\n",
      "weighted avg       0.62      0.65      0.64        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1544.csv ---\n",
      "[23:08:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.45652173913043476 and f1 score is: 0.3918561607615018\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.30      0.19        10\n",
      "           1       0.72      0.50      0.59        36\n",
      "\n",
      "    accuracy                           0.46        46\n",
      "   macro avg       0.43      0.40      0.39        46\n",
      "weighted avg       0.59      0.46      0.50        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.41304347826086957 and f1 score is: 0.362095531587057\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.30      0.18        10\n",
      "           1       0.70      0.44      0.54        36\n",
      "\n",
      "    accuracy                           0.41        46\n",
      "   macro avg       0.41      0.37      0.36        46\n",
      "weighted avg       0.57      0.41      0.46        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.559748427672956 and f1 score is: 0.49991013659237954\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.23      0.33        73\n",
      "           1       0.56      0.84      0.67        86\n",
      "\n",
      "    accuracy                           0.56       159\n",
      "   macro avg       0.56      0.54      0.50       159\n",
      "weighted avg       0.56      0.56      0.51       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.6415094339622641 and f1 score is: 0.6263758914952384\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.48      0.55        73\n",
      "           1       0.64      0.78      0.70        86\n",
      "\n",
      "    accuracy                           0.64       159\n",
      "   macro avg       0.64      0.63      0.63       159\n",
      "weighted avg       0.64      0.64      0.63       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.4528301886792453 and f1 score is: 0.4232645403377111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.25      0.29        73\n",
      "           1       0.50      0.63      0.55        86\n",
      "\n",
      "    accuracy                           0.45       159\n",
      "   macro avg       0.43      0.44      0.42       159\n",
      "weighted avg       0.43      0.45      0.43       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5471698113207547 and f1 score is: 0.5471518987341772\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.59      0.54        73\n",
      "           1       0.59      0.51      0.55        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.55      0.55      0.55       159\n",
      "weighted avg       0.55      0.55      0.55       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.6163522012578616 and f1 score is: 0.584536303276933\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.37      0.47        73\n",
      "           1       0.61      0.83      0.70        86\n",
      "\n",
      "    accuracy                           0.62       159\n",
      "   macro avg       0.62      0.60      0.58       159\n",
      "weighted avg       0.62      0.62      0.59       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5786163522012578 and f1 score is: 0.5731458107945666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.51      0.52        73\n",
      "           1       0.60      0.64      0.62        86\n",
      "\n",
      "    accuracy                           0.58       159\n",
      "   macro avg       0.57      0.57      0.57       159\n",
      "weighted avg       0.58      0.58      0.58       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1624.csv ---\n",
      "[23:10:11] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5660377358490566 and f1 score is: 0.557567447675122\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50        73\n",
      "           1       0.59      0.65      0.62        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.56      0.56      0.56       159\n",
      "weighted avg       0.56      0.57      0.56       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5094339622641509 and f1 score is: 0.4969987021414666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.38      0.42        73\n",
      "           1       0.54      0.62      0.58        86\n",
      "\n",
      "    accuracy                           0.51       159\n",
      "   macro avg       0.50      0.50      0.50       159\n",
      "weighted avg       0.50      0.51      0.50       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6629834254143646 and f1 score is: 0.39867109634551495\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.66       181\n",
      "   macro avg       0.33      0.50      0.40       181\n",
      "weighted avg       0.45      0.66      0.53       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6685082872928176 and f1 score is: 0.41612903225806447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.02      0.03        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.59      0.50      0.42       181\n",
      "weighted avg       0.61      0.67      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6519337016574586 and f1 score is: 0.42307108525170756\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.03      0.06        60\n",
      "           1       0.67      0.96      0.79       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.48      0.50      0.42       181\n",
      "weighted avg       0.54      0.65      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6464088397790055 and f1 score is: 0.47706753340556163\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.12      0.18        60\n",
      "           1       0.67      0.91      0.77       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.53      0.51      0.48       181\n",
      "weighted avg       0.58      0.65      0.58       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6629834254143646 and f1 score is: 0.39867109634551495\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.66       181\n",
      "   macro avg       0.33      0.50      0.40       181\n",
      "weighted avg       0.45      0.66      0.53       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6464088397790055 and f1 score is: 0.43326810176125247\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.05      0.09        60\n",
      "           1       0.67      0.94      0.78       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.48      0.50      0.43       181\n",
      "weighted avg       0.55      0.65      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1688.csv ---\n",
      "[23:11:59] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6850828729281768 and f1 score is: 0.5876004317064396\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.30      0.39        60\n",
      "           1       0.72      0.88      0.79       121\n",
      "\n",
      "    accuracy                           0.69       181\n",
      "   macro avg       0.63      0.59      0.59       181\n",
      "weighted avg       0.66      0.69      0.66       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6353591160220995 and f1 score is: 0.5733571428571429\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.38      0.41        60\n",
      "           1       0.71      0.76      0.74       121\n",
      "\n",
      "    accuracy                           0.64       181\n",
      "   macro avg       0.58      0.57      0.57       181\n",
      "weighted avg       0.62      0.64      0.63       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6944444444444444 and f1 score is: 0.5032752613240418\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.12      0.20        34\n",
      "           1       0.70      0.96      0.81        74\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.64      0.54      0.50       108\n",
      "weighted avg       0.66      0.69      0.62       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.37037037037037035 and f1 score is: 0.37037037037037035\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.59      0.37        34\n",
      "           1       0.59      0.27      0.37        74\n",
      "\n",
      "    accuracy                           0.37       108\n",
      "   macro avg       0.43      0.43      0.37       108\n",
      "weighted avg       0.49      0.37      0.37       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5092592592592593 and f1 score is: 0.4651966738297673\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.35      0.31        34\n",
      "           1       0.66      0.58      0.62        74\n",
      "\n",
      "    accuracy                           0.51       108\n",
      "   macro avg       0.47      0.47      0.47       108\n",
      "weighted avg       0.54      0.51      0.52       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.4722222222222222 and f1 score is: 0.4588131868131867\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.50      0.37        34\n",
      "           1       0.67      0.46      0.54        74\n",
      "\n",
      "    accuracy                           0.47       108\n",
      "   macro avg       0.48      0.48      0.46       108\n",
      "weighted avg       0.55      0.47      0.49       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.39814814814814814 and f1 score is: 0.39768339768339767\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.68      0.41        34\n",
      "           1       0.65      0.27      0.38        74\n",
      "\n",
      "    accuracy                           0.40       108\n",
      "   macro avg       0.47      0.47      0.40       108\n",
      "weighted avg       0.54      0.40      0.39       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5462962962962963 and f1 score is: 0.5373721479150275\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.65      0.47        34\n",
      "           1       0.76      0.50      0.60        74\n",
      "\n",
      "    accuracy                           0.55       108\n",
      "   macro avg       0.56      0.57      0.54       108\n",
      "weighted avg       0.63      0.55      0.56       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1717.csv ---\n",
      "[23:13:49] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6296296296296297 and f1 score is: 0.5178571428571428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.24      0.29        34\n",
      "           1       0.70      0.81      0.75        74\n",
      "\n",
      "    accuracy                           0.63       108\n",
      "   macro avg       0.53      0.52      0.52       108\n",
      "weighted avg       0.59      0.63      0.60       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5740740740740741 and f1 score is: 0.49818181818181817\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.29      0.30        34\n",
      "           1       0.68      0.70      0.69        74\n",
      "\n",
      "    accuracy                           0.57       108\n",
      "   macro avg       0.50      0.50      0.50       108\n",
      "weighted avg       0.57      0.57      0.57       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5432098765432098 and f1 score is: 0.5166129032258064\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.29      0.40        86\n",
      "           1       0.51      0.83      0.63        76\n",
      "\n",
      "    accuracy                           0.54       162\n",
      "   macro avg       0.58      0.56      0.52       162\n",
      "weighted avg       0.59      0.54      0.51       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5 and f1 score is: 0.47835420393559924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.28      0.37        86\n",
      "           1       0.48      0.75      0.58        76\n",
      "\n",
      "    accuracy                           0.50       162\n",
      "   macro avg       0.52      0.51      0.48       162\n",
      "weighted avg       0.52      0.50      0.47       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5 and f1 score is: 0.46210288993646237\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.22      0.32        86\n",
      "           1       0.48      0.82      0.60        76\n",
      "\n",
      "    accuracy                           0.50       162\n",
      "   macro avg       0.53      0.52      0.46       162\n",
      "weighted avg       0.53      0.50      0.45       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4382716049382716 and f1 score is: 0.43653250773993807\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.36      0.41        86\n",
      "           1       0.42      0.53      0.47        76\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.44      0.44      0.44       162\n",
      "weighted avg       0.44      0.44      0.43       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5493827160493827 and f1 score is: 0.5464621284755513\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.44      0.51        86\n",
      "           1       0.52      0.67      0.58        76\n",
      "\n",
      "    accuracy                           0.55       162\n",
      "   macro avg       0.56      0.56      0.55       162\n",
      "weighted avg       0.56      0.55      0.54       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5370370370370371 and f1 score is: 0.5257426129044849\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.36      0.45        86\n",
      "           1       0.50      0.74      0.60        76\n",
      "\n",
      "    accuracy                           0.54       162\n",
      "   macro avg       0.56      0.55      0.53       162\n",
      "weighted avg       0.56      0.54      0.52       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1765.csv ---\n",
      "[23:15:39] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5185185185185185 and f1 score is: 0.4762931034482758\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.22      0.33        86\n",
      "           1       0.49      0.86      0.62        76\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.56      0.54      0.48       162\n",
      "weighted avg       0.57      0.52      0.47       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5185185185185185 and f1 score is: 0.5077138849929873\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.35      0.43        86\n",
      "           1       0.49      0.71      0.58        76\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.53      0.53      0.51       162\n",
      "weighted avg       0.54      0.52      0.50       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8773584905660378 and f1 score is: 0.5336717428087987\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.12      0.13        16\n",
      "           1       0.93      0.94      0.93       196\n",
      "\n",
      "    accuracy                           0.88       212\n",
      "   macro avg       0.54      0.53      0.53       212\n",
      "weighted avg       0.87      0.88      0.87       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6462264150943396 and f1 score is: 0.49872316277310136\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.69      0.23        16\n",
      "           1       0.96      0.64      0.77       196\n",
      "\n",
      "    accuracy                           0.65       212\n",
      "   macro avg       0.55      0.67      0.50       212\n",
      "weighted avg       0.90      0.65      0.73       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7452830188679245 and f1 score is: 0.48993049367314206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.25      0.13        16\n",
      "           1       0.93      0.79      0.85       196\n",
      "\n",
      "    accuracy                           0.75       212\n",
      "   macro avg       0.51      0.52      0.49       212\n",
      "weighted avg       0.86      0.75      0.80       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7311320754716981 and f1 score is: 0.46867167919799496\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.19      0.10        16\n",
      "           1       0.92      0.78      0.84       196\n",
      "\n",
      "    accuracy                           0.73       212\n",
      "   macro avg       0.49      0.48      0.47       212\n",
      "weighted avg       0.86      0.73      0.79       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8679245283018868 and f1 score is: 0.4978003384094754\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.06      0.07        16\n",
      "           1       0.92      0.93      0.93       196\n",
      "\n",
      "    accuracy                           0.87       212\n",
      "   macro avg       0.50      0.50      0.50       212\n",
      "weighted avg       0.86      0.87      0.86       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7783018867924528 and f1 score is: 0.4762130053093624\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.12      0.08        16\n",
      "           1       0.92      0.83      0.87       196\n",
      "\n",
      "    accuracy                           0.78       212\n",
      "   macro avg       0.49      0.48      0.48       212\n",
      "weighted avg       0.86      0.78      0.81       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1818.csv ---\n",
      "[23:17:27] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6556603773584906 and f1 score is: 0.4429687218802865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.25      0.10        16\n",
      "           1       0.92      0.69      0.79       196\n",
      "\n",
      "    accuracy                           0.66       212\n",
      "   macro avg       0.49      0.47      0.44       212\n",
      "weighted avg       0.85      0.66      0.74       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7264150943396226 and f1 score is: 0.45214756727856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.12      0.06        16\n",
      "           1       0.92      0.78      0.84       196\n",
      "\n",
      "    accuracy                           0.73       212\n",
      "   macro avg       0.48      0.45      0.45       212\n",
      "weighted avg       0.85      0.73      0.78       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5416666666666666 and f1 score is: 0.4749429125641466\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.60      0.66       162\n",
      "           1       0.24      0.37      0.29        54\n",
      "\n",
      "    accuracy                           0.54       216\n",
      "   macro avg       0.49      0.48      0.47       216\n",
      "weighted avg       0.61      0.54      0.57       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.3888888888888889 and f1 score is: 0.38841698841698846\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.28      0.41       162\n",
      "           1       0.25      0.72      0.37        54\n",
      "\n",
      "    accuracy                           0.39       216\n",
      "   macro avg       0.50      0.50      0.39       216\n",
      "weighted avg       0.62      0.39      0.40       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.49537037037037035 and f1 score is: 0.4655771195097038\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.49      0.59       162\n",
      "           1       0.25      0.52      0.34        54\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.50      0.50      0.47       216\n",
      "weighted avg       0.63      0.50      0.53       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5555555555555556 and f1 score is: 0.5066615911686334\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.58      0.66       162\n",
      "           1       0.28      0.48      0.35        54\n",
      "\n",
      "    accuracy                           0.56       216\n",
      "   macro avg       0.52      0.53      0.51       216\n",
      "weighted avg       0.65      0.56      0.58       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.41203703703703703 and f1 score is: 0.41101449275362323\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.30      0.44       162\n",
      "           1       0.26      0.74      0.39        54\n",
      "\n",
      "    accuracy                           0.41       216\n",
      "   macro avg       0.52      0.52      0.41       216\n",
      "weighted avg       0.65      0.41      0.42       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.49074074074074076 and f1 score is: 0.4540441176470588\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.50      0.60       162\n",
      "           1       0.24      0.46      0.31        54\n",
      "\n",
      "    accuracy                           0.49       216\n",
      "   macro avg       0.49      0.48      0.45       216\n",
      "weighted avg       0.61      0.49      0.52       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1892.csv ---\n",
      "[23:19:14] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.48148148148148145 and f1 score is: 0.4521242866201649\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.48      0.58       162\n",
      "           1       0.24      0.50      0.33        54\n",
      "\n",
      "    accuracy                           0.48       216\n",
      "   macro avg       0.49      0.49      0.45       216\n",
      "weighted avg       0.62      0.48      0.52       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5416666666666666 and f1 score is: 0.4825658770295449\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66       162\n",
      "           1       0.25      0.41      0.31        54\n",
      "\n",
      "    accuracy                           0.54       216\n",
      "   macro avg       0.50      0.50      0.48       216\n",
      "weighted avg       0.62      0.54      0.57       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6084905660377359 and f1 score is: 0.5048262276628676\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.25      0.28        65\n",
      "           1       0.70      0.77      0.73       147\n",
      "\n",
      "    accuracy                           0.61       212\n",
      "   macro avg       0.51      0.51      0.50       212\n",
      "weighted avg       0.58      0.61      0.59       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6933962264150944 and f1 score is: 0.5717171717171717\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.26      0.34        65\n",
      "           1       0.73      0.88      0.80       147\n",
      "\n",
      "    accuracy                           0.69       212\n",
      "   macro avg       0.62      0.57      0.57       212\n",
      "weighted avg       0.66      0.69      0.66       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5566037735849056 and f1 score is: 0.4871847658260422\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.31      0.30        65\n",
      "           1       0.69      0.67      0.68       147\n",
      "\n",
      "    accuracy                           0.56       212\n",
      "   macro avg       0.49      0.49      0.49       212\n",
      "weighted avg       0.56      0.56      0.56       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.45754716981132076 and f1 score is: 0.4405048766494549\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.46      0.34        65\n",
      "           1       0.66      0.46      0.54       147\n",
      "\n",
      "    accuracy                           0.46       212\n",
      "   macro avg       0.46      0.46      0.44       212\n",
      "weighted avg       0.54      0.46      0.48       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6509433962264151 and f1 score is: 0.5158024691358025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.20      0.26        65\n",
      "           1       0.71      0.85      0.77       147\n",
      "\n",
      "    accuracy                           0.65       212\n",
      "   macro avg       0.54      0.53      0.52       212\n",
      "weighted avg       0.60      0.65      0.61       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.45754716981132076 and f1 score is: 0.4295074295074295\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.38      0.30        65\n",
      "           1       0.64      0.49      0.56       147\n",
      "\n",
      "    accuracy                           0.46       212\n",
      "   macro avg       0.45      0.44      0.43       212\n",
      "weighted avg       0.52      0.46      0.48       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1929.csv ---\n",
      "[23:21:02] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6698113207547169 and f1 score is: 0.604772557792692\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.43      0.44        65\n",
      "           1       0.75      0.78      0.77       147\n",
      "\n",
      "    accuracy                           0.67       212\n",
      "   macro avg       0.61      0.60      0.60       212\n",
      "weighted avg       0.66      0.67      0.67       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5660377358490566 and f1 score is: 0.509456740442656\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.37      0.34        65\n",
      "           1       0.70      0.65      0.68       147\n",
      "\n",
      "    accuracy                           0.57       212\n",
      "   macro avg       0.51      0.51      0.51       212\n",
      "weighted avg       0.58      0.57      0.57       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5816326530612245 and f1 score is: 0.5652926539002489\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.53      0.48        36\n",
      "           1       0.69      0.61      0.65        62\n",
      "\n",
      "    accuracy                           0.58        98\n",
      "   macro avg       0.57      0.57      0.57        98\n",
      "weighted avg       0.60      0.58      0.59        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6020408163265306 and f1 score is: 0.5896940418679549\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.58      0.52        36\n",
      "           1       0.72      0.61      0.66        62\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.59      0.60      0.59        98\n",
      "weighted avg       0.63      0.60      0.61        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5510204081632653 and f1 score is: 0.5223748338502437\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.42      0.41        36\n",
      "           1       0.65      0.63      0.64        62\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.52      0.52      0.52        98\n",
      "weighted avg       0.56      0.55      0.55        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5714285714285714 and f1 score is: 0.5389784946236559\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.42      0.42        36\n",
      "           1       0.66      0.66      0.66        62\n",
      "\n",
      "    accuracy                           0.57        98\n",
      "   macro avg       0.54      0.54      0.54        98\n",
      "weighted avg       0.57      0.57      0.57        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6020408163265306 and f1 score is: 0.5896940418679549\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.58      0.52        36\n",
      "           1       0.72      0.61      0.66        62\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.59      0.60      0.59        98\n",
      "weighted avg       0.63      0.60      0.61        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.4897959183673469 and f1 score is: 0.43704044117647056\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.25      0.26        36\n",
      "           1       0.59      0.63      0.61        62\n",
      "\n",
      "    accuracy                           0.49        98\n",
      "   macro avg       0.44      0.44      0.44        98\n",
      "weighted avg       0.48      0.49      0.48        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1933.csv ---\n",
      "[23:22:51] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5612244897959183 and f1 score is: 0.5506983686960231\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.56      0.48        36\n",
      "           1       0.69      0.56      0.62        62\n",
      "\n",
      "    accuracy                           0.56        98\n",
      "   macro avg       0.56      0.56      0.55        98\n",
      "weighted avg       0.59      0.56      0.57        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5510204081632653 and f1 score is: 0.5387248609328199\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.53      0.46        36\n",
      "           1       0.67      0.56      0.61        62\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.54      0.55      0.54        98\n",
      "weighted avg       0.58      0.55      0.56        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losoValidation1('MatbII', 'ECG_EDA_Features_Combined_scld', 'ECG_EDA_Base2_Features_Combined', config2.SELECTEEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_run = {\"ECG_EEG\": config2.SELECT_ECG_EEG, \"ECG_GAZE\": config2.SELECT_ECG_GAZE, \"EDA_EEG\": config2.SELECT_EDA_EEG,\n",
    "            \"EDA_GAZE\": config2.SELECT_EDA_GAZE, \"EEG_GAZE\": config2.SELECT_EEG_GAZE,\n",
    "            \"ECG_EDA_EEG\": config2.SELECT_ECG_EDA_EEG, \"ECG_EDA_GAZE\": config2.SELECT_ECG_EDA_GAZE,\n",
    "            \"ECG_EEG_GAZE\": config2.SELECT_ECG_EEG_GAZE, \"EDA_EEG_GAZE\": config2.SELECT_EDA_EEG_GAZE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Running Modality Combination ECG_EEG\n",
      "Saved Directory: 2022_08_11_14_49\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5673076923076923 and f1 score is: 0.4155114275009367\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.06      0.12        95\n",
      "           1       0.56      0.99      0.71       113\n",
      "\n",
      "    accuracy                           0.57       208\n",
      "   macro avg       0.71      0.53      0.42       208\n",
      "weighted avg       0.69      0.57      0.44       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5192307692307693 and f1 score is: 0.44956070710278395\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.18      0.25        95\n",
      "           1       0.54      0.81      0.65       113\n",
      "\n",
      "    accuracy                           0.52       208\n",
      "   macro avg       0.49      0.49      0.45       208\n",
      "weighted avg       0.49      0.52      0.47       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5384615384615384 and f1 score is: 0.5225251076040172\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.39      0.44        95\n",
      "           1       0.56      0.66      0.61       113\n",
      "\n",
      "    accuracy                           0.54       208\n",
      "   macro avg       0.53      0.53      0.52       208\n",
      "weighted avg       0.53      0.54      0.53       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5576923076923077 and f1 score is: 0.5114379084967321\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.27      0.36        95\n",
      "           1       0.57      0.80      0.66       113\n",
      "\n",
      "    accuracy                           0.56       208\n",
      "   macro avg       0.55      0.54      0.51       208\n",
      "weighted avg       0.55      0.56      0.52       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.4807692307692308 and f1 score is: 0.4515625\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.27      0.33        95\n",
      "           1       0.52      0.65      0.58       113\n",
      "\n",
      "    accuracy                           0.48       208\n",
      "   macro avg       0.46      0.46      0.45       208\n",
      "weighted avg       0.46      0.48      0.46       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5432692307692307 and f1 score is: 0.5299602749827541\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.41      0.45        95\n",
      "           1       0.57      0.65      0.61       113\n",
      "\n",
      "    accuracy                           0.54       208\n",
      "   macro avg       0.53      0.53      0.53       208\n",
      "weighted avg       0.54      0.54      0.54       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1105.csv ---\n",
      "[14:50:49] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5192307692307693 and f1 score is: 0.5026303204208512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.37      0.41        95\n",
      "           1       0.55      0.65      0.59       113\n",
      "\n",
      "    accuracy                           0.52       208\n",
      "   macro avg       0.51      0.51      0.50       208\n",
      "weighted avg       0.51      0.52      0.51       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5384615384615384 and f1 score is: 0.5051055814414593\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.31      0.38        95\n",
      "           1       0.56      0.73      0.63       113\n",
      "\n",
      "    accuracy                           0.54       208\n",
      "   macro avg       0.52      0.52      0.51       208\n",
      "weighted avg       0.53      0.54      0.52       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8299319727891157 and f1 score is: 0.5217957059206246\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.12      0.14        16\n",
      "           1       0.90      0.92      0.91       131\n",
      "\n",
      "    accuracy                           0.83       147\n",
      "   macro avg       0.52      0.52      0.52       147\n",
      "weighted avg       0.81      0.83      0.82       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8231292517006803 and f1 score is: 0.5885012919896642\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.31      0.28        16\n",
      "           1       0.91      0.89      0.90       131\n",
      "\n",
      "    accuracy                           0.82       147\n",
      "   macro avg       0.58      0.60      0.59       147\n",
      "weighted avg       0.84      0.82      0.83       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7551020408163265 and f1 score is: 0.5518292682926829\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.38      0.25        16\n",
      "           1       0.91      0.80      0.85       131\n",
      "\n",
      "    accuracy                           0.76       147\n",
      "   macro avg       0.55      0.59      0.55       147\n",
      "weighted avg       0.83      0.76      0.79       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.4557823129251701 and f1 score is: 0.39950980392156865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.69      0.22        16\n",
      "           1       0.92      0.43      0.58       131\n",
      "\n",
      "    accuracy                           0.46       147\n",
      "   macro avg       0.52      0.56      0.40       147\n",
      "weighted avg       0.83      0.46      0.54       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.891156462585034 and f1 score is: 0.637037037037037\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.25      0.33        16\n",
      "           1       0.91      0.97      0.94       131\n",
      "\n",
      "    accuracy                           0.89       147\n",
      "   macro avg       0.71      0.61      0.64       147\n",
      "weighted avg       0.87      0.89      0.87       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.41496598639455784 and f1 score is: 0.37539525691699605\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.75      0.22        16\n",
      "           1       0.92      0.37      0.53       131\n",
      "\n",
      "    accuracy                           0.41       147\n",
      "   macro avg       0.53      0.56      0.38       147\n",
      "weighted avg       0.84      0.41      0.50       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1106.csv ---\n",
      "[14:52:57] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8367346938775511 and f1 score is: 0.5545454545454546\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.19      0.20        16\n",
      "           1       0.90      0.92      0.91       131\n",
      "\n",
      "    accuracy                           0.84       147\n",
      "   macro avg       0.56      0.55      0.55       147\n",
      "weighted avg       0.83      0.84      0.83       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7891156462585034 and f1 score is: 0.5606863973778078\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.31      0.24        16\n",
      "           1       0.91      0.85      0.88       131\n",
      "\n",
      "    accuracy                           0.79       147\n",
      "   macro avg       0.55      0.58      0.56       147\n",
      "weighted avg       0.83      0.79      0.81       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5310734463276836 and f1 score is: 0.35748961294555004\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02        84\n",
      "           1       0.53      1.00      0.69        93\n",
      "\n",
      "    accuracy                           0.53       177\n",
      "   macro avg       0.76      0.51      0.36       177\n",
      "weighted avg       0.75      0.53      0.37       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4971751412429379 and f1 score is: 0.4948532948532949\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.60      0.53        84\n",
      "           1       0.53      0.41      0.46        93\n",
      "\n",
      "    accuracy                           0.50       177\n",
      "   macro avg       0.50      0.50      0.49       177\n",
      "weighted avg       0.50      0.50      0.49       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5875706214689266 and f1 score is: 0.5604055387337121\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.36      0.45        84\n",
      "           1       0.58      0.80      0.67        93\n",
      "\n",
      "    accuracy                           0.59       177\n",
      "   macro avg       0.60      0.58      0.56       177\n",
      "weighted avg       0.59      0.59      0.57       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5254237288135594 and f1 score is: 0.5219907407407407\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.46      0.48        84\n",
      "           1       0.55      0.58      0.56        93\n",
      "\n",
      "    accuracy                           0.53       177\n",
      "   macro avg       0.52      0.52      0.52       177\n",
      "weighted avg       0.52      0.53      0.52       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4463276836158192 and f1 score is: 0.4350573215216258\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.62      0.51        84\n",
      "           1       0.46      0.29      0.36        93\n",
      "\n",
      "    accuracy                           0.45       177\n",
      "   macro avg       0.45      0.45      0.44       177\n",
      "weighted avg       0.45      0.45      0.43       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5141242937853108 and f1 score is: 0.48657582298974633\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.30      0.37        84\n",
      "           1       0.53      0.71      0.61        93\n",
      "\n",
      "    accuracy                           0.51       177\n",
      "   macro avg       0.50      0.50      0.49       177\n",
      "weighted avg       0.51      0.51      0.49       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1175.csv ---\n",
      "[14:55:01] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5649717514124294 and f1 score is: 0.5084929135562047\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.24      0.34        84\n",
      "           1       0.56      0.86      0.68        93\n",
      "\n",
      "    accuracy                           0.56       177\n",
      "   macro avg       0.58      0.55      0.51       177\n",
      "weighted avg       0.58      0.56      0.52       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.536723163841808 and f1 score is: 0.5365900383141764\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.58      0.54        84\n",
      "           1       0.57      0.49      0.53        93\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.54      0.54      0.54       177\n",
      "weighted avg       0.54      0.54      0.54       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5509259259259259 and f1 score is: 0.4686414242600999\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.15      0.26       113\n",
      "           1       0.52      0.99      0.68       103\n",
      "\n",
      "    accuracy                           0.55       216\n",
      "   macro avg       0.73      0.57      0.47       216\n",
      "weighted avg       0.74      0.55      0.46       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5092592592592593 and f1 score is: 0.49824684431977556\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.63      0.57       113\n",
      "           1       0.48      0.38      0.42       103\n",
      "\n",
      "    accuracy                           0.51       216\n",
      "   macro avg       0.50      0.50      0.50       216\n",
      "weighted avg       0.50      0.51      0.50       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6203703703703703 and f1 score is: 0.6006493506493507\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.38      0.51       113\n",
      "           1       0.57      0.88      0.69       103\n",
      "\n",
      "    accuracy                           0.62       216\n",
      "   macro avg       0.67      0.63      0.60       216\n",
      "weighted avg       0.68      0.62      0.60       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6157407407407407 and f1 score is: 0.6120740019474196\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65       113\n",
      "           1       0.61      0.54      0.57       103\n",
      "\n",
      "    accuracy                           0.62       216\n",
      "   macro avg       0.61      0.61      0.61       216\n",
      "weighted avg       0.62      0.62      0.61       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5046296296296297 and f1 score is: 0.4927908354730397\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.63      0.57       113\n",
      "           1       0.47      0.37      0.42       103\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.50      0.50      0.49       216\n",
      "weighted avg       0.50      0.50      0.50       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.49074074074074076 and f1 score is: 0.490566037735849\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.49      0.50       113\n",
      "           1       0.47      0.50      0.48       103\n",
      "\n",
      "    accuracy                           0.49       216\n",
      "   macro avg       0.49      0.49      0.49       216\n",
      "weighted avg       0.49      0.49      0.49       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1337.csv ---\n",
      "[14:57:05] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6111111111111112 and f1 score is: 0.5761935905820798\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.31      0.45       113\n",
      "           1       0.55      0.94      0.70       103\n",
      "\n",
      "    accuracy                           0.61       216\n",
      "   macro avg       0.70      0.63      0.58       216\n",
      "weighted avg       0.71      0.61      0.57       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5787037037037037 and f1 score is: 0.5173717681145186\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.21      0.35       113\n",
      "           1       0.53      0.98      0.69       103\n",
      "\n",
      "    accuracy                           0.58       216\n",
      "   macro avg       0.73      0.60      0.52       216\n",
      "weighted avg       0.74      0.58      0.51       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5070422535211268 and f1 score is: 0.45468509984639016\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.22      0.29        95\n",
      "           1       0.54      0.74      0.62       118\n",
      "\n",
      "    accuracy                           0.51       213\n",
      "   macro avg       0.47      0.48      0.45       213\n",
      "weighted avg       0.48      0.51      0.47       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.49765258215962443 and f1 score is: 0.4888191095659975\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.71      0.56        95\n",
      "           1       0.58      0.33      0.42       118\n",
      "\n",
      "    accuracy                           0.50       213\n",
      "   macro avg       0.52      0.52      0.49       213\n",
      "weighted avg       0.53      0.50      0.48       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5164319248826291 and f1 score is: 0.46844183849005405\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.92      0.63        95\n",
      "           1       0.74      0.19      0.31       118\n",
      "\n",
      "    accuracy                           0.52       213\n",
      "   macro avg       0.61      0.56      0.47       213\n",
      "weighted avg       0.62      0.52      0.45       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5211267605633803 and f1 score is: 0.5133064516129032\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.73      0.57        95\n",
      "           1       0.62      0.36      0.45       118\n",
      "\n",
      "    accuracy                           0.52       213\n",
      "   macro avg       0.55      0.54      0.51       213\n",
      "weighted avg       0.55      0.52      0.51       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.4647887323943662 and f1 score is: 0.434881772481847\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.78      0.56        95\n",
      "           1       0.54      0.21      0.30       118\n",
      "\n",
      "    accuracy                           0.46       213\n",
      "   macro avg       0.49      0.50      0.43       213\n",
      "weighted avg       0.50      0.46      0.42       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.47417840375586856 and f1 score is: 0.39513184584178496\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.94      0.61        95\n",
      "           1       0.67      0.10      0.18       118\n",
      "\n",
      "    accuracy                           0.47       213\n",
      "   macro avg       0.56      0.52      0.40       213\n",
      "weighted avg       0.57      0.47      0.37       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1390.csv ---\n",
      "[14:59:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5446009389671361 and f1 score is: 0.5420167135858843\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.53      0.51        95\n",
      "           1       0.59      0.56      0.58       118\n",
      "\n",
      "    accuracy                           0.54       213\n",
      "   macro avg       0.54      0.54      0.54       213\n",
      "weighted avg       0.55      0.54      0.55       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5211267605633803 and f1 score is: 0.5210317460317461\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.57      0.51        95\n",
      "           1       0.58      0.48      0.53       118\n",
      "\n",
      "    accuracy                           0.52       213\n",
      "   macro avg       0.53      0.53      0.52       213\n",
      "weighted avg       0.53      0.52      0.52       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6285714285714286 and f1 score is: 0.3859649122807018\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.97      0.77       136\n",
      "           1       0.00      0.00      0.00        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.32      0.49      0.39       210\n",
      "weighted avg       0.41      0.63      0.50       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5238095238095238 and f1 score is: 0.4476010101010101\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       136\n",
      "           1       0.28      0.22      0.24        74\n",
      "\n",
      "    accuracy                           0.52       210\n",
      "   macro avg       0.45      0.45      0.45       210\n",
      "weighted avg       0.50      0.52      0.51       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5571428571428572 and f1 score is: 0.4168582604281748\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       136\n",
      "           1       0.21      0.09      0.13        74\n",
      "\n",
      "    accuracy                           0.56       210\n",
      "   macro avg       0.42      0.45      0.42       210\n",
      "weighted avg       0.48      0.56      0.50       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5619047619047619 and f1 score is: 0.5200715421303657\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       136\n",
      "           1       0.38      0.38      0.38        74\n",
      "\n",
      "    accuracy                           0.56       210\n",
      "   macro avg       0.52      0.52      0.52       210\n",
      "weighted avg       0.56      0.56      0.56       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5476190476190477 and f1 score is: 0.4043175778567376\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70       136\n",
      "           1       0.18      0.08      0.11        74\n",
      "\n",
      "    accuracy                           0.55       210\n",
      "   macro avg       0.40      0.44      0.40       210\n",
      "weighted avg       0.46      0.55      0.49       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5761904761904761 and f1 score is: 0.5214931257840703\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68       136\n",
      "           1       0.38      0.34      0.36        74\n",
      "\n",
      "    accuracy                           0.58       210\n",
      "   macro avg       0.52      0.52      0.52       210\n",
      "weighted avg       0.56      0.58      0.57       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1400.csv ---\n",
      "[15:01:11] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6 and f1 score is: 0.5193984306887532\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.78      0.72       136\n",
      "           1       0.40      0.27      0.32        74\n",
      "\n",
      "    accuracy                           0.60       210\n",
      "   macro avg       0.53      0.52      0.52       210\n",
      "weighted avg       0.57      0.60      0.58       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6285714285714286 and f1 score is: 0.4297451608411085\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.94      0.77       136\n",
      "           1       0.33      0.05      0.09        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.49      0.50      0.43       210\n",
      "weighted avg       0.54      0.63      0.53       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.45794392523364486 and f1 score is: 0.45561403508771925\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.59      0.49        95\n",
      "           1       0.52      0.35      0.42       119\n",
      "\n",
      "    accuracy                           0.46       214\n",
      "   macro avg       0.47      0.47      0.46       214\n",
      "weighted avg       0.48      0.46      0.45       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.4766355140186916 and f1 score is: 0.44379467186484733\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.81      0.58        95\n",
      "           1       0.58      0.21      0.31       119\n",
      "\n",
      "    accuracy                           0.48       214\n",
      "   macro avg       0.52      0.51      0.44       214\n",
      "weighted avg       0.52      0.48      0.43       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.43457943925233644 and f1 score is: 0.42908168889868814\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.60      0.49        95\n",
      "           1       0.49      0.30      0.37       119\n",
      "\n",
      "    accuracy                           0.43       214\n",
      "   macro avg       0.45      0.45      0.43       214\n",
      "weighted avg       0.45      0.43      0.42       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.514018691588785 and f1 score is: 0.4964250158385375\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.79      0.59        95\n",
      "           1       0.64      0.29      0.40       119\n",
      "\n",
      "    accuracy                           0.51       214\n",
      "   macro avg       0.55      0.54      0.50       214\n",
      "weighted avg       0.56      0.51      0.49       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.46261682242990654 and f1 score is: 0.4184095474418055\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.83      0.58        95\n",
      "           1       0.56      0.17      0.26       119\n",
      "\n",
      "    accuracy                           0.46       214\n",
      "   macro avg       0.50      0.50      0.42       214\n",
      "weighted avg       0.51      0.46      0.40       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5233644859813084 and f1 score is: 0.5162234042553191\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.73      0.57        95\n",
      "           1       0.62      0.36      0.46       119\n",
      "\n",
      "    accuracy                           0.52       214\n",
      "   macro avg       0.55      0.54      0.52       214\n",
      "weighted avg       0.56      0.52      0.51       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1419.csv ---\n",
      "[15:03:12] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5186915887850467 and f1 score is: 0.514867392978981\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.48      0.47        95\n",
      "           1       0.57      0.55      0.56       119\n",
      "\n",
      "    accuracy                           0.52       214\n",
      "   macro avg       0.52      0.52      0.51       214\n",
      "weighted avg       0.52      0.52      0.52       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.48598130841121495 and f1 score is: 0.48485644257703076\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.60      0.51        95\n",
      "           1       0.55      0.39      0.46       119\n",
      "\n",
      "    accuracy                           0.49       214\n",
      "   macro avg       0.50      0.50      0.48       214\n",
      "weighted avg       0.50      0.49      0.48       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.2839506172839506 and f1 score is: 0.25095663265306123\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.09       122\n",
      "           1       0.26      1.00      0.41        40\n",
      "\n",
      "    accuracy                           0.28       162\n",
      "   macro avg       0.63      0.52      0.25       162\n",
      "weighted avg       0.82      0.28      0.17       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.3765432098765432 and f1 score is: 0.3746130030959752\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.21      0.34       122\n",
      "           1       0.27      0.88      0.41        40\n",
      "\n",
      "    accuracy                           0.38       162\n",
      "   macro avg       0.55      0.54      0.37       162\n",
      "weighted avg       0.70      0.38      0.36       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.4012345679012346 and f1 score is: 0.400663640871124\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.29      0.42       122\n",
      "           1       0.26      0.75      0.38        40\n",
      "\n",
      "    accuracy                           0.40       162\n",
      "   macro avg       0.52      0.52      0.40       162\n",
      "weighted avg       0.65      0.40      0.41       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.30864197530864196 and f1 score is: 0.2931276297335203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.11      0.19       122\n",
      "           1       0.25      0.93      0.40        40\n",
      "\n",
      "    accuracy                           0.31       162\n",
      "   macro avg       0.53      0.52      0.29       162\n",
      "weighted avg       0.67      0.31      0.24       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.43209876543209874 and f1 score is: 0.4317523257587311\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.30      0.45       122\n",
      "           1       0.28      0.82      0.42        40\n",
      "\n",
      "    accuracy                           0.43       162\n",
      "   macro avg       0.56      0.56      0.43       162\n",
      "weighted avg       0.70      0.43      0.44       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.2962962962962963 and f1 score is: 0.26772402854877075\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.12       122\n",
      "           1       0.26      1.00      0.41        40\n",
      "\n",
      "    accuracy                           0.30       162\n",
      "   macro avg       0.63      0.53      0.27       162\n",
      "weighted avg       0.82      0.30      0.19       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1517.csv ---\n",
      "[15:05:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.46296296296296297 and f1 score is: 0.4604754430961222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.35      0.50       122\n",
      "           1       0.29      0.80      0.42        40\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.57      0.58      0.46       162\n",
      "weighted avg       0.71      0.46      0.48       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.3395061728395062 and f1 score is: 0.3364468093251158\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.18      0.29       122\n",
      "           1       0.25      0.82      0.38        40\n",
      "\n",
      "    accuracy                           0.34       162\n",
      "   macro avg       0.50      0.50      0.34       162\n",
      "weighted avg       0.63      0.34      0.31       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.5869565217391305 and f1 score is: 0.4138162307176391\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.10      0.10        10\n",
      "           1       0.74      0.72      0.73        36\n",
      "\n",
      "    accuracy                           0.59        46\n",
      "   macro avg       0.42      0.41      0.41        46\n",
      "weighted avg       0.60      0.59      0.59        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.21739130434782608 and f1 score is: 0.1929824561403509\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.90      0.33        10\n",
      "           1       0.50      0.03      0.05        36\n",
      "\n",
      "    accuracy                           0.22        46\n",
      "   macro avg       0.35      0.46      0.19        46\n",
      "weighted avg       0.44      0.22      0.11        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6086956521739131 and f1 score is: 0.5174825174825175\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.40      0.31        10\n",
      "           1       0.80      0.67      0.73        36\n",
      "\n",
      "    accuracy                           0.61        46\n",
      "   macro avg       0.53      0.53      0.52        46\n",
      "weighted avg       0.68      0.61      0.64        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.45652173913043476 and f1 score is: 0.4562647754137116\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.44        10\n",
      "           1       1.00      0.31      0.47        36\n",
      "\n",
      "    accuracy                           0.46        46\n",
      "   macro avg       0.64      0.65      0.46        46\n",
      "weighted avg       0.84      0.46      0.46        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.21739130434782608 and f1 score is: 0.17857142857142855\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36        10\n",
      "           1       1.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.22        46\n",
      "   macro avg       0.61      0.50      0.18        46\n",
      "weighted avg       0.83      0.22      0.08        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6521739130434783 and f1 score is: 0.5490196078431372\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33        10\n",
      "           1       0.81      0.72      0.76        36\n",
      "\n",
      "    accuracy                           0.65        46\n",
      "   macro avg       0.55      0.56      0.55        46\n",
      "weighted avg       0.70      0.65      0.67        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1544.csv ---\n",
      "[15:07:24] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.5217391304347826 and f1 score is: 0.47291666666666665\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.50      0.31        10\n",
      "           1       0.79      0.53      0.63        36\n",
      "\n",
      "    accuracy                           0.52        46\n",
      "   macro avg       0.51      0.51      0.47        46\n",
      "weighted avg       0.67      0.52      0.56        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.45652173913043476 and f1 score is: 0.3134328358208955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.68      0.58      0.63        36\n",
      "\n",
      "    accuracy                           0.46        46\n",
      "   macro avg       0.34      0.29      0.31        46\n",
      "weighted avg       0.53      0.46      0.49        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5849056603773585 and f1 score is: 0.561140849782536\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.38      0.46        73\n",
      "           1       0.59      0.76      0.66        86\n",
      "\n",
      "    accuracy                           0.58       159\n",
      "   macro avg       0.58      0.57      0.56       159\n",
      "weighted avg       0.58      0.58      0.57       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5660377358490566 and f1 score is: 0.49398090493980906\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.21      0.30        73\n",
      "           1       0.56      0.87      0.68        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.57      0.54      0.49       159\n",
      "weighted avg       0.57      0.57      0.51       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.4968553459119497 and f1 score is: 0.49523809523809526\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.48      0.47        73\n",
      "           1       0.54      0.51      0.52        86\n",
      "\n",
      "    accuracy                           0.50       159\n",
      "   macro avg       0.50      0.50      0.50       159\n",
      "weighted avg       0.50      0.50      0.50       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5408805031446541 and f1 score is: 0.3745217438163497\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.03      0.05        73\n",
      "           1       0.54      0.98      0.70        86\n",
      "\n",
      "    accuracy                           0.54       159\n",
      "   macro avg       0.52      0.50      0.37       159\n",
      "weighted avg       0.52      0.54      0.40       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5471698113207547 and f1 score is: 0.43438735177865617\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.11      0.18        73\n",
      "           1       0.55      0.92      0.69        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.54      0.51      0.43       159\n",
      "weighted avg       0.54      0.55      0.46       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5283018867924528 and f1 score is: 0.42271385002662537\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.11      0.18        73\n",
      "           1       0.54      0.88      0.67        86\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.49      0.50      0.42       159\n",
      "weighted avg       0.50      0.53      0.44       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1624.csv ---\n",
      "[15:09:31] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5408805031446541 and f1 score is: 0.5130679196207576\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40        73\n",
      "           1       0.56      0.72      0.63        86\n",
      "\n",
      "    accuracy                           0.54       159\n",
      "   macro avg       0.53      0.52      0.51       159\n",
      "weighted avg       0.53      0.54      0.52       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.49056603773584906 and f1 score is: 0.4717607973421927\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.33      0.37        73\n",
      "           1       0.52      0.63      0.57        86\n",
      "\n",
      "    accuracy                           0.49       159\n",
      "   macro avg       0.48      0.48      0.47       159\n",
      "weighted avg       0.48      0.49      0.48       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6685082872928176 and f1 score is: 0.40066225165562913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        60\n",
      "           1       0.67      1.00      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.83      0.50      0.40       181\n",
      "weighted avg       0.78      0.67      0.54       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6740331491712708 and f1 score is: 0.4330838243881722\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.03      0.06        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.67      0.51      0.43       181\n",
      "weighted avg       0.67      0.67      0.56       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6740331491712708 and f1 score is: 0.47178117425928673\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.08      0.14        60\n",
      "           1       0.68      0.97      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.62      0.53      0.47       181\n",
      "weighted avg       0.64      0.67      0.58       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6077348066298343 and f1 score is: 0.5124995258146504\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.25      0.30        60\n",
      "           1       0.68      0.79      0.73       121\n",
      "\n",
      "    accuracy                           0.61       181\n",
      "   macro avg       0.52      0.52      0.51       181\n",
      "weighted avg       0.57      0.61      0.59       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6574585635359116 and f1 score is: 0.39666666666666667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.66      0.98      0.79       121\n",
      "\n",
      "    accuracy                           0.66       181\n",
      "   macro avg       0.33      0.49      0.40       181\n",
      "weighted avg       0.44      0.66      0.53       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6519337016574586 and f1 score is: 0.3946488294314381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.66      0.98      0.79       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.33      0.49      0.39       181\n",
      "weighted avg       0.44      0.65      0.53       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1688.csv ---\n",
      "[15:11:34] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6464088397790055 and f1 score is: 0.5401714830104796\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.25      0.32        60\n",
      "           1       0.69      0.84      0.76       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.57      0.55      0.54       181\n",
      "weighted avg       0.61      0.65      0.61       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6022099447513812 and f1 score is: 0.5249343832020997\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.30      0.33        60\n",
      "           1       0.68      0.75      0.72       121\n",
      "\n",
      "    accuracy                           0.60       181\n",
      "   macro avg       0.53      0.53      0.52       181\n",
      "weighted avg       0.58      0.60      0.59       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6944444444444444 and f1 score is: 0.46187528310433335\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.06      0.11        34\n",
      "           1       0.70      0.99      0.82        74\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.68      0.52      0.46       108\n",
      "weighted avg       0.69      0.69      0.59       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.42592592592592593 and f1 score is: 0.42096160498097546\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.53      0.37        34\n",
      "           1       0.64      0.38      0.47        74\n",
      "\n",
      "    accuracy                           0.43       108\n",
      "   macro avg       0.46      0.45      0.42       108\n",
      "weighted avg       0.52      0.43      0.44       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5370370370370371 and f1 score is: 0.4634340222575517\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.26      0.26        34\n",
      "           1       0.66      0.66      0.66        74\n",
      "\n",
      "    accuracy                           0.54       108\n",
      "   macro avg       0.46      0.46      0.46       108\n",
      "weighted avg       0.54      0.54      0.54       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5370370370370371 and f1 score is: 0.4983277591973244\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.41      0.36        34\n",
      "           1       0.69      0.59      0.64        74\n",
      "\n",
      "    accuracy                           0.54       108\n",
      "   macro avg       0.50      0.50      0.50       108\n",
      "weighted avg       0.57      0.54      0.55       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.4166666666666667 and f1 score is: 0.4142057684029272\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.56      0.38        34\n",
      "           1       0.63      0.35      0.45        74\n",
      "\n",
      "    accuracy                           0.42       108\n",
      "   macro avg       0.46      0.46      0.41       108\n",
      "weighted avg       0.52      0.42      0.43       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.7037037037037037 and f1 score is: 0.5947467166979362\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.29      0.38        34\n",
      "           1       0.73      0.89      0.80        74\n",
      "\n",
      "    accuracy                           0.70       108\n",
      "   macro avg       0.64      0.59      0.59       108\n",
      "weighted avg       0.68      0.70      0.67       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1717.csv ---\n",
      "[15:13:39] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.7037037037037037 and f1 score is: 0.5270935960591133\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.15      0.24        34\n",
      "           1       0.71      0.96      0.82        74\n",
      "\n",
      "    accuracy                           0.70       108\n",
      "   macro avg       0.67      0.55      0.53       108\n",
      "weighted avg       0.68      0.70      0.63       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6759259259259259 and f1 score is: 0.5508021390374332\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.24      0.31        34\n",
      "           1       0.71      0.88      0.79        74\n",
      "\n",
      "    accuracy                           0.68       108\n",
      "   macro avg       0.59      0.56      0.55       108\n",
      "weighted avg       0.64      0.68      0.64       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5061728395061729 and f1 score is: 0.45417789757412397\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.19      0.29        86\n",
      "           1       0.49      0.87      0.62        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.55      0.53      0.45       162\n",
      "weighted avg       0.55      0.51      0.44       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5123456790123457 and f1 score is: 0.4538937486665245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.17      0.28        86\n",
      "           1       0.49      0.89      0.63        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.57      0.53      0.45       162\n",
      "weighted avg       0.58      0.51      0.44       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.47530864197530864 and f1 score is: 0.42708550031204495\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.17      0.26        86\n",
      "           1       0.47      0.82      0.59        76\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.49      0.50      0.43       162\n",
      "weighted avg       0.49      0.48      0.42       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.47530864197530864 and f1 score is: 0.4430287586457954\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.22      0.31        86\n",
      "           1       0.46      0.76      0.58        76\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.49      0.49      0.44       162\n",
      "weighted avg       0.49      0.48      0.43       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5308641975308642 and f1 score is: 0.4722222222222222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.19      0.30        86\n",
      "           1       0.50      0.92      0.65        76\n",
      "\n",
      "    accuracy                           0.53       162\n",
      "   macro avg       0.61      0.55      0.47       162\n",
      "weighted avg       0.62      0.53      0.46       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4012345679012346 and f1 score is: 0.3841269841269841\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.22      0.28        86\n",
      "           1       0.41      0.61      0.49        76\n",
      "\n",
      "    accuracy                           0.40       162\n",
      "   macro avg       0.40      0.41      0.38       162\n",
      "weighted avg       0.40      0.40      0.38       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1765.csv ---\n",
      "[15:15:44] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5185185185185185 and f1 score is: 0.4678234501347709\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.20      0.30        86\n",
      "           1       0.49      0.88      0.63        76\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.57      0.54      0.47       162\n",
      "weighted avg       0.58      0.52      0.46       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5061728395061729 and f1 score is: 0.48612212529738297\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.29      0.38        86\n",
      "           1       0.48      0.75      0.59        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.53      0.52      0.49       162\n",
      "weighted avg       0.53      0.51      0.48       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.660377358490566 and f1 score is: 0.4557124518613607\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.31      0.12        16\n",
      "           1       0.92      0.69      0.79       196\n",
      "\n",
      "    accuracy                           0.66       212\n",
      "   macro avg       0.50      0.50      0.46       212\n",
      "weighted avg       0.86      0.66      0.74       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.5283018867924528 and f1 score is: 0.4246010205189447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.69      0.18        16\n",
      "           1       0.95      0.52      0.67       196\n",
      "\n",
      "    accuracy                           0.53       212\n",
      "   macro avg       0.53      0.60      0.42       212\n",
      "weighted avg       0.89      0.53      0.63       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6320754716981132 and f1 score is: 0.46692456479690525\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.50      0.17        16\n",
      "           1       0.94      0.64      0.76       196\n",
      "\n",
      "    accuracy                           0.63       212\n",
      "   macro avg       0.52      0.57      0.47       212\n",
      "weighted avg       0.88      0.63      0.72       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.589622641509434 and f1 score is: 0.4346320080924501\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.44      0.14        16\n",
      "           1       0.93      0.60      0.73       196\n",
      "\n",
      "    accuracy                           0.59       212\n",
      "   macro avg       0.51      0.52      0.43       212\n",
      "weighted avg       0.87      0.59      0.69       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8301886792452831 and f1 score is: 0.5435406698564593\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.25      0.18        16\n",
      "           1       0.93      0.88      0.91       196\n",
      "\n",
      "    accuracy                           0.83       212\n",
      "   macro avg       0.54      0.56      0.54       212\n",
      "weighted avg       0.88      0.83      0.85       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.30660377358490565 and f1 score is: 0.2738880216221254\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.62      0.12        16\n",
      "           1       0.90      0.28      0.43       196\n",
      "\n",
      "    accuracy                           0.31       212\n",
      "   macro avg       0.48      0.45      0.27       212\n",
      "weighted avg       0.84      0.31      0.40       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1818.csv ---\n",
      "[15:17:49] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.660377358490566 and f1 score is: 0.47488647309756427\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.44      0.16        16\n",
      "           1       0.94      0.68      0.79       196\n",
      "\n",
      "    accuracy                           0.66       212\n",
      "   macro avg       0.52      0.56      0.47       212\n",
      "weighted avg       0.87      0.66      0.74       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.4056603773584906 and f1 score is: 0.33293377284986514\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.50      0.11        16\n",
      "           1       0.91      0.40      0.55       196\n",
      "\n",
      "    accuracy                           0.41       212\n",
      "   macro avg       0.49      0.45      0.33       212\n",
      "weighted avg       0.84      0.41      0.52       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5185185185185185 and f1 score is: 0.44631765749778174\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.59      0.65       162\n",
      "           1       0.20      0.31      0.25        54\n",
      "\n",
      "    accuracy                           0.52       216\n",
      "   macro avg       0.46      0.45      0.45       216\n",
      "weighted avg       0.59      0.52      0.55       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.41203703703703703 and f1 score is: 0.39426325435555454\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.39      0.50       162\n",
      "           1       0.21      0.48      0.29        54\n",
      "\n",
      "    accuracy                           0.41       216\n",
      "   macro avg       0.45      0.44      0.39       216\n",
      "weighted avg       0.57      0.41      0.45       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5 and f1 score is: 0.46114755613046293\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.51      0.61       162\n",
      "           1       0.24      0.46      0.32        54\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.49      0.49      0.46       216\n",
      "weighted avg       0.62      0.50      0.53       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.49537037037037035 and f1 score is: 0.4416486826191097\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.54      0.61       162\n",
      "           1       0.21      0.37      0.27        54\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.46      0.45      0.44       216\n",
      "weighted avg       0.59      0.50      0.53       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.39814814814814814 and f1 score is: 0.38786187652598536\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.35      0.47       162\n",
      "           1       0.22      0.54      0.31        54\n",
      "\n",
      "    accuracy                           0.40       216\n",
      "   macro avg       0.46      0.44      0.39       216\n",
      "weighted avg       0.58      0.40      0.43       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4305555555555556 and f1 score is: 0.4169464744222793\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.39      0.51       162\n",
      "           1       0.23      0.56      0.33        54\n",
      "\n",
      "    accuracy                           0.43       216\n",
      "   macro avg       0.48      0.47      0.42       216\n",
      "weighted avg       0.60      0.43      0.46       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1892.csv ---\n",
      "[15:19:57] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5046296296296297 and f1 score is: 0.45189366091967653\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.54      0.62       162\n",
      "           1       0.22      0.39      0.28        54\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.47      0.47      0.45       216\n",
      "weighted avg       0.60      0.50      0.54       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.6342592592592593 and f1 score is: 0.49644406409537584\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       162\n",
      "           1       0.24      0.22      0.23        54\n",
      "\n",
      "    accuracy                           0.63       216\n",
      "   macro avg       0.50      0.50      0.50       216\n",
      "weighted avg       0.62      0.63      0.63       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.4669811320754717 and f1 score is: 0.4616992112891266\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.60      0.41        65\n",
      "           1       0.70      0.41      0.52       147\n",
      "\n",
      "    accuracy                           0.47       212\n",
      "   macro avg       0.50      0.50      0.46       212\n",
      "weighted avg       0.58      0.47      0.48       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.3632075471698113 and f1 score is: 0.36308000445087346\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.57      0.35        65\n",
      "           1       0.59      0.27      0.37       147\n",
      "\n",
      "    accuracy                           0.36       212\n",
      "   macro avg       0.42      0.42      0.36       212\n",
      "weighted avg       0.49      0.36      0.37       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.4811320754716981 and f1 score is: 0.47885939036381514\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.68      0.44        65\n",
      "           1       0.73      0.39      0.51       147\n",
      "\n",
      "    accuracy                           0.48       212\n",
      "   macro avg       0.53      0.54      0.48       212\n",
      "weighted avg       0.61      0.48      0.49       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5141509433962265 and f1 score is: 0.47909062716190753\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.42      0.34        65\n",
      "           1       0.68      0.56      0.61       147\n",
      "\n",
      "    accuracy                           0.51       212\n",
      "   macro avg       0.49      0.49      0.48       212\n",
      "weighted avg       0.56      0.51      0.53       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.41509433962264153 and f1 score is: 0.40471014492753626\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.46      0.33        65\n",
      "           1       0.62      0.39      0.48       147\n",
      "\n",
      "    accuracy                           0.42       212\n",
      "   macro avg       0.44      0.43      0.40       212\n",
      "weighted avg       0.51      0.42      0.44       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.32075471698113206 and f1 score is: 0.28074639525021206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.91      0.45        65\n",
      "           1       0.60      0.06      0.11       147\n",
      "\n",
      "    accuracy                           0.32       212\n",
      "   macro avg       0.45      0.48      0.28       212\n",
      "weighted avg       0.51      0.32      0.22       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1929.csv ---\n",
      "[15:21:59] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.419811320754717 and f1 score is: 0.4197984113210066\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.69      0.42        65\n",
      "           1       0.69      0.30      0.42       147\n",
      "\n",
      "    accuracy                           0.42       212\n",
      "   macro avg       0.50      0.50      0.42       212\n",
      "weighted avg       0.57      0.42      0.42       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.38207547169811323 and f1 score is: 0.38206172262643795\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.63      0.38        65\n",
      "           1       0.62      0.27      0.38       147\n",
      "\n",
      "    accuracy                           0.38       212\n",
      "   macro avg       0.45      0.45      0.38       212\n",
      "weighted avg       0.52      0.38      0.38       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5306122448979592 and f1 score is: 0.4950716845878136\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.36      0.36        36\n",
      "           1       0.63      0.63      0.63        62\n",
      "\n",
      "    accuracy                           0.53        98\n",
      "   macro avg       0.50      0.50      0.50        98\n",
      "weighted avg       0.53      0.53      0.53        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6224489795918368 and f1 score is: 0.580469744301747\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.42      0.45        36\n",
      "           1       0.69      0.74      0.71        62\n",
      "\n",
      "    accuracy                           0.62        98\n",
      "   macro avg       0.59      0.58      0.58        98\n",
      "weighted avg       0.61      0.62      0.62        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5510204081632653 and f1 score is: 0.5111111111111112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.36      0.37        36\n",
      "           1       0.64      0.66      0.65        62\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.51      0.51      0.51        98\n",
      "weighted avg       0.55      0.55      0.55        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5918367346938775 and f1 score is: 0.49999999999999994\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.22      0.29        36\n",
      "           1       0.64      0.81      0.71        62\n",
      "\n",
      "    accuracy                           0.59        98\n",
      "   macro avg       0.52      0.51      0.50        98\n",
      "weighted avg       0.55      0.59      0.56        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5918367346938775 and f1 score is: 0.5609318996415771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.44      0.44        36\n",
      "           1       0.68      0.68      0.68        62\n",
      "\n",
      "    accuracy                           0.59        98\n",
      "   macro avg       0.56      0.56      0.56        98\n",
      "weighted avg       0.59      0.59      0.59        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5510204081632653 and f1 score is: 0.4715686274509804\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.22      0.27        36\n",
      "           1       0.62      0.74      0.68        62\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.48      0.48      0.47        98\n",
      "weighted avg       0.52      0.55      0.53        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1933.csv ---\n",
      "[15:24:06] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5102040816326531 and f1 score is: 0.47895436420026594\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.36      0.35        36\n",
      "           1       0.62      0.60      0.61        62\n",
      "\n",
      "    accuracy                           0.51        98\n",
      "   macro avg       0.48      0.48      0.48        98\n",
      "weighted avg       0.52      0.51      0.51        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5306122448979592 and f1 score is: 0.5006645990252548\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.39      0.38        36\n",
      "           1       0.63      0.61      0.62        62\n",
      "\n",
      "    accuracy                           0.53        98\n",
      "   macro avg       0.50      0.50      0.50        98\n",
      "weighted avg       0.54      0.53      0.53        98\n",
      "\n",
      "----- Running Modality Combination ECG_GAZE\n",
      "Saved Directory: 2022_08_11_15_25\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5673076923076923 and f1 score is: 0.450187969924812\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.12      0.20        95\n",
      "           1       0.56      0.95      0.70       113\n",
      "\n",
      "    accuracy                           0.57       208\n",
      "   macro avg       0.60      0.53      0.45       208\n",
      "weighted avg       0.60      0.57      0.47       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5625 and f1 score is: 0.42036441586280815\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.07      0.13        95\n",
      "           1       0.56      0.97      0.71       113\n",
      "\n",
      "    accuracy                           0.56       208\n",
      "   macro avg       0.63      0.52      0.42       208\n",
      "weighted avg       0.62      0.56      0.45       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5480769230769231 and f1 score is: 0.5371212121212121\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.43      0.47        95\n",
      "           1       0.57      0.65      0.61       113\n",
      "\n",
      "    accuracy                           0.55       208\n",
      "   macro avg       0.54      0.54      0.54       208\n",
      "weighted avg       0.54      0.55      0.54       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6057692307692307 and f1 score is: 0.5045892877890089\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.17      0.28        95\n",
      "           1       0.58      0.97      0.73       113\n",
      "\n",
      "    accuracy                           0.61       208\n",
      "   macro avg       0.71      0.57      0.50       208\n",
      "weighted avg       0.70      0.61      0.52       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5721153846153846 and f1 score is: 0.43310365947021895\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.08      0.15        95\n",
      "           1       0.56      0.98      0.71       113\n",
      "\n",
      "    accuracy                           0.57       208\n",
      "   macro avg       0.68      0.53      0.43       208\n",
      "weighted avg       0.67      0.57      0.46       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6057692307692307 and f1 score is: 0.5873015873015873\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.43      0.50        95\n",
      "           1       0.61      0.75      0.67       113\n",
      "\n",
      "    accuracy                           0.61       208\n",
      "   macro avg       0.60      0.59      0.59       208\n",
      "weighted avg       0.60      0.61      0.59       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1105.csv ---\n",
      "[15:25:30] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6346153846153846 and f1 score is: 0.6038095238095238\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.39      0.49        95\n",
      "           1       0.62      0.84      0.71       113\n",
      "\n",
      "    accuracy                           0.63       208\n",
      "   macro avg       0.65      0.62      0.60       208\n",
      "weighted avg       0.64      0.63      0.61       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6057692307692307 and f1 score is: 0.5984934086629001\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.52      0.54        95\n",
      "           1       0.63      0.68      0.65       113\n",
      "\n",
      "    accuracy                           0.61       208\n",
      "   macro avg       0.60      0.60      0.60       208\n",
      "weighted avg       0.60      0.61      0.60       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.9115646258503401 and f1 score is: 0.6934060644954275\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.31      0.43        16\n",
      "           1       0.92      0.98      0.95       131\n",
      "\n",
      "    accuracy                           0.91       147\n",
      "   macro avg       0.82      0.65      0.69       147\n",
      "weighted avg       0.90      0.91      0.90       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.9115646258503401 and f1 score is: 0.7158364312267658\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.38      0.48        16\n",
      "           1       0.93      0.98      0.95       131\n",
      "\n",
      "    accuracy                           0.91       147\n",
      "   macro avg       0.80      0.68      0.72       147\n",
      "weighted avg       0.90      0.91      0.90       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8843537414965986 and f1 score is: 0.6748210800260248\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.38      0.41        16\n",
      "           1       0.93      0.95      0.94       131\n",
      "\n",
      "    accuracy                           0.88       147\n",
      "   macro avg       0.69      0.66      0.67       147\n",
      "weighted avg       0.87      0.88      0.88       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7687074829931972 and f1 score is: 0.5767276422764228\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.44      0.29        16\n",
      "           1       0.92      0.81      0.86       131\n",
      "\n",
      "    accuracy                           0.77       147\n",
      "   macro avg       0.57      0.62      0.58       147\n",
      "weighted avg       0.85      0.77      0.80       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.9047619047619048 and f1 score is: 0.7046498277841561\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.38      0.46        16\n",
      "           1       0.93      0.97      0.95       131\n",
      "\n",
      "    accuracy                           0.90       147\n",
      "   macro avg       0.76      0.67      0.70       147\n",
      "weighted avg       0.89      0.90      0.89       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7142857142857143 and f1 score is: 0.5489479836353011\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.28        16\n",
      "           1       0.92      0.74      0.82       131\n",
      "\n",
      "    accuracy                           0.71       147\n",
      "   macro avg       0.56      0.62      0.55       147\n",
      "weighted avg       0.84      0.71      0.76       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1106.csv ---\n",
      "[15:26:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8979591836734694 and f1 score is: 0.7295474058628726\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.50      0.52        16\n",
      "           1       0.94      0.95      0.94       131\n",
      "\n",
      "    accuracy                           0.90       147\n",
      "   macro avg       0.74      0.72      0.73       147\n",
      "weighted avg       0.90      0.90      0.90       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8571428571428571 and f1 score is: 0.6415882967607106\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.38      0.36        16\n",
      "           1       0.92      0.92      0.92       131\n",
      "\n",
      "    accuracy                           0.86       147\n",
      "   macro avg       0.64      0.65      0.64       147\n",
      "weighted avg       0.86      0.86      0.86       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.519774011299435 and f1 score is: 0.4422199977755533\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.15      0.23        84\n",
      "           1       0.53      0.85      0.65        93\n",
      "\n",
      "    accuracy                           0.52       177\n",
      "   macro avg       0.50      0.50      0.44       177\n",
      "weighted avg       0.51      0.52      0.45       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.559322033898305 and f1 score is: 0.46288515406162467\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.14      0.24        84\n",
      "           1       0.55      0.94      0.69        93\n",
      "\n",
      "    accuracy                           0.56       177\n",
      "   macro avg       0.61      0.54      0.46       177\n",
      "weighted avg       0.60      0.56      0.47       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5649717514124294 and f1 score is: 0.5126408010012516\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.25      0.35        84\n",
      "           1       0.56      0.85      0.67        93\n",
      "\n",
      "    accuracy                           0.56       177\n",
      "   macro avg       0.58      0.55      0.51       177\n",
      "weighted avg       0.58      0.56      0.52       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5932203389830508 and f1 score is: 0.5623626373626374\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.35      0.45        84\n",
      "           1       0.58      0.82      0.68        93\n",
      "\n",
      "    accuracy                           0.59       177\n",
      "   macro avg       0.61      0.58      0.56       177\n",
      "weighted avg       0.60      0.59      0.57       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.559322033898305 and f1 score is: 0.45645669291338575\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.13      0.22        84\n",
      "           1       0.55      0.95      0.69        93\n",
      "\n",
      "    accuracy                           0.56       177\n",
      "   macro avg       0.62      0.54      0.46       177\n",
      "weighted avg       0.61      0.56      0.47       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5819209039548022 and f1 score is: 0.5296610169491526\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.26      0.37        84\n",
      "           1       0.57      0.87      0.69        93\n",
      "\n",
      "    accuracy                           0.58       177\n",
      "   macro avg       0.61      0.57      0.53       177\n",
      "weighted avg       0.60      0.58      0.54       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1175.csv ---\n",
      "[15:27:12] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5141242937853108 and f1 score is: 0.49192256341789053\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.76      0.60        84\n",
      "           1       0.57      0.29      0.39        93\n",
      "\n",
      "    accuracy                           0.51       177\n",
      "   macro avg       0.53      0.53      0.49       177\n",
      "weighted avg       0.54      0.51      0.49       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5084745762711864 and f1 score is: 0.49393670511682936\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.71      0.58        84\n",
      "           1       0.56      0.32      0.41        93\n",
      "\n",
      "    accuracy                           0.51       177\n",
      "   macro avg       0.52      0.52      0.49       177\n",
      "weighted avg       0.52      0.51      0.49       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.49537037037037035 and f1 score is: 0.36117216117216117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.07       113\n",
      "           1       0.49      1.00      0.65       103\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.74      0.52      0.36       216\n",
      "weighted avg       0.75      0.50      0.35       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.49537037037037035 and f1 score is: 0.4174440183100334\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.12      0.20       113\n",
      "           1       0.48      0.90      0.63       103\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.53      0.51      0.42       216\n",
      "weighted avg       0.54      0.50      0.41       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.4398148148148148 and f1 score is: 0.40392729263119487\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.19      0.26       113\n",
      "           1       0.45      0.72      0.55       103\n",
      "\n",
      "    accuracy                           0.44       216\n",
      "   macro avg       0.43      0.45      0.40       216\n",
      "weighted avg       0.43      0.44      0.40       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.4722222222222222 and f1 score is: 0.3930789707187222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.11      0.17       113\n",
      "           1       0.47      0.87      0.61       103\n",
      "\n",
      "    accuracy                           0.47       216\n",
      "   macro avg       0.48      0.49      0.39       216\n",
      "weighted avg       0.48      0.47      0.38       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.4861111111111111 and f1 score is: 0.3919504958027948\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.09      0.15       113\n",
      "           1       0.48      0.92      0.63       103\n",
      "\n",
      "    accuracy                           0.49       216\n",
      "   macro avg       0.52      0.51      0.39       216\n",
      "weighted avg       0.52      0.49      0.38       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.4722222222222222 and f1 score is: 0.4178723404255319\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.16      0.24       113\n",
      "           1       0.47      0.82      0.60       103\n",
      "\n",
      "    accuracy                           0.47       216\n",
      "   macro avg       0.48      0.49      0.42       216\n",
      "weighted avg       0.48      0.47      0.41       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1337.csv ---\n",
      "[15:27:59] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5046296296296297 and f1 score is: 0.40333032141474123\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.09      0.16       113\n",
      "           1       0.49      0.96      0.65       103\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.60      0.52      0.40       216\n",
      "weighted avg       0.61      0.50      0.39       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5231481481481481 and f1 score is: 0.4577758280324633\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.17      0.27       113\n",
      "           1       0.50      0.91      0.65       103\n",
      "\n",
      "    accuracy                           0.52       216\n",
      "   macro avg       0.59      0.54      0.46       216\n",
      "weighted avg       0.59      0.52      0.45       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.6103286384976526 and f1 score is: 0.6081173940992619\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.60      0.58        95\n",
      "           1       0.66      0.62      0.64       118\n",
      "\n",
      "    accuracy                           0.61       213\n",
      "   macro avg       0.61      0.61      0.61       213\n",
      "weighted avg       0.61      0.61      0.61       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5070422535211268 and f1 score is: 0.4393753290050886\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.96      0.63        95\n",
      "           1       0.81      0.14      0.24       118\n",
      "\n",
      "    accuracy                           0.51       213\n",
      "   macro avg       0.64      0.55      0.44       213\n",
      "weighted avg       0.66      0.51      0.42       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5070422535211268 and f1 score is: 0.48292603981226734\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.81      0.59        95\n",
      "           1       0.63      0.26      0.37       118\n",
      "\n",
      "    accuracy                           0.51       213\n",
      "   macro avg       0.55      0.54      0.48       213\n",
      "weighted avg       0.56      0.51      0.47       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5305164319248826 and f1 score is: 0.5216492993172834\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.75      0.59        95\n",
      "           1       0.64      0.36      0.46       118\n",
      "\n",
      "    accuracy                           0.53       213\n",
      "   macro avg       0.56      0.55      0.52       213\n",
      "weighted avg       0.57      0.53      0.51       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5164319248826291 and f1 score is: 0.4500538941668965\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.97      0.64        95\n",
      "           1       0.86      0.15      0.26       118\n",
      "\n",
      "    accuracy                           0.52       213\n",
      "   macro avg       0.67      0.56      0.45       213\n",
      "weighted avg       0.69      0.52      0.43       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.48826291079812206 and f1 score is: 0.4339111988881574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.89      0.61        95\n",
      "           1       0.66      0.16      0.26       118\n",
      "\n",
      "    accuracy                           0.49       213\n",
      "   macro avg       0.56      0.53      0.43       213\n",
      "weighted avg       0.57      0.49      0.41       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1390.csv ---\n",
      "[15:28:47] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5492957746478874 and f1 score is: 0.5448717948717949\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.73      0.59        95\n",
      "           1       0.65      0.41      0.50       118\n",
      "\n",
      "    accuracy                           0.55       213\n",
      "   macro avg       0.57      0.57      0.54       213\n",
      "weighted avg       0.58      0.55      0.54       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5446009389671361 and f1 score is: 0.5396903197059151\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.73      0.59        95\n",
      "           1       0.64      0.40      0.49       118\n",
      "\n",
      "    accuracy                           0.54       213\n",
      "   macro avg       0.57      0.56      0.54       213\n",
      "weighted avg       0.58      0.54      0.53       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.44285714285714284 and f1 score is: 0.4184753023597075\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.18      0.30       136\n",
      "           1       0.38      0.92      0.54        74\n",
      "\n",
      "    accuracy                           0.44       210\n",
      "   macro avg       0.59      0.55      0.42       210\n",
      "weighted avg       0.66      0.44      0.38       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5285714285714286 and f1 score is: 0.5246804910949039\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.34      0.48       136\n",
      "           1       0.42      0.88      0.57        74\n",
      "\n",
      "    accuracy                           0.53       210\n",
      "   macro avg       0.63      0.61      0.52       210\n",
      "weighted avg       0.69      0.53      0.51       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.4857142857142857 and f1 score is: 0.47014297729184196\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.24      0.38       136\n",
      "           1       0.40      0.93      0.56        74\n",
      "\n",
      "    accuracy                           0.49       210\n",
      "   macro avg       0.63      0.59      0.47       210\n",
      "weighted avg       0.70      0.49      0.44       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5714285714285714 and f1 score is: 0.5712730242264767\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.46      0.58       136\n",
      "           1       0.44      0.78      0.56        74\n",
      "\n",
      "    accuracy                           0.57       210\n",
      "   macro avg       0.62      0.62      0.57       210\n",
      "weighted avg       0.67      0.57      0.57       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5619047619047619 and f1 score is: 0.5599489795918368\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.38      0.53       136\n",
      "           1       0.44      0.89      0.59        74\n",
      "\n",
      "    accuracy                           0.56       210\n",
      "   macro avg       0.65      0.64      0.56       210\n",
      "weighted avg       0.72      0.56      0.55       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.4 and f1 score is: 0.35751748251748255\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.11      0.19       136\n",
      "           1       0.36      0.93      0.52        74\n",
      "\n",
      "    accuracy                           0.40       210\n",
      "   macro avg       0.56      0.52      0.36       210\n",
      "weighted avg       0.61      0.40      0.31       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1400.csv ---\n",
      "[15:29:39] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.43333333333333335 and f1 score is: 0.40070505287896596\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.15      0.26       136\n",
      "           1       0.38      0.95      0.54        74\n",
      "\n",
      "    accuracy                           0.43       210\n",
      "   macro avg       0.61      0.55      0.40       210\n",
      "weighted avg       0.68      0.43      0.36       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5 and f1 score is: 0.4888615869630728\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.27      0.41       136\n",
      "           1       0.41      0.92      0.56        74\n",
      "\n",
      "    accuracy                           0.50       210\n",
      "   macro avg       0.63      0.60      0.49       210\n",
      "weighted avg       0.70      0.50      0.47       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5841121495327103 and f1 score is: 0.5184932372645683\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.24      0.34        95\n",
      "           1       0.59      0.86      0.70       119\n",
      "\n",
      "    accuracy                           0.58       214\n",
      "   macro avg       0.58      0.55      0.52       214\n",
      "weighted avg       0.58      0.58      0.54       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5841121495327103 and f1 score is: 0.5145660762074677\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.23      0.33        95\n",
      "           1       0.59      0.87      0.70       119\n",
      "\n",
      "    accuracy                           0.58       214\n",
      "   macro avg       0.58      0.55      0.51       214\n",
      "weighted avg       0.58      0.58      0.54       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5700934579439252 and f1 score is: 0.5676767676767677\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.56      0.54        95\n",
      "           1       0.62      0.58      0.60       119\n",
      "\n",
      "    accuracy                           0.57       214\n",
      "   macro avg       0.57      0.57      0.57       214\n",
      "weighted avg       0.57      0.57      0.57       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5700934579439252 and f1 score is: 0.5307017543859649\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.32      0.39        95\n",
      "           1       0.59      0.77      0.67       119\n",
      "\n",
      "    accuracy                           0.57       214\n",
      "   macro avg       0.56      0.54      0.53       214\n",
      "weighted avg       0.56      0.57      0.55       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5887850467289719 and f1 score is: 0.5219819270991979\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.24      0.34        95\n",
      "           1       0.59      0.87      0.70       119\n",
      "\n",
      "    accuracy                           0.59       214\n",
      "   macro avg       0.59      0.55      0.52       214\n",
      "weighted avg       0.59      0.59      0.54       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5514018691588785 and f1 score is: 0.4826752618855762\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.21      0.29        95\n",
      "           1       0.57      0.82      0.67       119\n",
      "\n",
      "    accuracy                           0.55       214\n",
      "   macro avg       0.53      0.52      0.48       214\n",
      "weighted avg       0.53      0.55      0.50       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1419.csv ---\n",
      "[15:30:27] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5700934579439252 and f1 score is: 0.5528706395348837\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.42      0.47        95\n",
      "           1       0.60      0.69      0.64       119\n",
      "\n",
      "    accuracy                           0.57       214\n",
      "   macro avg       0.56      0.56      0.55       214\n",
      "weighted avg       0.56      0.57      0.56       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5794392523364486 and f1 score is: 0.5794392523364486\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.65      0.58        95\n",
      "           1       0.65      0.52      0.58       119\n",
      "\n",
      "    accuracy                           0.58       214\n",
      "   macro avg       0.59      0.59      0.58       214\n",
      "weighted avg       0.59      0.58      0.58       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5308641975308642 and f1 score is: 0.5064935064935066\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62       122\n",
      "           1       0.29      0.62      0.40        40\n",
      "\n",
      "    accuracy                           0.53       162\n",
      "   macro avg       0.55      0.56      0.51       162\n",
      "weighted avg       0.68      0.53      0.56       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.7469135802469136 and f1 score is: 0.47096774193548396\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.85       122\n",
      "           1       0.40      0.05      0.09        40\n",
      "\n",
      "    accuracy                           0.75       162\n",
      "   macro avg       0.58      0.51      0.47       162\n",
      "weighted avg       0.67      0.75      0.66       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5864197530864198 and f1 score is: 0.5231735711461583\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.63      0.70       122\n",
      "           1       0.29      0.45      0.35        40\n",
      "\n",
      "    accuracy                           0.59       162\n",
      "   macro avg       0.53      0.54      0.52       162\n",
      "weighted avg       0.66      0.59      0.61       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5185185185185185 and f1 score is: 0.487258561921766\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.51      0.61       122\n",
      "           1       0.27      0.55      0.36        40\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.52      0.53      0.49       162\n",
      "weighted avg       0.65      0.52      0.55       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.7530864197530864 and f1 score is: 0.452887537993921\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86       122\n",
      "           1       0.50      0.03      0.05        40\n",
      "\n",
      "    accuracy                           0.75       162\n",
      "   macro avg       0.63      0.51      0.45       162\n",
      "weighted avg       0.69      0.75      0.66       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.654320987654321 and f1 score is: 0.5499999999999999\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77       122\n",
      "           1       0.32      0.35      0.33        40\n",
      "\n",
      "    accuracy                           0.65       162\n",
      "   macro avg       0.55      0.55      0.55       162\n",
      "weighted avg       0.67      0.65      0.66       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1517.csv ---\n",
      "[15:31:21] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.47530864197530864 and f1 score is: 0.4603174603174603\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.43      0.55       122\n",
      "           1       0.26      0.62      0.37        40\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.52      0.53      0.46       162\n",
      "weighted avg       0.65      0.48      0.51       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5987654320987654 and f1 score is: 0.5464920969895344\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.62      0.70       122\n",
      "           1       0.31      0.53      0.39        40\n",
      "\n",
      "    accuracy                           0.60       162\n",
      "   macro avg       0.56      0.57      0.55       162\n",
      "weighted avg       0.68      0.60      0.62       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.5208333333333334\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.10      0.17        10\n",
      "           1       0.80      0.97      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.65      0.54      0.52        46\n",
      "weighted avg       0.73      0.78      0.72        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.5208333333333334\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.10      0.17        10\n",
      "           1       0.80      0.97      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.65      0.54      0.52        46\n",
      "weighted avg       0.73      0.78      0.72        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.5 and f1 score is: 0.39715099715099716\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.20      0.15        10\n",
      "           1       0.72      0.58      0.65        36\n",
      "\n",
      "    accuracy                           0.50        46\n",
      "   macro avg       0.42      0.39      0.40        46\n",
      "weighted avg       0.59      0.50      0.54        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.21739130434782608 and f1 score is: 0.17857142857142855\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36        10\n",
      "           1       1.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.22        46\n",
      "   macro avg       0.61      0.50      0.18        46\n",
      "weighted avg       0.83      0.22      0.08        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.5208333333333334\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.10      0.17        10\n",
      "           1       0.80      0.97      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.65      0.54      0.52        46\n",
      "weighted avg       0.73      0.78      0.72        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1544.csv ---\n",
      "[15:32:13] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.7608695652173914 and f1 score is: 0.50730282375852\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.10      0.15        10\n",
      "           1       0.79      0.94      0.86        36\n",
      "\n",
      "    accuracy                           0.76        46\n",
      "   macro avg       0.56      0.52      0.51        46\n",
      "weighted avg       0.69      0.76      0.71        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.7608695652173914 and f1 score is: 0.50730282375852\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.10      0.15        10\n",
      "           1       0.79      0.94      0.86        36\n",
      "\n",
      "    accuracy                           0.76        46\n",
      "   macro avg       0.56      0.52      0.51        46\n",
      "weighted avg       0.69      0.76      0.71        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5974842767295597 and f1 score is: 0.48997594226142743\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.15      0.26        73\n",
      "           1       0.58      0.98      0.72        86\n",
      "\n",
      "    accuracy                           0.60       159\n",
      "   macro avg       0.71      0.56      0.49       159\n",
      "weighted avg       0.70      0.60      0.51       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5534591194968553 and f1 score is: 0.421225326839272\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.08      0.14        73\n",
      "           1       0.55      0.95      0.70        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.58      0.52      0.42       159\n",
      "weighted avg       0.57      0.55      0.44       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5283018867924528 and f1 score is: 0.5207186206342188\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.71      0.58        73\n",
      "           1       0.60      0.37      0.46        86\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.55      0.54      0.52       159\n",
      "weighted avg       0.55      0.53      0.52       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5345911949685535 and f1 score is: 0.38203781512605034\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.04      0.07        73\n",
      "           1       0.54      0.95      0.69        86\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.48      0.50      0.38       159\n",
      "weighted avg       0.49      0.53      0.41       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5660377358490566 and f1 score is: 0.4821335850837858\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.18      0.27        73\n",
      "           1       0.56      0.90      0.69        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.58      0.54      0.48       159\n",
      "weighted avg       0.58      0.57      0.50       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5471698113207547 and f1 score is: 0.37755545889517184\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.03      0.05        73\n",
      "           1       0.54      0.99      0.70        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.61      0.51      0.38       159\n",
      "weighted avg       0.60      0.55      0.40       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1624.csv ---\n",
      "[15:33:03] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5911949685534591 and f1 score is: 0.587012987012987\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.53      0.55        73\n",
      "           1       0.62      0.64      0.63        86\n",
      "\n",
      "    accuracy                           0.59       159\n",
      "   macro avg       0.59      0.59      0.59       159\n",
      "weighted avg       0.59      0.59      0.59       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5911949685534591 and f1 score is: 0.5832157115780136\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.79      0.64        73\n",
      "           1       0.71      0.42      0.53        86\n",
      "\n",
      "    accuracy                           0.59       159\n",
      "   macro avg       0.62      0.61      0.58       159\n",
      "weighted avg       0.63      0.59      0.58       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6795580110497238 and f1 score is: 0.44955956375838924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.05      0.09        60\n",
      "           1       0.68      0.99      0.81       121\n",
      "\n",
      "    accuracy                           0.68       181\n",
      "   macro avg       0.71      0.52      0.45       181\n",
      "weighted avg       0.70      0.68      0.57       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.4419889502762431 and f1 score is: 0.4320024856299518\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.87      0.51        60\n",
      "           1       0.78      0.23      0.36       121\n",
      "\n",
      "    accuracy                           0.44       181\n",
      "   macro avg       0.57      0.55      0.43       181\n",
      "weighted avg       0.64      0.44      0.41       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.4861878453038674 and f1 score is: 0.4696096039323188\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.47      0.38        60\n",
      "           1       0.65      0.50      0.56       121\n",
      "\n",
      "    accuracy                           0.49       181\n",
      "   macro avg       0.48      0.48      0.47       181\n",
      "weighted avg       0.54      0.49      0.50       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.46408839779005523 and f1 score is: 0.4640883977900553\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.70      0.46        60\n",
      "           1       0.70      0.35      0.46       121\n",
      "\n",
      "    accuracy                           0.46       181\n",
      "   macro avg       0.52      0.52      0.46       181\n",
      "weighted avg       0.58      0.46      0.46       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.4198895027624309 and f1 score is: 0.40566657284923535\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.87      0.50        60\n",
      "           1       0.75      0.20      0.31       121\n",
      "\n",
      "    accuracy                           0.42       181\n",
      "   macro avg       0.55      0.53      0.41       181\n",
      "weighted avg       0.62      0.42      0.37       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.46408839779005523 and f1 score is: 0.45094911967976975\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.93      0.54        60\n",
      "           1       0.88      0.23      0.37       121\n",
      "\n",
      "    accuracy                           0.46       181\n",
      "   macro avg       0.63      0.58      0.45       181\n",
      "weighted avg       0.71      0.46      0.42       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1688.csv ---\n",
      "[15:33:53] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6353591160220995 and f1 score is: 0.47047872340425534\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.12      0.17        60\n",
      "           1       0.67      0.89      0.77       121\n",
      "\n",
      "    accuracy                           0.64       181\n",
      "   macro avg       0.51      0.50      0.47       181\n",
      "weighted avg       0.56      0.64      0.57       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6077348066298343 and f1 score is: 0.5000583544057576\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.22      0.27        60\n",
      "           1       0.67      0.80      0.73       121\n",
      "\n",
      "    accuracy                           0.61       181\n",
      "   macro avg       0.51      0.51      0.50       181\n",
      "weighted avg       0.57      0.61      0.58       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.7037037037037037 and f1 score is: 0.5090909090909091\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.12      0.20        34\n",
      "           1       0.71      0.97      0.82        74\n",
      "\n",
      "    accuracy                           0.70       108\n",
      "   macro avg       0.69      0.55      0.51       108\n",
      "weighted avg       0.69      0.70      0.62       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.46296296296296297 and f1 score is: 0.45999999999999996\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.85      0.50        34\n",
      "           1       0.81      0.28      0.42        74\n",
      "\n",
      "    accuracy                           0.46       108\n",
      "   macro avg       0.58      0.57      0.46       108\n",
      "weighted avg       0.66      0.46      0.45       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6944444444444444 and f1 score is: 0.5209033472240893\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.15      0.23        34\n",
      "           1       0.71      0.95      0.81        74\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.63      0.55      0.52       108\n",
      "weighted avg       0.66      0.69      0.63       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6851851851851852 and f1 score is: 0.6458333333333333\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.56      0.53        34\n",
      "           1       0.79      0.74      0.76        74\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.64      0.65      0.65       108\n",
      "weighted avg       0.70      0.69      0.69       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.46296296296296297 and f1 score is: 0.4622252747252747\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.79      0.48        34\n",
      "           1       0.77      0.31      0.44        74\n",
      "\n",
      "    accuracy                           0.46       108\n",
      "   macro avg       0.56      0.55      0.46       108\n",
      "weighted avg       0.63      0.46      0.45       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5 and f1 score is: 0.4984520123839009\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.88      0.53        34\n",
      "           1       0.86      0.32      0.47        74\n",
      "\n",
      "    accuracy                           0.50       108\n",
      "   macro avg       0.62      0.60      0.50       108\n",
      "weighted avg       0.71      0.50      0.49       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1717.csv ---\n",
      "[15:34:46] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6759259259259259 and f1 score is: 0.4731707317073171\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.09      0.15        34\n",
      "           1       0.69      0.95      0.80        74\n",
      "\n",
      "    accuracy                           0.68       108\n",
      "   macro avg       0.56      0.52      0.47       108\n",
      "weighted avg       0.61      0.68      0.59       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6388888888888888 and f1 score is: 0.5124435698576224\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.21      0.26        34\n",
      "           1       0.70      0.84      0.76        74\n",
      "\n",
      "    accuracy                           0.64       108\n",
      "   macro avg       0.53      0.52      0.51       108\n",
      "weighted avg       0.59      0.64      0.60       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4691358024691358 and f1 score is: 0.39108391608391607\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.10      0.17        86\n",
      "           1       0.47      0.88      0.61        76\n",
      "\n",
      "    accuracy                           0.47       162\n",
      "   macro avg       0.48      0.49      0.39       162\n",
      "weighted avg       0.48      0.47      0.38       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.43209876543209874 and f1 score is: 0.3190789473684211\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.02      0.04        86\n",
      "           1       0.45      0.89      0.60        76\n",
      "\n",
      "    accuracy                           0.43       162\n",
      "   macro avg       0.32      0.46      0.32       162\n",
      "weighted avg       0.32      0.43      0.30       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.46296296296296297 and f1 score is: 0.429923552966873\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.21      0.29        86\n",
      "           1       0.46      0.75      0.57        76\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.47      0.48      0.43       162\n",
      "weighted avg       0.47      0.46      0.42       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4691358024691358 and f1 score is: 0.4662068965517241\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.37      0.43        86\n",
      "           1       0.45      0.58      0.51        76\n",
      "\n",
      "    accuracy                           0.47       162\n",
      "   macro avg       0.47      0.48      0.47       162\n",
      "weighted avg       0.48      0.47      0.46       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4444444444444444 and f1 score is: 0.3338815789473684\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.03      0.06        86\n",
      "           1       0.45      0.91      0.61        76\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.38      0.47      0.33       162\n",
      "weighted avg       0.37      0.44      0.32       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.41975308641975306 and f1 score is: 0.393016581632653\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.20      0.27        86\n",
      "           1       0.42      0.67      0.52        76\n",
      "\n",
      "    accuracy                           0.42       162\n",
      "   macro avg       0.41      0.43      0.39       162\n",
      "weighted avg       0.41      0.42      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1765.csv ---\n",
      "[15:35:34] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4382716049382716 and f1 score is: 0.40735678391959795\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.20      0.27        86\n",
      "           1       0.44      0.71      0.54        76\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.44      0.45      0.41       162\n",
      "weighted avg       0.44      0.44      0.40       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.43209876543209874 and f1 score is: 0.4090404440919905\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.22      0.29        86\n",
      "           1       0.43      0.67      0.53        76\n",
      "\n",
      "    accuracy                           0.43       162\n",
      "   macro avg       0.43      0.45      0.41       162\n",
      "weighted avg       0.43      0.43      0.40       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.5613207547169812 and f1 score is: 0.42577544779379645\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.50      0.15        16\n",
      "           1       0.93      0.57      0.70       196\n",
      "\n",
      "    accuracy                           0.56       212\n",
      "   macro avg       0.51      0.53      0.43       212\n",
      "weighted avg       0.87      0.56      0.66       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.660377358490566 and f1 score is: 0.46554621848739497\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.38      0.14        16\n",
      "           1       0.93      0.68      0.79       196\n",
      "\n",
      "    accuracy                           0.66       212\n",
      "   macro avg       0.51      0.53      0.47       212\n",
      "weighted avg       0.87      0.66      0.74       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.5754716981132075 and f1 score is: 0.44092827004219415\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.56      0.17        16\n",
      "           1       0.94      0.58      0.72       196\n",
      "\n",
      "    accuracy                           0.58       212\n",
      "   macro avg       0.52      0.57      0.44       212\n",
      "weighted avg       0.88      0.58      0.67       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6179245283018868 and f1 score is: 0.45862101579494935\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.50      0.16        16\n",
      "           1       0.94      0.63      0.75       196\n",
      "\n",
      "    accuracy                           0.62       212\n",
      "   macro avg       0.52      0.56      0.46       212\n",
      "weighted avg       0.88      0.62      0.71       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6179245283018868 and f1 score is: 0.450583906574948\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.44      0.15        16\n",
      "           1       0.93      0.63      0.75       196\n",
      "\n",
      "    accuracy                           0.62       212\n",
      "   macro avg       0.51      0.54      0.45       212\n",
      "weighted avg       0.87      0.62      0.71       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.4339622641509434 and f1 score is: 0.37720329024676846\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.88      0.19        16\n",
      "           1       0.97      0.40      0.57       196\n",
      "\n",
      "    accuracy                           0.43       212\n",
      "   macro avg       0.54      0.64      0.38       212\n",
      "weighted avg       0.91      0.43      0.54       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1818.csv ---\n",
      "[15:36:22] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.4811320754716981 and f1 score is: 0.38984824699110415\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.62      0.15        16\n",
      "           1       0.94      0.47      0.63       196\n",
      "\n",
      "    accuracy                           0.48       212\n",
      "   macro avg       0.51      0.55      0.39       212\n",
      "weighted avg       0.87      0.48      0.59       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.4811320754716981 and f1 score is: 0.3949771689497717\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.69      0.17        16\n",
      "           1       0.95      0.46      0.62       196\n",
      "\n",
      "    accuracy                           0.48       212\n",
      "   macro avg       0.52      0.58      0.39       212\n",
      "weighted avg       0.88      0.48      0.59       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.3472222222222222 and f1 score is: 0.3409931840311587\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.17      0.28       162\n",
      "           1       0.26      0.89      0.41        54\n",
      "\n",
      "    accuracy                           0.35       216\n",
      "   macro avg       0.54      0.53      0.34       216\n",
      "weighted avg       0.68      0.35      0.31       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.35185185185185186 and f1 score is: 0.3509615384615385\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.26      0.38       162\n",
      "           1       0.22      0.63      0.33        54\n",
      "\n",
      "    accuracy                           0.35       216\n",
      "   macro avg       0.45      0.44      0.35       216\n",
      "weighted avg       0.56      0.35      0.36       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4351851851851852 and f1 score is: 0.4328024106758501\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.33      0.47       162\n",
      "           1       0.27      0.74      0.40        54\n",
      "\n",
      "    accuracy                           0.44       216\n",
      "   macro avg       0.53      0.54      0.43       216\n",
      "weighted avg       0.66      0.44      0.45       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.3888888888888889 and f1 score is: 0.3846153846153847\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.31      0.44       162\n",
      "           1       0.23      0.61      0.33        54\n",
      "\n",
      "    accuracy                           0.39       216\n",
      "   macro avg       0.47      0.46      0.38       216\n",
      "weighted avg       0.59      0.39      0.41       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.35648148148148145 and f1 score is: 0.3548082088750403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.27      0.39       162\n",
      "           1       0.22      0.61      0.32        54\n",
      "\n",
      "    accuracy                           0.36       216\n",
      "   macro avg       0.45      0.44      0.35       216\n",
      "weighted avg       0.56      0.36      0.37       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4444444444444444 and f1 score is: 0.4319775596072931\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.40      0.52       162\n",
      "           1       0.25      0.59      0.35        54\n",
      "\n",
      "    accuracy                           0.44       216\n",
      "   macro avg       0.50      0.49      0.43       216\n",
      "weighted avg       0.62      0.44      0.47       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1892.csv ---\n",
      "[15:37:12] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4074074074074074 and f1 score is: 0.40735659778787614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.28      0.41       162\n",
      "           1       0.27      0.80      0.40        54\n",
      "\n",
      "    accuracy                           0.41       216\n",
      "   macro avg       0.54      0.54      0.41       216\n",
      "weighted avg       0.67      0.41      0.41       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.41203703703703703 and f1 score is: 0.4114188855751282\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.30      0.43       162\n",
      "           1       0.26      0.76      0.39        54\n",
      "\n",
      "    accuracy                           0.41       216\n",
      "   macro avg       0.53      0.53      0.41       216\n",
      "weighted avg       0.66      0.41      0.42       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.37735849056603776 and f1 score is: 0.3566896551724138\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.91      0.47        65\n",
      "           1       0.78      0.14      0.24       147\n",
      "\n",
      "    accuracy                           0.38       212\n",
      "   macro avg       0.55      0.53      0.36       212\n",
      "weighted avg       0.64      0.38      0.31       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5330188679245284 and f1 score is: 0.49932011736921206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.45      0.37        65\n",
      "           1       0.70      0.57      0.63       147\n",
      "\n",
      "    accuracy                           0.53       212\n",
      "   macro avg       0.51      0.51      0.50       212\n",
      "weighted avg       0.58      0.53      0.55       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.49056603773584906 and f1 score is: 0.4883346741753821\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.69      0.45        65\n",
      "           1       0.75      0.40      0.52       147\n",
      "\n",
      "    accuracy                           0.49       212\n",
      "   macro avg       0.54      0.55      0.49       212\n",
      "weighted avg       0.62      0.49      0.50       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.4386792452830189 and f1 score is: 0.43836683808633314\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.75      0.45        65\n",
      "           1       0.73      0.30      0.43       147\n",
      "\n",
      "    accuracy                           0.44       212\n",
      "   macro avg       0.53      0.53      0.44       212\n",
      "weighted avg       0.61      0.44      0.43       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5424528301886793 and f1 score is: 0.5067993764240317\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.45      0.37        65\n",
      "           1       0.70      0.59      0.64       147\n",
      "\n",
      "    accuracy                           0.54       212\n",
      "   macro avg       0.51      0.52      0.51       212\n",
      "weighted avg       0.59      0.54      0.56       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5424528301886793 and f1 score is: 0.5349089675449508\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.68      0.48        65\n",
      "           1       0.77      0.48      0.59       147\n",
      "\n",
      "    accuracy                           0.54       212\n",
      "   macro avg       0.57      0.58      0.53       212\n",
      "weighted avg       0.65      0.54      0.56       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1929.csv ---\n",
      "[15:38:02] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.4386792452830189 and f1 score is: 0.43866675566829094\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.72      0.44        65\n",
      "           1       0.72      0.31      0.44       147\n",
      "\n",
      "    accuracy                           0.44       212\n",
      "   macro avg       0.52      0.52      0.44       212\n",
      "weighted avg       0.60      0.44      0.44       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.37264150943396224 and f1 score is: 0.36379430943838986\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.80      0.44        65\n",
      "           1       0.68      0.18      0.29       147\n",
      "\n",
      "    accuracy                           0.37       212\n",
      "   macro avg       0.49      0.49      0.36       212\n",
      "weighted avg       0.56      0.37      0.33       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6224489795918368 and f1 score is: 0.542345071311372\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.28      0.35        36\n",
      "           1       0.66      0.82      0.73        62\n",
      "\n",
      "    accuracy                           0.62        98\n",
      "   macro avg       0.57      0.55      0.54        98\n",
      "weighted avg       0.59      0.62      0.59        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6122448979591837 and f1 score is: 0.5916666666666667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.53      0.50        36\n",
      "           1       0.71      0.66      0.68        62\n",
      "\n",
      "    accuracy                           0.61        98\n",
      "   macro avg       0.59      0.59      0.59        98\n",
      "weighted avg       0.62      0.61      0.62        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.46938775510204084 and f1 score is: 0.46850229453483516\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.58      0.45        36\n",
      "           1       0.62      0.40      0.49        62\n",
      "\n",
      "    accuracy                           0.47        98\n",
      "   macro avg       0.49      0.49      0.47        98\n",
      "weighted avg       0.53      0.47      0.47        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.673469387755102 and f1 score is: 0.6620689655172414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.60        36\n",
      "           1       0.78      0.68      0.72        62\n",
      "\n",
      "    accuracy                           0.67        98\n",
      "   macro avg       0.66      0.67      0.66        98\n",
      "weighted avg       0.69      0.67      0.68        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5918367346938775 and f1 score is: 0.5740982181660147\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.53      0.49        36\n",
      "           1       0.70      0.63      0.66        62\n",
      "\n",
      "    accuracy                           0.59        98\n",
      "   macro avg       0.57      0.58      0.57        98\n",
      "weighted avg       0.61      0.59      0.60        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6632653061224489 and f1 score is: 0.6398262612763115\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.56      0.55        36\n",
      "           1       0.74      0.73      0.73        62\n",
      "\n",
      "    accuracy                           0.66        98\n",
      "   macro avg       0.64      0.64      0.64        98\n",
      "weighted avg       0.67      0.66      0.66        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1933.csv ---\n",
      "[15:38:54] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6122448979591837 and f1 score is: 0.595393307257714\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.56      0.51        36\n",
      "           1       0.71      0.65      0.68        62\n",
      "\n",
      "    accuracy                           0.61        98\n",
      "   macro avg       0.60      0.60      0.60        98\n",
      "weighted avg       0.63      0.61      0.62        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6122448979591837 and f1 score is: 0.5987068965517242\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.58      0.53        36\n",
      "           1       0.72      0.63      0.67        62\n",
      "\n",
      "    accuracy                           0.61        98\n",
      "   macro avg       0.60      0.61      0.60        98\n",
      "weighted avg       0.63      0.61      0.62        98\n",
      "\n",
      "----- Running Modality Combination EDA_EEG\n",
      "Saved Directory: 2022_08_11_15_39\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5721153846153846 and f1 score is: 0.43310365947021895\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.08      0.15        95\n",
      "           1       0.56      0.98      0.71       113\n",
      "\n",
      "    accuracy                           0.57       208\n",
      "   macro avg       0.68      0.53      0.43       208\n",
      "weighted avg       0.67      0.57      0.46       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.46634615384615385 and f1 score is: 0.4447731043936224\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.29      0.34        95\n",
      "           1       0.51      0.61      0.55       113\n",
      "\n",
      "    accuracy                           0.47       208\n",
      "   macro avg       0.45      0.45      0.44       208\n",
      "weighted avg       0.45      0.47      0.45       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5817307692307693 and f1 score is: 0.5265677733301938\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.26      0.36        95\n",
      "           1       0.58      0.85      0.69       113\n",
      "\n",
      "    accuracy                           0.58       208\n",
      "   macro avg       0.59      0.56      0.53       208\n",
      "weighted avg       0.59      0.58      0.54       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5576923076923077 and f1 score is: 0.45011494252873563\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.13      0.21        95\n",
      "           1       0.56      0.92      0.69       113\n",
      "\n",
      "    accuracy                           0.56       208\n",
      "   macro avg       0.56      0.52      0.45       208\n",
      "weighted avg       0.56      0.56      0.47       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.4519230769230769 and f1 score is: 0.4506533222129552\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.44      0.42        95\n",
      "           1       0.50      0.46      0.48       113\n",
      "\n",
      "    accuracy                           0.45       208\n",
      "   macro avg       0.45      0.45      0.45       208\n",
      "weighted avg       0.46      0.45      0.45       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5240384615384616 and f1 score is: 0.5239394289677494\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.59      0.53        95\n",
      "           1       0.58      0.47      0.52       113\n",
      "\n",
      "    accuracy                           0.52       208\n",
      "   macro avg       0.53      0.53      0.52       208\n",
      "weighted avg       0.53      0.52      0.52       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1105.csv ---\n",
      "[15:40:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5480769230769231 and f1 score is: 0.4649151614668856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.17      0.25        95\n",
      "           1       0.55      0.87      0.68       113\n",
      "\n",
      "    accuracy                           0.55       208\n",
      "   macro avg       0.53      0.52      0.46       208\n",
      "weighted avg       0.54      0.55      0.48       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5048076923076923 and f1 score is: 0.4675812023161609\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.26      0.33        95\n",
      "           1       0.53      0.71      0.61       113\n",
      "\n",
      "    accuracy                           0.50       208\n",
      "   macro avg       0.48      0.49      0.47       208\n",
      "weighted avg       0.49      0.50      0.48       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7959183673469388 and f1 score is: 0.5251937984496123\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.19      0.17        16\n",
      "           1       0.90      0.87      0.88       131\n",
      "\n",
      "    accuracy                           0.80       147\n",
      "   macro avg       0.52      0.53      0.53       147\n",
      "weighted avg       0.82      0.80      0.81       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.5850340136054422 and f1 score is: 0.4720635855166323\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.56      0.23        16\n",
      "           1       0.92      0.59      0.72       131\n",
      "\n",
      "    accuracy                           0.59       147\n",
      "   macro avg       0.53      0.58      0.47       147\n",
      "weighted avg       0.83      0.59      0.66       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7006802721088435 and f1 score is: 0.550333704115684\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.56      0.29        16\n",
      "           1       0.93      0.72      0.81       131\n",
      "\n",
      "    accuracy                           0.70       147\n",
      "   macro avg       0.56      0.64      0.55       147\n",
      "weighted avg       0.85      0.70      0.75       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.5850340136054422 and f1 score is: 0.42241545893719806\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.25      0.12        16\n",
      "           1       0.87      0.63      0.73       131\n",
      "\n",
      "    accuracy                           0.59       147\n",
      "   macro avg       0.47      0.44      0.42       147\n",
      "weighted avg       0.79      0.59      0.66       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.6326530612244898 and f1 score is: 0.4937499999999999\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.50      0.23        16\n",
      "           1       0.91      0.65      0.76       131\n",
      "\n",
      "    accuracy                           0.63       147\n",
      "   macro avg       0.53      0.57      0.49       147\n",
      "weighted avg       0.83      0.63      0.70       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.3945578231292517 and f1 score is: 0.3750059714326662\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      1.00      0.26        16\n",
      "           1       1.00      0.32      0.49       131\n",
      "\n",
      "    accuracy                           0.39       147\n",
      "   macro avg       0.58      0.66      0.38       147\n",
      "weighted avg       0.91      0.39      0.46       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1106.csv ---\n",
      "[15:42:27] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7414965986394558 and f1 score is: 0.5808823529411765\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.56      0.32        16\n",
      "           1       0.93      0.76      0.84       131\n",
      "\n",
      "    accuracy                           0.74       147\n",
      "   macro avg       0.58      0.66      0.58       147\n",
      "weighted avg       0.86      0.74      0.78       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7074829931972789 and f1 score is: 0.5656565656565655\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.62      0.32        16\n",
      "           1       0.94      0.72      0.81       131\n",
      "\n",
      "    accuracy                           0.71       147\n",
      "   macro avg       0.58      0.67      0.57       147\n",
      "weighted avg       0.86      0.71      0.76       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.536723163841808 and f1 score is: 0.3891414141414142\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.05      0.09        84\n",
      "           1       0.53      0.98      0.69        93\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.60      0.51      0.39       177\n",
      "weighted avg       0.60      0.54      0.40       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5141242937853108 and f1 score is: 0.5141087844739529\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.54      0.51        84\n",
      "           1       0.54      0.49      0.52        93\n",
      "\n",
      "    accuracy                           0.51       177\n",
      "   macro avg       0.52      0.52      0.51       177\n",
      "weighted avg       0.52      0.51      0.51       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5988700564971752 and f1 score is: 0.5427687829725305\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.26      0.38        84\n",
      "           1       0.58      0.90      0.70        93\n",
      "\n",
      "    accuracy                           0.60       177\n",
      "   macro avg       0.64      0.58      0.54       177\n",
      "weighted avg       0.64      0.60      0.55       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.559322033898305 and f1 score is: 0.5552190721649484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.49      0.51        84\n",
      "           1       0.57      0.62      0.60        93\n",
      "\n",
      "    accuracy                           0.56       177\n",
      "   macro avg       0.56      0.56      0.56       177\n",
      "weighted avg       0.56      0.56      0.56       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5084745762711864 and f1 score is: 0.5084118116520351\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.52      0.50        84\n",
      "           1       0.53      0.49      0.51        93\n",
      "\n",
      "    accuracy                           0.51       177\n",
      "   macro avg       0.51      0.51      0.51       177\n",
      "weighted avg       0.51      0.51      0.51       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4745762711864407 and f1 score is: 0.47430779548430363\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.52      0.49        84\n",
      "           1       0.50      0.43      0.46        93\n",
      "\n",
      "    accuracy                           0.47       177\n",
      "   macro avg       0.48      0.48      0.47       177\n",
      "weighted avg       0.48      0.47      0.47       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1175.csv ---\n",
      "[15:44:34] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.6101694915254238 and f1 score is: 0.6015724398916908\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.49      0.54        84\n",
      "           1       0.61      0.72      0.66        93\n",
      "\n",
      "    accuracy                           0.61       177\n",
      "   macro avg       0.61      0.60      0.60       177\n",
      "weighted avg       0.61      0.61      0.60       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5875706214689266 and f1 score is: 0.576984776559175\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.45      0.51        84\n",
      "           1       0.59      0.71      0.64        93\n",
      "\n",
      "    accuracy                           0.59       177\n",
      "   macro avg       0.59      0.58      0.58       177\n",
      "weighted avg       0.59      0.59      0.58       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5972222222222222 and f1 score is: 0.5789473684210527\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.37      0.49       113\n",
      "           1       0.55      0.84      0.67       103\n",
      "\n",
      "    accuracy                           0.60       216\n",
      "   macro avg       0.64      0.61      0.58       216\n",
      "weighted avg       0.64      0.60      0.57       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5462962962962963 and f1 score is: 0.5333333333333333\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61       113\n",
      "           1       0.53      0.40      0.46       103\n",
      "\n",
      "    accuracy                           0.55       216\n",
      "   macro avg       0.54      0.54      0.53       216\n",
      "weighted avg       0.54      0.55      0.54       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6666666666666666 and f1 score is: 0.6652604390873871\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69       113\n",
      "           1       0.66      0.63      0.64       103\n",
      "\n",
      "    accuracy                           0.67       216\n",
      "   macro avg       0.67      0.67      0.67       216\n",
      "weighted avg       0.67      0.67      0.67       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6157407407407407 and f1 score is: 0.6120740019474197\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.50      0.57       113\n",
      "           1       0.57      0.75      0.65       103\n",
      "\n",
      "    accuracy                           0.62       216\n",
      "   macro avg       0.63      0.62      0.61       216\n",
      "weighted avg       0.63      0.62      0.61       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5509259259259259 and f1 score is: 0.5448284851513111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.64      0.60       113\n",
      "           1       0.53      0.46      0.49       103\n",
      "\n",
      "    accuracy                           0.55       216\n",
      "   macro avg       0.55      0.55      0.54       216\n",
      "weighted avg       0.55      0.55      0.55       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5509259259259259 and f1 score is: 0.5501449275362318\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57       113\n",
      "           1       0.53      0.53      0.53       103\n",
      "\n",
      "    accuracy                           0.55       216\n",
      "   macro avg       0.55      0.55      0.55       216\n",
      "weighted avg       0.55      0.55      0.55       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1337.csv ---\n",
      "[15:46:38] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6574074074074074 and f1 score is: 0.657142857142857\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.67       113\n",
      "           1       0.64      0.66      0.65       103\n",
      "\n",
      "    accuracy                           0.66       216\n",
      "   macro avg       0.66      0.66      0.66       216\n",
      "weighted avg       0.66      0.66      0.66       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6111111111111112 and f1 score is: 0.6\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.67       113\n",
      "           1       0.62      0.47      0.53       103\n",
      "\n",
      "    accuracy                           0.61       216\n",
      "   macro avg       0.61      0.60      0.60       216\n",
      "weighted avg       0.61      0.61      0.60       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5023474178403756 and f1 score is: 0.45463768115942027\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.23      0.29        95\n",
      "           1       0.54      0.72      0.62       118\n",
      "\n",
      "    accuracy                           0.50       213\n",
      "   macro avg       0.47      0.48      0.45       213\n",
      "weighted avg       0.48      0.50      0.47       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5211267605633803 and f1 score is: 0.4813311688311689\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.27      0.34        95\n",
      "           1       0.55      0.72      0.63       118\n",
      "\n",
      "    accuracy                           0.52       213\n",
      "   macro avg       0.50      0.50      0.48       213\n",
      "weighted avg       0.50      0.52      0.50       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5352112676056338 and f1 score is: 0.5318681318681319\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.51      0.49        95\n",
      "           1       0.58      0.56      0.57       118\n",
      "\n",
      "    accuracy                           0.54       213\n",
      "   macro avg       0.53      0.53      0.53       213\n",
      "weighted avg       0.54      0.54      0.54       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5586854460093896 and f1 score is: 0.38582822085889573\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.03      0.06        95\n",
      "           1       0.56      0.98      0.71       118\n",
      "\n",
      "    accuracy                           0.56       213\n",
      "   macro avg       0.58      0.51      0.39       213\n",
      "weighted avg       0.58      0.56      0.42       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5446009389671361 and f1 score is: 0.49940639158772077\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.27      0.35        95\n",
      "           1       0.57      0.76      0.65       118\n",
      "\n",
      "    accuracy                           0.54       213\n",
      "   macro avg       0.52      0.52      0.50       213\n",
      "weighted avg       0.53      0.54      0.52       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5727699530516432 and f1 score is: 0.5518692345039651\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.40      0.46        95\n",
      "           1       0.60      0.71      0.65       118\n",
      "\n",
      "    accuracy                           0.57       213\n",
      "   macro avg       0.56      0.56      0.55       213\n",
      "weighted avg       0.57      0.57      0.56       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1390.csv ---\n",
      "[15:48:39] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5258215962441315 and f1 score is: 0.47545900080462294\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.24      0.31        95\n",
      "           1       0.55      0.75      0.64       118\n",
      "\n",
      "    accuracy                           0.53       213\n",
      "   macro avg       0.50      0.50      0.48       213\n",
      "weighted avg       0.50      0.53      0.49       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5070422535211268 and f1 score is: 0.45812032079083176\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.23      0.30        95\n",
      "           1       0.54      0.73      0.62       118\n",
      "\n",
      "    accuracy                           0.51       213\n",
      "   macro avg       0.47      0.48      0.46       213\n",
      "weighted avg       0.48      0.51      0.48       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6238095238095238 and f1 score is: 0.45447371017066196\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.91      0.76       136\n",
      "           1       0.37      0.09      0.15        74\n",
      "\n",
      "    accuracy                           0.62       210\n",
      "   macro avg       0.51      0.50      0.45       210\n",
      "weighted avg       0.55      0.62      0.54       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5952380952380952 and f1 score is: 0.49109052031361367\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.81      0.72       136\n",
      "           1       0.37      0.20      0.26        74\n",
      "\n",
      "    accuracy                           0.60       210\n",
      "   macro avg       0.51      0.51      0.49       210\n",
      "weighted avg       0.55      0.60      0.56       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6333333333333333 and f1 score is: 0.411122036490768\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.96      0.77       136\n",
      "           1       0.29      0.03      0.05        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.47      0.50      0.41       210\n",
      "weighted avg       0.52      0.63      0.52       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.46190476190476193 and f1 score is: 0.4583552075962658\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.42      0.50       136\n",
      "           1       0.34      0.54      0.41        74\n",
      "\n",
      "    accuracy                           0.46       210\n",
      "   macro avg       0.48      0.48      0.46       210\n",
      "weighted avg       0.52      0.46      0.47       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6 and f1 score is: 0.44875000000000004\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.74       136\n",
      "           1       0.31      0.11      0.16        74\n",
      "\n",
      "    accuracy                           0.60       210\n",
      "   macro avg       0.47      0.49      0.45       210\n",
      "weighted avg       0.52      0.60      0.53       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.4142857142857143 and f1 score is: 0.41427243248146217\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.32      0.41       136\n",
      "           1       0.32      0.59      0.42        74\n",
      "\n",
      "    accuracy                           0.41       210\n",
      "   macro avg       0.46      0.46      0.41       210\n",
      "weighted avg       0.49      0.41      0.41       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1400.csv ---\n",
      "[15:50:40] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.638095238095238 and f1 score is: 0.4443670797939005\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.95      0.77       136\n",
      "           1       0.42      0.07      0.12        74\n",
      "\n",
      "    accuracy                           0.64       210\n",
      "   macro avg       0.53      0.51      0.44       210\n",
      "weighted avg       0.57      0.64      0.54       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5904761904761905 and f1 score is: 0.4822841417268662\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.81      0.72       136\n",
      "           1       0.35      0.19      0.25        74\n",
      "\n",
      "    accuracy                           0.59       210\n",
      "   macro avg       0.50      0.50      0.48       210\n",
      "weighted avg       0.54      0.59      0.55       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5 and f1 score is: 0.4991140763425571\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.61      0.52        95\n",
      "           1       0.57      0.41      0.48       119\n",
      "\n",
      "    accuracy                           0.50       214\n",
      "   macro avg       0.51      0.51      0.50       214\n",
      "weighted avg       0.52      0.50      0.50       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.42990654205607476 and f1 score is: 0.41330337078651685\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.67      0.51        95\n",
      "           1       0.47      0.24      0.31       119\n",
      "\n",
      "    accuracy                           0.43       214\n",
      "   macro avg       0.44      0.45      0.41       214\n",
      "weighted avg       0.45      0.43      0.40       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.4953271028037383 and f1 score is: 0.4952830188679245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.57      0.50        95\n",
      "           1       0.56      0.44      0.49       119\n",
      "\n",
      "    accuracy                           0.50       214\n",
      "   macro avg       0.50      0.50      0.50       214\n",
      "weighted avg       0.51      0.50      0.49       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5327102803738317 and f1 score is: 0.4802292820363354\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.24      0.32        95\n",
      "           1       0.56      0.76      0.65       119\n",
      "\n",
      "    accuracy                           0.53       214\n",
      "   macro avg       0.50      0.50      0.48       214\n",
      "weighted avg       0.51      0.53      0.50       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.42990654205607476 and f1 score is: 0.4022893772893773\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.73      0.53        95\n",
      "           1       0.47      0.19      0.27       119\n",
      "\n",
      "    accuracy                           0.43       214\n",
      "   macro avg       0.44      0.46      0.40       214\n",
      "weighted avg       0.45      0.43      0.39       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5280373831775701 and f1 score is: 0.5262892585530496\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.53      0.50        95\n",
      "           1       0.58      0.53      0.56       119\n",
      "\n",
      "    accuracy                           0.53       214\n",
      "   macro avg       0.53      0.53      0.53       214\n",
      "weighted avg       0.53      0.53      0.53       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1419.csv ---\n",
      "[15:52:41] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5841121495327103 and f1 score is: 0.5418440739938899\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.32      0.40        95\n",
      "           1       0.59      0.80      0.68       119\n",
      "\n",
      "    accuracy                           0.58       214\n",
      "   macro avg       0.57      0.56      0.54       214\n",
      "weighted avg       0.58      0.58      0.56       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5186915887850467 and f1 score is: 0.5038602651540729\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.39      0.42        95\n",
      "           1       0.56      0.62      0.59       119\n",
      "\n",
      "    accuracy                           0.52       214\n",
      "   macro avg       0.51      0.51      0.50       214\n",
      "weighted avg       0.51      0.52      0.51       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.42592592592592593 and f1 score is: 0.4259040506039706\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.29      0.43       122\n",
      "           1       0.28      0.85      0.42        40\n",
      "\n",
      "    accuracy                           0.43       162\n",
      "   macro avg       0.57      0.57      0.43       162\n",
      "weighted avg       0.71      0.43      0.43       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.30246913580246915 and f1 score is: 0.2947023694856482\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.13      0.22       122\n",
      "           1       0.24      0.82      0.37        40\n",
      "\n",
      "    accuracy                           0.30       162\n",
      "   macro avg       0.47      0.48      0.29       162\n",
      "weighted avg       0.58      0.30      0.26       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.3765432098765432 and f1 score is: 0.37365539945641774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.30      0.42       122\n",
      "           1       0.23      0.62      0.33        40\n",
      "\n",
      "    accuracy                           0.38       162\n",
      "   macro avg       0.47      0.46      0.37       162\n",
      "weighted avg       0.59      0.38      0.40       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.7098765432098766 and f1 score is: 0.4531351001939238\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83       122\n",
      "           1       0.18      0.05      0.08        40\n",
      "\n",
      "    accuracy                           0.71       162\n",
      "   macro avg       0.47      0.49      0.45       162\n",
      "weighted avg       0.61      0.71      0.64       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.30864197530864196 and f1 score is: 0.30482758620689654\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.16      0.25       122\n",
      "           1       0.23      0.78      0.36        40\n",
      "\n",
      "    accuracy                           0.31       162\n",
      "   macro avg       0.45      0.47      0.30       162\n",
      "weighted avg       0.57      0.31      0.28       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.30246913580246915 and f1 score is: 0.2927404087625082\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.12      0.21       122\n",
      "           1       0.24      0.85      0.38        40\n",
      "\n",
      "    accuracy                           0.30       162\n",
      "   macro avg       0.48      0.49      0.29       162\n",
      "weighted avg       0.60      0.30      0.25       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1517.csv ---\n",
      "[15:54:45] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.41358024691358025 and f1 score is: 0.4097794822627038\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.33      0.46       122\n",
      "           1       0.25      0.68      0.36        40\n",
      "\n",
      "    accuracy                           0.41       162\n",
      "   macro avg       0.50      0.50      0.41       162\n",
      "weighted avg       0.63      0.41      0.43       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.4567901234567901 and f1 score is: 0.44999999999999996\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.38      0.51       122\n",
      "           1       0.27      0.70      0.39        40\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.53      0.54      0.45       162\n",
      "weighted avg       0.66      0.46      0.48       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6304347826086957 and f1 score is: 0.571975916803503\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.60      0.41        10\n",
      "           1       0.85      0.64      0.73        36\n",
      "\n",
      "    accuracy                           0.63        46\n",
      "   macro avg       0.58      0.62      0.57        46\n",
      "weighted avg       0.74      0.63      0.66        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.2391304347826087 and f1 score is: 0.20884520884520882\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36        10\n",
      "           1       1.00      0.03      0.05        36\n",
      "\n",
      "    accuracy                           0.24        46\n",
      "   macro avg       0.61      0.51      0.21        46\n",
      "weighted avg       0.83      0.24      0.12        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6086956521739131 and f1 score is: 0.5548387096774194\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.60      0.40        10\n",
      "           1       0.85      0.61      0.71        36\n",
      "\n",
      "    accuracy                           0.61        46\n",
      "   macro avg       0.57      0.61      0.55        46\n",
      "weighted avg       0.73      0.61      0.64        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.43478260869565216 and f1 score is: 0.43047619047619046\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.80      0.38        10\n",
      "           1       0.86      0.33      0.48        36\n",
      "\n",
      "    accuracy                           0.43        46\n",
      "   macro avg       0.55      0.57      0.43        46\n",
      "weighted avg       0.73      0.43      0.46        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.21739130434782608 and f1 score is: 0.17857142857142855\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36        10\n",
      "           1       1.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.22        46\n",
      "   macro avg       0.61      0.50      0.18        46\n",
      "weighted avg       0.83      0.22      0.08        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6521739130434783 and f1 score is: 0.5490196078431372\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33        10\n",
      "           1       0.81      0.72      0.76        36\n",
      "\n",
      "    accuracy                           0.65        46\n",
      "   macro avg       0.55      0.56      0.55        46\n",
      "weighted avg       0.70      0.65      0.67        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1544.csv ---\n",
      "[15:56:55] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.7608695652173914 and f1 score is: 0.6811594202898551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.60      0.52        10\n",
      "           1       0.88      0.81      0.84        36\n",
      "\n",
      "    accuracy                           0.76        46\n",
      "   macro avg       0.67      0.70      0.68        46\n",
      "weighted avg       0.79      0.76      0.77        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6521739130434783 and f1 score is: 0.6349206349206349\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.56        10\n",
      "           1       1.00      0.56      0.71        36\n",
      "\n",
      "    accuracy                           0.65        46\n",
      "   macro avg       0.69      0.78      0.63        46\n",
      "weighted avg       0.87      0.65      0.68        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5660377358490566 and f1 score is: 0.49398090493980906\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.21      0.30        73\n",
      "           1       0.56      0.87      0.68        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.57      0.54      0.49       159\n",
      "weighted avg       0.57      0.57      0.51       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5471698113207547 and f1 score is: 0.5471518987341772\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.60      0.55        73\n",
      "           1       0.60      0.50      0.54        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.55      0.55      0.55       159\n",
      "weighted avg       0.56      0.55      0.55       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5471698113207547 and f1 score is: 0.5457142857142857\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.53      0.52        73\n",
      "           1       0.59      0.56      0.57        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.55      0.55      0.55       159\n",
      "weighted avg       0.55      0.55      0.55       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5283018867924528 and f1 score is: 0.5221781464118284\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.45      0.47        73\n",
      "           1       0.56      0.59      0.58        86\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.52      0.52      0.52       159\n",
      "weighted avg       0.53      0.53      0.53       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5345911949685535 and f1 score is: 0.5341305036426988\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.55      0.52        73\n",
      "           1       0.58      0.52      0.55        86\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.54      0.54      0.53       159\n",
      "weighted avg       0.54      0.53      0.54       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5723270440251572 and f1 score is: 0.5232804232804233\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.27      0.37        73\n",
      "           1       0.57      0.83      0.68        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.57      0.55      0.52       159\n",
      "weighted avg       0.57      0.57      0.54       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1624.csv ---\n",
      "[15:59:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5723270440251572 and f1 score is: 0.5684865900383141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53        73\n",
      "           1       0.60      0.62      0.61        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.57      0.57      0.57       159\n",
      "weighted avg       0.57      0.57      0.57       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5534591194968553 and f1 score is: 0.5533884559085334\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.59      0.55        73\n",
      "           1       0.60      0.52      0.56        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.56      0.56      0.55       159\n",
      "weighted avg       0.56      0.55      0.55       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6685082872928176 and f1 score is: 0.40066225165562913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        60\n",
      "           1       0.67      1.00      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.83      0.50      0.40       181\n",
      "weighted avg       0.78      0.67      0.54       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6685082872928176 and f1 score is: 0.41612903225806447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.02      0.03        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.59      0.50      0.42       181\n",
      "weighted avg       0.61      0.67      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6464088397790055 and f1 score is: 0.5195753151957532\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.20      0.27        60\n",
      "           1       0.69      0.87      0.77       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.56      0.53      0.52       181\n",
      "weighted avg       0.60      0.65      0.60       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.3756906077348066 and f1 score is: 0.3499761639917368\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.27      0.22        60\n",
      "           1       0.54      0.43      0.48       121\n",
      "\n",
      "    accuracy                           0.38       181\n",
      "   macro avg       0.36      0.35      0.35       181\n",
      "weighted avg       0.42      0.38      0.39       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6519337016574586 and f1 score is: 0.3946488294314381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.66      0.98      0.79       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.33      0.49      0.39       181\n",
      "weighted avg       0.44      0.65      0.53       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6464088397790055 and f1 score is: 0.4670592565329408\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.10      0.16        60\n",
      "           1       0.67      0.92      0.78       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.52      0.51      0.47       181\n",
      "weighted avg       0.57      0.65      0.57       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1688.csv ---\n",
      "[16:01:11] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6464088397790055 and f1 score is: 0.5731132075471699\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.35      0.40        60\n",
      "           1       0.71      0.79      0.75       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.58      0.57      0.57       181\n",
      "weighted avg       0.63      0.65      0.63       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5359116022099447 and f1 score is: 0.5053357626236337\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.43      0.38        60\n",
      "           1       0.68      0.59      0.63       121\n",
      "\n",
      "    accuracy                           0.54       181\n",
      "   macro avg       0.51      0.51      0.51       181\n",
      "weighted avg       0.57      0.54      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.7314814814814815 and f1 score is: 0.5634843205574913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.18      0.29        34\n",
      "           1       0.72      0.99      0.83        74\n",
      "\n",
      "    accuracy                           0.73       108\n",
      "   macro avg       0.79      0.58      0.56       108\n",
      "weighted avg       0.77      0.73      0.66       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.37037037037037035 and f1 score is: 0.34311270125223614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.91      0.48        34\n",
      "           1       0.75      0.12      0.21        74\n",
      "\n",
      "    accuracy                           0.37       108\n",
      "   macro avg       0.54      0.52      0.34       108\n",
      "weighted avg       0.62      0.37      0.29       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.4074074074074074 and f1 score is: 0.4041379310344828\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.53      0.36        34\n",
      "           1       0.62      0.35      0.45        74\n",
      "\n",
      "    accuracy                           0.41       108\n",
      "   macro avg       0.45      0.44      0.40       108\n",
      "weighted avg       0.51      0.41      0.42       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.46296296296296297 and f1 score is: 0.4613003095975232\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.82      0.49        34\n",
      "           1       0.79      0.30      0.43        74\n",
      "\n",
      "    accuracy                           0.46       108\n",
      "   macro avg       0.57      0.56      0.46       108\n",
      "weighted avg       0.65      0.46      0.45       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.37037037037037035 and f1 score is: 0.35960934775026165\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.79      0.44        34\n",
      "           1       0.65      0.18      0.28        74\n",
      "\n",
      "    accuracy                           0.37       108\n",
      "   macro avg       0.48      0.48      0.36       108\n",
      "weighted avg       0.54      0.37      0.33       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5185185185185185 and f1 score is: 0.4721804511278196\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.35      0.32        34\n",
      "           1       0.67      0.59      0.63        74\n",
      "\n",
      "    accuracy                           0.52       108\n",
      "   macro avg       0.48      0.47      0.47       108\n",
      "weighted avg       0.55      0.52      0.53       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1717.csv ---\n",
      "[16:03:18] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.75 and f1 score is: 0.7305737780652315\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.76      0.66        34\n",
      "           1       0.87      0.74      0.80        74\n",
      "\n",
      "    accuracy                           0.75       108\n",
      "   macro avg       0.73      0.75      0.73       108\n",
      "weighted avg       0.78      0.75      0.76       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.4722222222222222 and f1 score is: 0.4618410700236034\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.53      0.39        34\n",
      "           1       0.67      0.45      0.54        74\n",
      "\n",
      "    accuracy                           0.47       108\n",
      "   macro avg       0.49      0.49      0.46       108\n",
      "weighted avg       0.56      0.47      0.49       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5370370370370371 and f1 score is: 0.4716242661448141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.17      0.29        86\n",
      "           1       0.50      0.95      0.66        76\n",
      "\n",
      "    accuracy                           0.54       162\n",
      "   macro avg       0.65      0.56      0.47       162\n",
      "weighted avg       0.66      0.54      0.46       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5555555555555556 and f1 score is: 0.5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.21      0.33        86\n",
      "           1       0.51      0.95      0.67        76\n",
      "\n",
      "    accuracy                           0.56       162\n",
      "   macro avg       0.67      0.58      0.50       162\n",
      "weighted avg       0.68      0.56      0.49       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.49382716049382713 and f1 score is: 0.4069642857142857\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.10      0.18        86\n",
      "           1       0.48      0.93      0.63        76\n",
      "\n",
      "    accuracy                           0.49       162\n",
      "   macro avg       0.56      0.52      0.41       162\n",
      "weighted avg       0.57      0.49      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5987654320987654 and f1 score is: 0.588976931183887\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.42      0.53        86\n",
      "           1       0.55      0.80      0.65        76\n",
      "\n",
      "    accuracy                           0.60       162\n",
      "   macro avg       0.63      0.61      0.59       162\n",
      "weighted avg       0.63      0.60      0.59       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5679012345679012 and f1 score is: 0.5182667799490229\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.23      0.36        86\n",
      "           1       0.52      0.95      0.67        76\n",
      "\n",
      "    accuracy                           0.57       162\n",
      "   macro avg       0.68      0.59      0.52       162\n",
      "weighted avg       0.69      0.57      0.51       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.48148148148148145 and f1 score is: 0.40524475524475523\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.12      0.19        86\n",
      "           1       0.47      0.89      0.62        76\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.51      0.51      0.41       162\n",
      "weighted avg       0.52      0.48      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1765.csv ---\n",
      "[16:05:26] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5123456790123457 and f1 score is: 0.43178084624605956\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.13      0.22        86\n",
      "           1       0.49      0.95      0.65        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.61      0.54      0.43       162\n",
      "weighted avg       0.62      0.51      0.42       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5123456790123457 and f1 score is: 0.47897243822008706\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.24      0.35        86\n",
      "           1       0.49      0.82      0.61        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.54      0.53      0.48       162\n",
      "weighted avg       0.55      0.51      0.47       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.9339622641509434 and f1 score is: 0.6644052464947987\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.25      0.36        16\n",
      "           1       0.94      0.99      0.97       196\n",
      "\n",
      "    accuracy                           0.93       212\n",
      "   macro avg       0.80      0.62      0.66       212\n",
      "weighted avg       0.92      0.93      0.92       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7216981132075472 and f1 score is: 0.450028580222486\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.12      0.06        16\n",
      "           1       0.92      0.77      0.84       196\n",
      "\n",
      "    accuracy                           0.72       212\n",
      "   macro avg       0.48      0.45      0.45       212\n",
      "weighted avg       0.85      0.72      0.78       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7405660377358491 and f1 score is: 0.5003214056138847\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.31      0.15        16\n",
      "           1       0.93      0.78      0.85       196\n",
      "\n",
      "    accuracy                           0.74       212\n",
      "   macro avg       0.52      0.54      0.50       212\n",
      "weighted avg       0.87      0.74      0.79       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.4386792452830189 and f1 score is: 0.3533769063180827\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.50      0.12        16\n",
      "           1       0.91      0.43      0.59       196\n",
      "\n",
      "    accuracy                           0.44       212\n",
      "   macro avg       0.49      0.47      0.35       212\n",
      "weighted avg       0.85      0.44      0.55       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6933962264150944 and f1 score is: 0.4238889585685021\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.06      0.03        16\n",
      "           1       0.91      0.74      0.82       196\n",
      "\n",
      "    accuracy                           0.69       212\n",
      "   macro avg       0.46      0.40      0.42       212\n",
      "weighted avg       0.84      0.69      0.76       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8301886792452831 and f1 score is: 0.5610766045548654\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.31      0.22        16\n",
      "           1       0.94      0.87      0.90       196\n",
      "\n",
      "    accuracy                           0.83       212\n",
      "   macro avg       0.55      0.59      0.56       212\n",
      "weighted avg       0.88      0.83      0.85       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1818.csv ---\n",
      "[16:07:32] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.910377358490566 and f1 score is: 0.6242186771154026\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.25      0.30        16\n",
      "           1       0.94      0.96      0.95       196\n",
      "\n",
      "    accuracy                           0.91       212\n",
      "   macro avg       0.65      0.61      0.62       212\n",
      "weighted avg       0.90      0.91      0.90       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.9245283018867925 and f1 score is: 0.6466666666666666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.25      0.33        16\n",
      "           1       0.94      0.98      0.96       196\n",
      "\n",
      "    accuracy                           0.92       212\n",
      "   macro avg       0.72      0.61      0.65       212\n",
      "weighted avg       0.91      0.92      0.91       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5740740740740741 and f1 score is: 0.4938359653591442\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.70       162\n",
      "           1       0.25      0.35      0.29        54\n",
      "\n",
      "    accuracy                           0.57       216\n",
      "   macro avg       0.50      0.50      0.49       216\n",
      "weighted avg       0.62      0.57      0.59       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4675925925925926 and f1 score is: 0.44562233579574617\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.44      0.56       162\n",
      "           1       0.24      0.54      0.34        54\n",
      "\n",
      "    accuracy                           0.47       216\n",
      "   macro avg       0.49      0.49      0.45       216\n",
      "weighted avg       0.62      0.47      0.50       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.48148148148148145 and f1 score is: 0.4521242866201649\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.48      0.58       162\n",
      "           1       0.24      0.50      0.33        54\n",
      "\n",
      "    accuracy                           0.48       216\n",
      "   macro avg       0.49      0.49      0.45       216\n",
      "weighted avg       0.62      0.48      0.52       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.3055555555555556 and f1 score is: 0.30501930501930496\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.19      0.29       162\n",
      "           1       0.21      0.67      0.32        54\n",
      "\n",
      "    accuracy                           0.31       216\n",
      "   macro avg       0.42      0.43      0.31       216\n",
      "weighted avg       0.52      0.31      0.30       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.42592592592592593 and f1 score is: 0.4075909050694506\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.40      0.51       162\n",
      "           1       0.22      0.50      0.30        54\n",
      "\n",
      "    accuracy                           0.43       216\n",
      "   macro avg       0.46      0.45      0.41       216\n",
      "weighted avg       0.58      0.43      0.46       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5092592592592593 and f1 score is: 0.44400194269062654\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.57      0.63       162\n",
      "           1       0.20      0.33      0.25        54\n",
      "\n",
      "    accuracy                           0.51       216\n",
      "   macro avg       0.46      0.45      0.44       216\n",
      "weighted avg       0.59      0.51      0.54       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1892.csv ---\n",
      "[16:09:39] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.6157407407407407 and f1 score is: 0.5135531135531135\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74       162\n",
      "           1       0.27      0.31      0.29        54\n",
      "\n",
      "    accuracy                           0.62       216\n",
      "   macro avg       0.51      0.52      0.51       216\n",
      "weighted avg       0.64      0.62      0.63       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.6435185185185185 and f1 score is: 0.5275939443860596\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76       162\n",
      "           1       0.29      0.30      0.29        54\n",
      "\n",
      "    accuracy                           0.64       216\n",
      "   macro avg       0.53      0.53      0.53       216\n",
      "weighted avg       0.65      0.64      0.64       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5613207547169812 and f1 score is: 0.45678468108554904\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.20      0.22        65\n",
      "           1       0.67      0.72      0.70       147\n",
      "\n",
      "    accuracy                           0.56       212\n",
      "   macro avg       0.46      0.46      0.46       212\n",
      "weighted avg       0.54      0.56      0.55       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6132075471698113 and f1 score is: 0.4707100231396906\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.15      0.20        65\n",
      "           1       0.69      0.82      0.75       147\n",
      "\n",
      "    accuracy                           0.61       212\n",
      "   macro avg       0.48      0.49      0.47       212\n",
      "weighted avg       0.56      0.61      0.58       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5754716981132075 and f1 score is: 0.500784929356358\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.31      0.31        65\n",
      "           1       0.69      0.69      0.69       147\n",
      "\n",
      "    accuracy                           0.58       212\n",
      "   macro avg       0.50      0.50      0.50       212\n",
      "weighted avg       0.58      0.58      0.58       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6273584905660378 and f1 score is: 0.4999850723988656\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.20      0.25        65\n",
      "           1       0.70      0.82      0.75       147\n",
      "\n",
      "    accuracy                           0.63       212\n",
      "   macro avg       0.51      0.51      0.50       212\n",
      "weighted avg       0.58      0.63      0.60       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5943396226415094 and f1 score is: 0.47214823393167343\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.18      0.22        65\n",
      "           1       0.68      0.78      0.73       147\n",
      "\n",
      "    accuracy                           0.59       212\n",
      "   macro avg       0.47      0.48      0.47       212\n",
      "weighted avg       0.56      0.59      0.57       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5188679245283019 and f1 score is: 0.4636904761904762\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.32      0.29        65\n",
      "           1       0.67      0.61      0.64       147\n",
      "\n",
      "    accuracy                           0.52       212\n",
      "   macro avg       0.47      0.46      0.46       212\n",
      "weighted avg       0.55      0.52      0.53       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1929.csv ---\n",
      "[16:11:43] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5943396226415094 and f1 score is: 0.48969995521719667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.23      0.26        65\n",
      "           1       0.69      0.76      0.72       147\n",
      "\n",
      "    accuracy                           0.59       212\n",
      "   macro avg       0.49      0.49      0.49       212\n",
      "weighted avg       0.57      0.59      0.58       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5660377358490566 and f1 score is: 0.4706329388774292\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.23      0.25        65\n",
      "           1       0.68      0.71      0.70       147\n",
      "\n",
      "    accuracy                           0.57       212\n",
      "   macro avg       0.47      0.47      0.47       212\n",
      "weighted avg       0.55      0.57      0.56       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5 and f1 score is: 0.3807865892972276\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.08      0.11        36\n",
      "           1       0.58      0.74      0.65        62\n",
      "\n",
      "    accuracy                           0.50        98\n",
      "   macro avg       0.37      0.41      0.38        98\n",
      "weighted avg       0.43      0.50      0.45        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6122448979591837 and f1 score is: 0.6041666666666666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.64      0.55        36\n",
      "           1       0.74      0.60      0.66        62\n",
      "\n",
      "    accuracy                           0.61        98\n",
      "   macro avg       0.61      0.62      0.60        98\n",
      "weighted avg       0.64      0.61      0.62        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5204081632653061 and f1 score is: 0.45029239766081874\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.22      0.25        36\n",
      "           1       0.61      0.69      0.65        62\n",
      "\n",
      "    accuracy                           0.52        98\n",
      "   macro avg       0.45      0.46      0.45        98\n",
      "weighted avg       0.49      0.52      0.50        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6224489795918368 and f1 score is: 0.5672514619883041\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.36      0.41        36\n",
      "           1       0.68      0.77      0.72        62\n",
      "\n",
      "    accuracy                           0.62        98\n",
      "   macro avg       0.58      0.57      0.57        98\n",
      "weighted avg       0.60      0.62      0.61        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6326530612244898 and f1 score is: 0.625\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57        36\n",
      "           1       0.76      0.61      0.68        62\n",
      "\n",
      "    accuracy                           0.63        98\n",
      "   macro avg       0.63      0.64      0.62        98\n",
      "weighted avg       0.66      0.63      0.64        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5510204081632653 and f1 score is: 0.46126936531734136\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.19      0.24        36\n",
      "           1       0.62      0.76      0.68        62\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.47      0.48      0.46        98\n",
      "weighted avg       0.51      0.55      0.52        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1933.csv ---\n",
      "[16:13:52] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5102040816326531 and f1 score is: 0.4595588235294118\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29        36\n",
      "           1       0.61      0.65      0.62        62\n",
      "\n",
      "    accuracy                           0.51        98\n",
      "   macro avg       0.46      0.46      0.46        98\n",
      "weighted avg       0.50      0.51      0.50        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5 and f1 score is: 0.4880051178163983\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.47      0.41        36\n",
      "           1       0.63      0.52      0.57        62\n",
      "\n",
      "    accuracy                           0.50        98\n",
      "   macro avg       0.49      0.49      0.49        98\n",
      "weighted avg       0.53      0.50      0.51        98\n",
      "\n",
      "----- Running Modality Combination EDA_GAZE\n",
      "Saved Directory: 2022_08_11_16_14\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6009615384615384 and f1 score is: 0.5209634007602875\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.21      0.33        95\n",
      "           1       0.58      0.93      0.72       113\n",
      "\n",
      "    accuracy                           0.60       208\n",
      "   macro avg       0.65      0.57      0.52       208\n",
      "weighted avg       0.64      0.60      0.54       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6105769230769231 and f1 score is: 0.5449315290495097\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.25      0.37        95\n",
      "           1       0.59      0.91      0.72       113\n",
      "\n",
      "    accuracy                           0.61       208\n",
      "   macro avg       0.65      0.58      0.54       208\n",
      "weighted avg       0.64      0.61      0.56       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6105769230769231 and f1 score is: 0.5978517722878625\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.47      0.53        95\n",
      "           1       0.62      0.73      0.67       113\n",
      "\n",
      "    accuracy                           0.61       208\n",
      "   macro avg       0.61      0.60      0.60       208\n",
      "weighted avg       0.61      0.61      0.60       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5432692307692307 and f1 score is: 0.4971370403359206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.26      0.34        95\n",
      "           1       0.56      0.78      0.65       113\n",
      "\n",
      "    accuracy                           0.54       208\n",
      "   macro avg       0.53      0.52      0.50       208\n",
      "weighted avg       0.53      0.54      0.51       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5913461538461539 and f1 score is: 0.5139518900343643\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.21      0.32        95\n",
      "           1       0.58      0.91      0.71       113\n",
      "\n",
      "    accuracy                           0.59       208\n",
      "   macro avg       0.62      0.56      0.51       208\n",
      "weighted avg       0.62      0.59      0.53       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6394230769230769 and f1 score is: 0.6248466921578529\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.48      0.55        95\n",
      "           1       0.64      0.77      0.70       113\n",
      "\n",
      "    accuracy                           0.64       208\n",
      "   macro avg       0.64      0.63      0.62       208\n",
      "weighted avg       0.64      0.64      0.63       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1105.csv ---\n",
      "[16:15:20] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6298076923076923 and f1 score is: 0.6116297679381169\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.45      0.53        95\n",
      "           1       0.63      0.78      0.70       113\n",
      "\n",
      "    accuracy                           0.63       208\n",
      "   macro avg       0.63      0.62      0.61       208\n",
      "weighted avg       0.63      0.63      0.62       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6009615384615384 and f1 score is: 0.5951124557330144\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.53      0.55        95\n",
      "           1       0.62      0.66      0.64       113\n",
      "\n",
      "    accuracy                           0.60       208\n",
      "   macro avg       0.60      0.60      0.60       208\n",
      "weighted avg       0.60      0.60      0.60       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8707482993197279 and f1 score is: 0.6918918918918918\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.50      0.46        16\n",
      "           1       0.94      0.92      0.93       131\n",
      "\n",
      "    accuracy                           0.87       147\n",
      "   macro avg       0.68      0.71      0.69       147\n",
      "weighted avg       0.88      0.87      0.88       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8775510204081632 and f1 score is: 0.728001644736842\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.62      0.53        16\n",
      "           1       0.95      0.91      0.93       131\n",
      "\n",
      "    accuracy                           0.88       147\n",
      "   macro avg       0.70      0.77      0.73       147\n",
      "weighted avg       0.90      0.88      0.89       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7619047619047619 and f1 score is: 0.6289217454020917\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.75      0.41        16\n",
      "           1       0.96      0.76      0.85       131\n",
      "\n",
      "    accuracy                           0.76       147\n",
      "   macro avg       0.62      0.76      0.63       147\n",
      "weighted avg       0.89      0.76      0.80       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7687074829931972 and f1 score is: 0.590327868852459\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.50      0.32        16\n",
      "           1       0.93      0.80      0.86       131\n",
      "\n",
      "    accuracy                           0.77       147\n",
      "   macro avg       0.58      0.65      0.59       147\n",
      "weighted avg       0.85      0.77      0.80       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8231292517006803 and f1 score is: 0.6649719495091164\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.62      0.43        16\n",
      "           1       0.95      0.85      0.90       131\n",
      "\n",
      "    accuracy                           0.82       147\n",
      "   macro avg       0.64      0.74      0.66       147\n",
      "weighted avg       0.88      0.82      0.85       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.6122448979591837 and f1 score is: 0.5066823667942302\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.69      0.28        16\n",
      "           1       0.94      0.60      0.73       131\n",
      "\n",
      "    accuracy                           0.61       147\n",
      "   macro avg       0.56      0.65      0.51       147\n",
      "weighted avg       0.86      0.61      0.69       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1106.csv ---\n",
      "[16:16:13] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8367346938775511 and f1 score is: 0.6907433380084151\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.69      0.48        16\n",
      "           1       0.96      0.85      0.90       131\n",
      "\n",
      "    accuracy                           0.84       147\n",
      "   macro avg       0.66      0.77      0.69       147\n",
      "weighted avg       0.89      0.84      0.86       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7891156462585034 and f1 score is: 0.620408163265306\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.56      0.37        16\n",
      "           1       0.94      0.82      0.87       131\n",
      "\n",
      "    accuracy                           0.79       147\n",
      "   macro avg       0.61      0.69      0.62       147\n",
      "weighted avg       0.87      0.79      0.82       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5310734463276836 and f1 score is: 0.4029262345051819\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.07      0.13        84\n",
      "           1       0.53      0.95      0.68        93\n",
      "\n",
      "    accuracy                           0.53       177\n",
      "   macro avg       0.54      0.51      0.40       177\n",
      "weighted avg       0.54      0.53      0.42       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.576271186440678 and f1 score is: 0.49771084793219567\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.19      0.30        84\n",
      "           1       0.56      0.92      0.70        93\n",
      "\n",
      "    accuracy                           0.58       177\n",
      "   macro avg       0.63      0.56      0.50       177\n",
      "weighted avg       0.62      0.58      0.51       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.576271186440678 and f1 score is: 0.5125399331693166\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.23      0.34        84\n",
      "           1       0.56      0.89      0.69        93\n",
      "\n",
      "    accuracy                           0.58       177\n",
      "   macro avg       0.61      0.56      0.51       177\n",
      "weighted avg       0.61      0.58      0.52       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.615819209039548 and f1 score is: 0.5600877192982456\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.27      0.40        84\n",
      "           1       0.59      0.92      0.72        93\n",
      "\n",
      "    accuracy                           0.62       177\n",
      "   macro avg       0.68      0.60      0.56       177\n",
      "weighted avg       0.67      0.62      0.57       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.576271186440678 and f1 score is: 0.49771084793219567\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.19      0.30        84\n",
      "           1       0.56      0.92      0.70        93\n",
      "\n",
      "    accuracy                           0.58       177\n",
      "   macro avg       0.63      0.56      0.50       177\n",
      "weighted avg       0.62      0.58      0.51       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.536723163841808 and f1 score is: 0.45370370370370366\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.15      0.24        84\n",
      "           1       0.54      0.88      0.67        93\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.54      0.52      0.45       177\n",
      "weighted avg       0.54      0.54      0.46       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1175.csv ---\n",
      "[16:17:06] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.6384180790960452 and f1 score is: 0.6056808688387636\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.37      0.49        84\n",
      "           1       0.61      0.88      0.72        93\n",
      "\n",
      "    accuracy                           0.64       177\n",
      "   macro avg       0.67      0.63      0.61       177\n",
      "weighted avg       0.67      0.64      0.61       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.6045197740112994 and f1 score is: 0.5884267871379218\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.43      0.51        84\n",
      "           1       0.60      0.76      0.67        93\n",
      "\n",
      "    accuracy                           0.60       177\n",
      "   macro avg       0.61      0.60      0.59       177\n",
      "weighted avg       0.61      0.60      0.59       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5833333333333334 and f1 score is: 0.557699308336367\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.33      0.45       113\n",
      "           1       0.54      0.86      0.66       103\n",
      "\n",
      "    accuracy                           0.58       216\n",
      "   macro avg       0.63      0.60      0.56       216\n",
      "weighted avg       0.64      0.58      0.55       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5138888888888888 and f1 score is: 0.4248180365702113\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.12      0.20       113\n",
      "           1       0.49      0.95      0.65       103\n",
      "\n",
      "    accuracy                           0.51       216\n",
      "   macro avg       0.61      0.53      0.42       216\n",
      "weighted avg       0.61      0.51      0.41       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5601851851851852 and f1 score is: 0.5383265462235922\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.33      0.44       113\n",
      "           1       0.53      0.82      0.64       103\n",
      "\n",
      "    accuracy                           0.56       216\n",
      "   macro avg       0.59      0.57      0.54       216\n",
      "weighted avg       0.60      0.56      0.53       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.4722222222222222 and f1 score is: 0.4644628099173554\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.57      0.53       113\n",
      "           1       0.44      0.37      0.40       103\n",
      "\n",
      "    accuracy                           0.47       216\n",
      "   macro avg       0.47      0.47      0.46       216\n",
      "weighted avg       0.47      0.47      0.47       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5092592592592593 and f1 score is: 0.41681100356597045\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.11      0.18       113\n",
      "           1       0.49      0.95      0.65       103\n",
      "\n",
      "    accuracy                           0.51       216\n",
      "   macro avg       0.60      0.53      0.42       216\n",
      "weighted avg       0.60      0.51      0.41       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5370370370370371 and f1 score is: 0.530230535015224\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.40      0.47       113\n",
      "           1       0.51      0.69      0.59       103\n",
      "\n",
      "    accuracy                           0.54       216\n",
      "   macro avg       0.55      0.54      0.53       216\n",
      "weighted avg       0.55      0.54      0.53       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1337.csv ---\n",
      "[16:18:00] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5740740740740741 and f1 score is: 0.5573376102646351\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.36      0.47       113\n",
      "           1       0.54      0.81      0.64       103\n",
      "\n",
      "    accuracy                           0.57       216\n",
      "   macro avg       0.60      0.58      0.56       216\n",
      "weighted avg       0.61      0.57      0.55       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6111111111111112 and f1 score is: 0.6012307692307692\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.43      0.54       113\n",
      "           1       0.56      0.81      0.66       103\n",
      "\n",
      "    accuracy                           0.61       216\n",
      "   macro avg       0.64      0.62      0.60       216\n",
      "weighted avg       0.64      0.61      0.60       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.596244131455399 and f1 score is: 0.551908023483366\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.32      0.41        95\n",
      "           1       0.60      0.82      0.69       118\n",
      "\n",
      "    accuracy                           0.60       213\n",
      "   macro avg       0.59      0.57      0.55       213\n",
      "weighted avg       0.59      0.60      0.57       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.6150234741784038 and f1 score is: 0.6055555555555556\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.52      0.54        95\n",
      "           1       0.64      0.69      0.67       118\n",
      "\n",
      "    accuracy                           0.62       213\n",
      "   macro avg       0.61      0.61      0.61       213\n",
      "weighted avg       0.61      0.62      0.61       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5539906103286385 and f1 score is: 0.5449639074411388\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.46      0.48        95\n",
      "           1       0.59      0.63      0.61       118\n",
      "\n",
      "    accuracy                           0.55       213\n",
      "   macro avg       0.55      0.55      0.54       213\n",
      "weighted avg       0.55      0.55      0.55       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.6056338028169014 and f1 score is: 0.5623287671232877\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.33      0.42        95\n",
      "           1       0.60      0.83      0.70       118\n",
      "\n",
      "    accuracy                           0.61       213\n",
      "   macro avg       0.61      0.58      0.56       213\n",
      "weighted avg       0.61      0.61      0.58       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.6150234741784038 and f1 score is: 0.6043403407031533\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.51      0.54        95\n",
      "           1       0.64      0.70      0.67       118\n",
      "\n",
      "    accuracy                           0.62       213\n",
      "   macro avg       0.61      0.60      0.60       213\n",
      "weighted avg       0.61      0.62      0.61       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5539906103286385 and f1 score is: 0.5539512840295382\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.63      0.56        95\n",
      "           1       0.62      0.49      0.55       118\n",
      "\n",
      "    accuracy                           0.55       213\n",
      "   macro avg       0.56      0.56      0.55       213\n",
      "weighted avg       0.57      0.55      0.55       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1390.csv ---\n",
      "[16:18:53] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5868544600938967 and f1 score is: 0.5617283950617284\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.39      0.46        95\n",
      "           1       0.60      0.75      0.67       118\n",
      "\n",
      "    accuracy                           0.59       213\n",
      "   macro avg       0.58      0.57      0.56       213\n",
      "weighted avg       0.58      0.59      0.57       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.6056338028169014 and f1 score is: 0.5981854114265182\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.53      0.54        95\n",
      "           1       0.64      0.67      0.65       118\n",
      "\n",
      "    accuracy                           0.61       213\n",
      "   macro avg       0.60      0.60      0.60       213\n",
      "weighted avg       0.60      0.61      0.60       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5285714285714286 and f1 score is: 0.5280470363896393\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.43      0.54       136\n",
      "           1       0.40      0.70      0.51        74\n",
      "\n",
      "    accuracy                           0.53       210\n",
      "   macro avg       0.57      0.57      0.53       210\n",
      "weighted avg       0.61      0.53      0.53       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6285714285714286 and f1 score is: 0.5537271142109852\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74       136\n",
      "           1       0.46      0.31      0.37        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.57      0.56      0.55       210\n",
      "weighted avg       0.60      0.63      0.61       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6285714285714286 and f1 score is: 0.6043095951299643\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.70       136\n",
      "           1       0.48      0.54      0.51        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.60      0.61      0.60       210\n",
      "weighted avg       0.64      0.63      0.63       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6047619047619047 and f1 score is: 0.4515245917115075\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.88      0.74       136\n",
      "           1       0.32      0.11      0.16        74\n",
      "\n",
      "    accuracy                           0.60       210\n",
      "   macro avg       0.48      0.49      0.45       210\n",
      "weighted avg       0.53      0.60      0.54       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5952380952380952 and f1 score is: 0.56770240488242\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.68       136\n",
      "           1       0.43      0.49      0.46        74\n",
      "\n",
      "    accuracy                           0.60       210\n",
      "   macro avg       0.57      0.57      0.57       210\n",
      "weighted avg       0.61      0.60      0.60       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.47619047619047616 and f1 score is: 0.47614296081277213\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.36      0.47       136\n",
      "           1       0.37      0.69      0.48        74\n",
      "\n",
      "    accuracy                           0.48       210\n",
      "   macro avg       0.53      0.52      0.48       210\n",
      "weighted avg       0.57      0.48      0.47       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1400.csv ---\n",
      "[16:19:46] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5857142857142857 and f1 score is: 0.5815295815295816\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.53      0.62       136\n",
      "           1       0.44      0.69      0.54        74\n",
      "\n",
      "    accuracy                           0.59       210\n",
      "   macro avg       0.60      0.61      0.58       210\n",
      "weighted avg       0.65      0.59      0.59       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5047619047619047 and f1 score is: 0.5025510204081632\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.44      0.54       136\n",
      "           1       0.38      0.62      0.47        74\n",
      "\n",
      "    accuracy                           0.50       210\n",
      "   macro avg       0.53      0.53      0.50       210\n",
      "weighted avg       0.57      0.50      0.51       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5654205607476636 and f1 score is: 0.5045679719200418\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.24      0.33        95\n",
      "           1       0.58      0.82      0.68       119\n",
      "\n",
      "    accuracy                           0.57       214\n",
      "   macro avg       0.55      0.53      0.50       214\n",
      "weighted avg       0.55      0.57      0.52       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5794392523364486 and f1 score is: 0.5187406296851574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.25      0.35        95\n",
      "           1       0.58      0.84      0.69       119\n",
      "\n",
      "    accuracy                           0.58       214\n",
      "   macro avg       0.57      0.55      0.52       214\n",
      "weighted avg       0.57      0.58      0.54       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5607476635514018 and f1 score is: 0.5479550561797752\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.44      0.47        95\n",
      "           1       0.60      0.66      0.62       119\n",
      "\n",
      "    accuracy                           0.56       214\n",
      "   macro avg       0.55      0.55      0.55       214\n",
      "weighted avg       0.56      0.56      0.56       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5607476635514018 and f1 score is: 0.5493727598566307\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48        95\n",
      "           1       0.60      0.65      0.62       119\n",
      "\n",
      "    accuracy                           0.56       214\n",
      "   macro avg       0.55      0.55      0.55       214\n",
      "weighted avg       0.56      0.56      0.56       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5607476635514018 and f1 score is: 0.49345286059629334\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.22      0.31        95\n",
      "           1       0.57      0.83      0.68       119\n",
      "\n",
      "    accuracy                           0.56       214\n",
      "   macro avg       0.54      0.53      0.49       214\n",
      "weighted avg       0.55      0.56      0.51       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5700934579439252 and f1 score is: 0.5670302603800141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.74      0.60        95\n",
      "           1       0.68      0.44      0.53       119\n",
      "\n",
      "    accuracy                           0.57       214\n",
      "   macro avg       0.59      0.59      0.57       214\n",
      "weighted avg       0.60      0.57      0.56       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1419.csv ---\n",
      "[16:20:39] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5514018691588785 and f1 score is: 0.501020110754882\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.26      0.34        95\n",
      "           1       0.57      0.78      0.66       119\n",
      "\n",
      "    accuracy                           0.55       214\n",
      "   macro avg       0.53      0.52      0.50       214\n",
      "weighted avg       0.53      0.55      0.52       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5560747663551402 and f1 score is: 0.5221754765318354\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.39        95\n",
      "           1       0.58      0.74      0.65       119\n",
      "\n",
      "    accuracy                           0.56       214\n",
      "   macro avg       0.54      0.53      0.52       214\n",
      "weighted avg       0.54      0.56      0.54       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.7098765432098766 and f1 score is: 0.5130156699712184\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       122\n",
      "           1       0.32      0.15      0.20        40\n",
      "\n",
      "    accuracy                           0.71       162\n",
      "   macro avg       0.54      0.52      0.51       162\n",
      "weighted avg       0.65      0.71      0.67       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5 and f1 score is: 0.4449942900647127\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.54      0.62       122\n",
      "           1       0.21      0.38      0.27        40\n",
      "\n",
      "    accuracy                           0.50       162\n",
      "   macro avg       0.47      0.46      0.44       162\n",
      "weighted avg       0.60      0.50      0.53       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.6296296296296297 and f1 score is: 0.5020491803278688\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       122\n",
      "           1       0.25      0.25      0.25        40\n",
      "\n",
      "    accuracy                           0.63       162\n",
      "   macro avg       0.50      0.50      0.50       162\n",
      "weighted avg       0.63      0.63      0.63       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.36419753086419754 and f1 score is: 0.3486865217221593\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.34      0.45       122\n",
      "           1       0.18      0.42      0.25        40\n",
      "\n",
      "    accuracy                           0.36       162\n",
      "   macro avg       0.41      0.38      0.35       162\n",
      "weighted avg       0.53      0.36      0.40       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.46296296296296297 and f1 score is: 0.4299235529668729\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.47      0.57       122\n",
      "           1       0.22      0.45      0.29        40\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.47      0.46      0.43       162\n",
      "weighted avg       0.60      0.46      0.50       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.7592592592592593 and f1 score is: 0.6061833821604439\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       122\n",
      "           1       0.52      0.28      0.36        40\n",
      "\n",
      "    accuracy                           0.76       162\n",
      "   macro avg       0.66      0.60      0.61       162\n",
      "weighted avg       0.73      0.76      0.73       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1517.csv ---\n",
      "[16:21:32] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.654320987654321 and f1 score is: 0.5096216216216216\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       122\n",
      "           1       0.26      0.23      0.24        40\n",
      "\n",
      "    accuracy                           0.65       162\n",
      "   macro avg       0.51      0.51      0.51       162\n",
      "weighted avg       0.64      0.65      0.64       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.7345679012345679 and f1 score is: 0.4830426716141002\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84       122\n",
      "           1       0.33      0.07      0.12        40\n",
      "\n",
      "    accuracy                           0.73       162\n",
      "   macro avg       0.55      0.51      0.48       162\n",
      "weighted avg       0.65      0.73      0.67       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.9130434782608695 and f1 score is: 0.8618618618618618\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78        10\n",
      "           1       0.92      0.97      0.95        36\n",
      "\n",
      "    accuracy                           0.91        46\n",
      "   macro avg       0.90      0.84      0.86        46\n",
      "weighted avg       0.91      0.91      0.91        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.5869565217391305 and f1 score is: 0.5619047619047619\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.80      0.46        10\n",
      "           1       0.90      0.53      0.67        36\n",
      "\n",
      "    accuracy                           0.59        46\n",
      "   macro avg       0.61      0.66      0.56        46\n",
      "weighted avg       0.78      0.59      0.62        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.13043478260869565 and f1 score is: 0.12878787878787878\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.20      0.09        10\n",
      "           1       0.33      0.11      0.17        36\n",
      "\n",
      "    accuracy                           0.13        46\n",
      "   macro avg       0.20      0.16      0.13        46\n",
      "weighted avg       0.27      0.13      0.15        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1544.csv ---\n",
      "[16:22:27] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.6805555555555556\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50        10\n",
      "           1       0.86      0.86      0.86        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.68      0.68      0.68        46\n",
      "weighted avg       0.78      0.78      0.78        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.8478260869565217 and f1 score is: 0.7212121212121212\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.40      0.53        10\n",
      "           1       0.85      0.97      0.91        36\n",
      "\n",
      "    accuracy                           0.85        46\n",
      "   macro avg       0.83      0.69      0.72        46\n",
      "weighted avg       0.84      0.85      0.83        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5849056603773585 and f1 score is: 0.5236928104575164\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.25      0.35        73\n",
      "           1       0.58      0.87      0.69        86\n",
      "\n",
      "    accuracy                           0.58       159\n",
      "   macro avg       0.60      0.56      0.52       159\n",
      "weighted avg       0.60      0.58      0.54       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.4968553459119497 and f1 score is: 0.4165137614678899\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.95      0.63        73\n",
      "           1       0.71      0.12      0.20        86\n",
      "\n",
      "    accuracy                           0.50       159\n",
      "   macro avg       0.60      0.53      0.42       159\n",
      "weighted avg       0.60      0.50      0.40       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5345911949685535 and f1 score is: 0.5323529411764706\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50        73\n",
      "           1       0.57      0.56      0.56        86\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.53      0.53      0.53       159\n",
      "weighted avg       0.54      0.53      0.53       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.559748427672956 and f1 score is: 0.5595916429249763\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.63      0.57        73\n",
      "           1       0.61      0.50      0.55        86\n",
      "\n",
      "    accuracy                           0.56       159\n",
      "   macro avg       0.57      0.57      0.56       159\n",
      "weighted avg       0.57      0.56      0.56       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.49056603773584906 and f1 score is: 0.39921630825208754\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.96      0.63        73\n",
      "           1       0.73      0.09      0.16        86\n",
      "\n",
      "    accuracy                           0.49       159\n",
      "   macro avg       0.60      0.53      0.40       159\n",
      "weighted avg       0.61      0.49      0.38       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.4716981132075472 and f1 score is: 0.47150997150997154\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.53      0.48        73\n",
      "           1       0.51      0.42      0.46        86\n",
      "\n",
      "    accuracy                           0.47       159\n",
      "   macro avg       0.48      0.48      0.47       159\n",
      "weighted avg       0.48      0.47      0.47       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1624.csv ---\n",
      "[16:23:21] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5849056603773585 and f1 score is: 0.580105633802817\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.52      0.54        73\n",
      "           1       0.61      0.64      0.63        86\n",
      "\n",
      "    accuracy                           0.58       159\n",
      "   macro avg       0.58      0.58      0.58       159\n",
      "weighted avg       0.58      0.58      0.58       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5723270440251572 and f1 score is: 0.5721747388414056\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.64      0.58        73\n",
      "           1       0.63      0.51      0.56        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.58      0.58      0.57       159\n",
      "weighted avg       0.58      0.57      0.57       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6740331491712708 and f1 score is: 0.4330838243881722\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.03      0.06        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.67      0.51      0.43       181\n",
      "weighted avg       0.67      0.67      0.56       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.3812154696132597 and f1 score is: 0.3278514588859417\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      1.00      0.52        60\n",
      "           1       1.00      0.07      0.14       121\n",
      "\n",
      "    accuracy                           0.38       181\n",
      "   macro avg       0.67      0.54      0.33       181\n",
      "weighted avg       0.78      0.38      0.26       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5138121546961326 and f1 score is: 0.5071782178217822\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.60      0.45        60\n",
      "           1       0.70      0.47      0.56       121\n",
      "\n",
      "    accuracy                           0.51       181\n",
      "   macro avg       0.53      0.54      0.51       181\n",
      "weighted avg       0.59      0.51      0.53       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6408839779005525 and f1 score is: 0.4047558816089046\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.02      0.03        60\n",
      "           1       0.66      0.95      0.78       121\n",
      "\n",
      "    accuracy                           0.64       181\n",
      "   macro avg       0.40      0.48      0.40       181\n",
      "weighted avg       0.49      0.64      0.53       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.39226519337016574 and f1 score is: 0.35591356107660455\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.95      0.51        60\n",
      "           1       0.82      0.12      0.20       121\n",
      "\n",
      "    accuracy                           0.39       181\n",
      "   macro avg       0.59      0.53      0.36       181\n",
      "weighted avg       0.67      0.39      0.30       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.56353591160221 and f1 score is: 0.5411251243541606\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.52      0.44        60\n",
      "           1       0.71      0.59      0.64       121\n",
      "\n",
      "    accuracy                           0.56       181\n",
      "   macro avg       0.55      0.55      0.54       181\n",
      "weighted avg       0.60      0.56      0.58       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1688.csv ---\n",
      "[16:24:15] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5524861878453039 and f1 score is: 0.5489616982002768\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.70      0.51        60\n",
      "           1       0.76      0.48      0.59       121\n",
      "\n",
      "    accuracy                           0.55       181\n",
      "   macro avg       0.58      0.59      0.55       181\n",
      "weighted avg       0.64      0.55      0.56       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.48066298342541436 and f1 score is: 0.47937576499388\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.80      0.51        60\n",
      "           1       0.76      0.32      0.45       121\n",
      "\n",
      "    accuracy                           0.48       181\n",
      "   macro avg       0.57      0.56      0.48       181\n",
      "weighted avg       0.63      0.48      0.47       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6574074074074074 and f1 score is: 0.634567901234568\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.65      0.54        34\n",
      "           1       0.80      0.66      0.73        74\n",
      "\n",
      "    accuracy                           0.66       108\n",
      "   macro avg       0.64      0.65      0.63       108\n",
      "weighted avg       0.70      0.66      0.67       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.4351851851851852 and f1 score is: 0.4347490347490347\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.65      0.42        34\n",
      "           1       0.68      0.34      0.45        74\n",
      "\n",
      "    accuracy                           0.44       108\n",
      "   macro avg       0.49      0.49      0.43       108\n",
      "weighted avg       0.56      0.44      0.44       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6944444444444444 and f1 score is: 0.642993088250025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.50      0.51        34\n",
      "           1       0.77      0.78      0.78        74\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.64      0.64      0.64       108\n",
      "weighted avg       0.69      0.69      0.69       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5462962962962963 and f1 score is: 0.48596406022340943\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.32      0.31        34\n",
      "           1       0.68      0.65      0.66        74\n",
      "\n",
      "    accuracy                           0.55       108\n",
      "   macro avg       0.49      0.49      0.49       108\n",
      "weighted avg       0.56      0.55      0.55       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.48148148148148145 and f1 score is: 0.475\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.59      0.42        34\n",
      "           1       0.70      0.43      0.53        74\n",
      "\n",
      "    accuracy                           0.48       108\n",
      "   macro avg       0.51      0.51      0.47       108\n",
      "weighted avg       0.58      0.48      0.50       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.39814814814814814 and f1 score is: 0.39183920991076837\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.79      0.45        34\n",
      "           1       0.70      0.22      0.33        74\n",
      "\n",
      "    accuracy                           0.40       108\n",
      "   macro avg       0.51      0.51      0.39       108\n",
      "weighted avg       0.58      0.40      0.37       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1717.csv ---\n",
      "[16:25:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.75 and f1 score is: 0.712511091393079\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61        34\n",
      "           1       0.82      0.81      0.82        74\n",
      "\n",
      "    accuracy                           0.75       108\n",
      "   macro avg       0.71      0.71      0.71       108\n",
      "weighted avg       0.75      0.75      0.75       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5648148148148148 and f1 score is: 0.5509156861010351\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.62      0.47        34\n",
      "           1       0.75      0.54      0.63        74\n",
      "\n",
      "    accuracy                           0.56       108\n",
      "   macro avg       0.57      0.58      0.55       108\n",
      "weighted avg       0.64      0.56      0.58       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5308641975308642 and f1 score is: 0.4618881118881119\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.16      0.27        86\n",
      "           1       0.50      0.95      0.65        76\n",
      "\n",
      "    accuracy                           0.53       162\n",
      "   macro avg       0.64      0.56      0.46       162\n",
      "weighted avg       0.65      0.53      0.45       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5617283950617284 and f1 score is: 0.5135135135135136\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.23      0.36        86\n",
      "           1       0.52      0.93      0.67        76\n",
      "\n",
      "    accuracy                           0.56       162\n",
      "   macro avg       0.66      0.58      0.51       162\n",
      "weighted avg       0.67      0.56      0.50       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.49382716049382713 and f1 score is: 0.41940559440559444\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.13      0.21        86\n",
      "           1       0.48      0.91      0.63        76\n",
      "\n",
      "    accuracy                           0.49       162\n",
      "   macro avg       0.55      0.52      0.42       162\n",
      "weighted avg       0.55      0.49      0.41       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5370370370370371 and f1 score is: 0.5019471203115393\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.26      0.37        86\n",
      "           1       0.50      0.86      0.63        76\n",
      "\n",
      "    accuracy                           0.54       162\n",
      "   macro avg       0.59      0.56      0.50       162\n",
      "weighted avg       0.59      0.54      0.49       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5370370370370371 and f1 score is: 0.4767216503725398\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.19      0.30        86\n",
      "           1       0.50      0.93      0.65        76\n",
      "\n",
      "    accuracy                           0.54       162\n",
      "   macro avg       0.63      0.56      0.48       162\n",
      "weighted avg       0.64      0.54      0.47       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.48148148148148145 and f1 score is: 0.40524475524475523\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.12      0.19        86\n",
      "           1       0.47      0.89      0.62        76\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.51      0.51      0.41       162\n",
      "weighted avg       0.52      0.48      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1765.csv ---\n",
      "[16:26:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5061728395061729 and f1 score is: 0.42766295707472174\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.13      0.22        86\n",
      "           1       0.49      0.93      0.64        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.59      0.53      0.43       162\n",
      "weighted avg       0.59      0.51      0.41       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5061728395061729 and f1 score is: 0.43915527090185213\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.15      0.25        86\n",
      "           1       0.49      0.91      0.63        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.57      0.53      0.44       162\n",
      "weighted avg       0.57      0.51      0.43       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7830188679245284 and f1 score is: 0.5267857142857142\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.31      0.18        16\n",
      "           1       0.94      0.82      0.87       196\n",
      "\n",
      "    accuracy                           0.78       212\n",
      "   macro avg       0.53      0.57      0.53       212\n",
      "weighted avg       0.87      0.78      0.82       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7216981132075472 and f1 score is: 0.46398114420398534\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.19      0.09        16\n",
      "           1       0.92      0.77      0.84       196\n",
      "\n",
      "    accuracy                           0.72       212\n",
      "   macro avg       0.49      0.48      0.46       212\n",
      "weighted avg       0.86      0.72      0.78       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7122641509433962 and f1 score is: 0.4840202689223158\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.31      0.14        16\n",
      "           1       0.93      0.74      0.83       196\n",
      "\n",
      "    accuracy                           0.71       212\n",
      "   macro avg       0.51      0.53      0.48       212\n",
      "weighted avg       0.87      0.71      0.78       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.5707547169811321 and f1 score is: 0.4629026420557365\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.81      0.22        16\n",
      "           1       0.97      0.55      0.70       196\n",
      "\n",
      "    accuracy                           0.57       212\n",
      "   macro avg       0.55      0.68      0.46       212\n",
      "weighted avg       0.91      0.57      0.67       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7122641509433962 and f1 score is: 0.4593419457335173\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.19      0.09        16\n",
      "           1       0.92      0.76      0.83       196\n",
      "\n",
      "    accuracy                           0.71       212\n",
      "   macro avg       0.49      0.47      0.46       212\n",
      "weighted avg       0.85      0.71      0.77       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7358490566037735 and f1 score is: 0.4847222222222223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.25      0.12        16\n",
      "           1       0.93      0.78      0.84       196\n",
      "\n",
      "    accuracy                           0.74       212\n",
      "   macro avg       0.51      0.51      0.48       212\n",
      "weighted avg       0.86      0.74      0.79       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1818.csv ---\n",
      "[16:26:57] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7641509433962265 and f1 score is: 0.5146520146520147\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.31      0.17        16\n",
      "           1       0.93      0.80      0.86       196\n",
      "\n",
      "    accuracy                           0.76       212\n",
      "   macro avg       0.52      0.56      0.51       212\n",
      "weighted avg       0.87      0.76      0.81       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7216981132075472 and f1 score is: 0.46398114420398534\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.19      0.09        16\n",
      "           1       0.92      0.77      0.84       196\n",
      "\n",
      "    accuracy                           0.72       212\n",
      "   macro avg       0.49      0.48      0.46       212\n",
      "weighted avg       0.86      0.72      0.78       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.49074074074074076 and f1 score is: 0.47447580288418995\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.44      0.57       162\n",
      "           1       0.27      0.63      0.38        54\n",
      "\n",
      "    accuracy                           0.49       216\n",
      "   macro avg       0.53      0.54      0.47       216\n",
      "weighted avg       0.66      0.49      0.52       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5555555555555556 and f1 score is: 0.512781954887218\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66       162\n",
      "           1       0.29      0.52      0.37        54\n",
      "\n",
      "    accuracy                           0.56       216\n",
      "   macro avg       0.53      0.54      0.51       216\n",
      "weighted avg       0.66      0.56      0.58       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5324074074074074 and f1 score is: 0.5166500498504487\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.48      0.60       162\n",
      "           1       0.31      0.70      0.43        54\n",
      "\n",
      "    accuracy                           0.53       216\n",
      "   macro avg       0.57      0.59      0.52       216\n",
      "weighted avg       0.70      0.53      0.56       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.3055555555555556 and f1 score is: 0.29189614476789927\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.11      0.19       162\n",
      "           1       0.25      0.89      0.39        54\n",
      "\n",
      "    accuracy                           0.31       216\n",
      "   macro avg       0.50      0.50      0.29       216\n",
      "weighted avg       0.62      0.31      0.24       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5787037037037037 and f1 score is: 0.5136459235432389\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.63      0.69       162\n",
      "           1       0.28      0.43      0.34        54\n",
      "\n",
      "    accuracy                           0.58       216\n",
      "   macro avg       0.52      0.53      0.51       216\n",
      "weighted avg       0.64      0.58      0.60       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4305555555555556 and f1 score is: 0.4228237492124872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.36      0.49       162\n",
      "           1       0.25      0.63      0.36        54\n",
      "\n",
      "    accuracy                           0.43       216\n",
      "   macro avg       0.50      0.50      0.42       216\n",
      "weighted avg       0.62      0.43      0.46       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1892.csv ---\n",
      "[16:27:49] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5185185185185185 and f1 score is: 0.5077138849929874\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.44      0.58       162\n",
      "           1       0.31      0.74      0.43        54\n",
      "\n",
      "    accuracy                           0.52       216\n",
      "   macro avg       0.57      0.59      0.51       216\n",
      "weighted avg       0.70      0.52      0.54       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5092592592592593 and f1 score is: 0.4651966738297674\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.53      0.62       162\n",
      "           1       0.24      0.44      0.31        54\n",
      "\n",
      "    accuracy                           0.51       216\n",
      "   macro avg       0.49      0.49      0.47       216\n",
      "weighted avg       0.62      0.51      0.54       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6273584905660378 and f1 score is: 0.4934518948673744\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.18      0.23        65\n",
      "           1       0.70      0.82      0.75       147\n",
      "\n",
      "    accuracy                           0.63       212\n",
      "   macro avg       0.51      0.50      0.49       212\n",
      "weighted avg       0.58      0.63      0.59       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5 and f1 score is: 0.406883445945946\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.17      0.17        65\n",
      "           1       0.64      0.65      0.64       147\n",
      "\n",
      "    accuracy                           0.50       212\n",
      "   macro avg       0.41      0.41      0.41       212\n",
      "weighted avg       0.50      0.50      0.50       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5518867924528302 and f1 score is: 0.5053906038949876\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.40      0.35        65\n",
      "           1       0.70      0.62      0.66       147\n",
      "\n",
      "    accuracy                           0.55       212\n",
      "   macro avg       0.51      0.51      0.51       212\n",
      "weighted avg       0.58      0.55      0.56       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5990566037735849 and f1 score is: 0.48133436951328323\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.20      0.23        65\n",
      "           1       0.69      0.78      0.73       147\n",
      "\n",
      "    accuracy                           0.60       212\n",
      "   macro avg       0.48      0.49      0.48       212\n",
      "weighted avg       0.56      0.60      0.58       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5330188679245284 and f1 score is: 0.4384481605351171\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.20      0.21        65\n",
      "           1       0.66      0.68      0.67       147\n",
      "\n",
      "    accuracy                           0.53       212\n",
      "   macro avg       0.44      0.44      0.44       212\n",
      "weighted avg       0.52      0.53      0.53       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5094339622641509 and f1 score is: 0.4697450697450698\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.38      0.32        65\n",
      "           1       0.67      0.56      0.61       147\n",
      "\n",
      "    accuracy                           0.51       212\n",
      "   macro avg       0.48      0.47      0.47       212\n",
      "weighted avg       0.55      0.51      0.53       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1929.csv ---\n",
      "[16:28:42] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5330188679245284 and f1 score is: 0.4331091483672312\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.18      0.20        65\n",
      "           1       0.66      0.69      0.67       147\n",
      "\n",
      "    accuracy                           0.53       212\n",
      "   macro avg       0.43      0.44      0.43       212\n",
      "weighted avg       0.52      0.53      0.53       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5660377358490566 and f1 score is: 0.4481041312959819\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.17      0.19        65\n",
      "           1       0.67      0.74      0.70       147\n",
      "\n",
      "    accuracy                           0.57       212\n",
      "   macro avg       0.45      0.46      0.45       212\n",
      "weighted avg       0.53      0.57      0.55       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6122448979591837 and f1 score is: 0.47578828828828834\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.14      0.21        36\n",
      "           1       0.64      0.89      0.74        62\n",
      "\n",
      "    accuracy                           0.61        98\n",
      "   macro avg       0.53      0.51      0.48        98\n",
      "weighted avg       0.56      0.61      0.55        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5714285714285714 and f1 score is: 0.5625\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.97      0.62        36\n",
      "           1       0.95      0.34      0.50        62\n",
      "\n",
      "    accuracy                           0.57        98\n",
      "   macro avg       0.71      0.66      0.56        98\n",
      "weighted avg       0.77      0.57      0.55        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6530612244897959 and f1 score is: 0.6346491228070177\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.55        36\n",
      "           1       0.74      0.69      0.72        62\n",
      "\n",
      "    accuracy                           0.65        98\n",
      "   macro avg       0.63      0.64      0.63        98\n",
      "weighted avg       0.66      0.65      0.66        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.7755102040816326 and f1 score is: 0.7676724137931035\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73        36\n",
      "           1       0.87      0.76      0.81        62\n",
      "\n",
      "    accuracy                           0.78        98\n",
      "   macro avg       0.76      0.78      0.77        98\n",
      "weighted avg       0.79      0.78      0.78        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5408163265306123 and f1 score is: 0.5228821811100292\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.62        36\n",
      "           1       1.00      0.27      0.43        62\n",
      "\n",
      "    accuracy                           0.54        98\n",
      "   macro avg       0.72      0.64      0.52        98\n",
      "weighted avg       0.80      0.54      0.50        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5 and f1 score is: 0.45892957746478874\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.31      0.31        36\n",
      "           1       0.60      0.61      0.61        62\n",
      "\n",
      "    accuracy                           0.50        98\n",
      "   macro avg       0.46      0.46      0.46        98\n",
      "weighted avg       0.50      0.50      0.50        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1933.csv ---\n",
      "[16:29:36] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5408163265306123 and f1 score is: 0.4736842105263158\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.25      0.29        36\n",
      "           1       0.62      0.71      0.66        62\n",
      "\n",
      "    accuracy                           0.54        98\n",
      "   macro avg       0.48      0.48      0.47        98\n",
      "weighted avg       0.51      0.54      0.52        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5612244897959183 and f1 score is: 0.5251830985915493\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.39      0.39        36\n",
      "           1       0.65      0.66      0.66        62\n",
      "\n",
      "    accuracy                           0.56        98\n",
      "   macro avg       0.53      0.53      0.53        98\n",
      "weighted avg       0.56      0.56      0.56        98\n",
      "\n",
      "----- Running Modality Combination EEG_GAZE\n",
      "Saved Directory: 2022_08_11_16_29\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5721153846153846 and f1 score is: 0.5081697175801695\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.23      0.33        95\n",
      "           1       0.57      0.86      0.69       113\n",
      "\n",
      "    accuracy                           0.57       208\n",
      "   macro avg       0.57      0.54      0.51       208\n",
      "weighted avg       0.57      0.57      0.52       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.47115384615384615 and f1 score is: 0.4707134264828352\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.48      0.46        95\n",
      "           1       0.51      0.46      0.49       113\n",
      "\n",
      "    accuracy                           0.47       208\n",
      "   macro avg       0.47      0.47      0.47       208\n",
      "weighted avg       0.48      0.47      0.47       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5673076923076923 and f1 score is: 0.5632698768197089\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.73      0.61        95\n",
      "           1       0.65      0.43      0.52       113\n",
      "\n",
      "    accuracy                           0.57       208\n",
      "   macro avg       0.59      0.58      0.56       208\n",
      "weighted avg       0.59      0.57      0.56       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.4951923076923077 and f1 score is: 0.4877928656863435\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.67      0.55        95\n",
      "           1       0.56      0.35      0.43       113\n",
      "\n",
      "    accuracy                           0.50       208\n",
      "   macro avg       0.51      0.51      0.49       208\n",
      "weighted avg       0.51      0.50      0.48       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.4855769230769231 and f1 score is: 0.4855650324757876\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.53      0.48        95\n",
      "           1       0.53      0.45      0.49       113\n",
      "\n",
      "    accuracy                           0.49       208\n",
      "   macro avg       0.49      0.49      0.49       208\n",
      "weighted avg       0.49      0.49      0.49       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.49038461538461536 and f1 score is: 0.44741854636591477\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.84      0.60        95\n",
      "           1       0.59      0.19      0.29       113\n",
      "\n",
      "    accuracy                           0.49       208\n",
      "   macro avg       0.53      0.52      0.45       208\n",
      "weighted avg       0.54      0.49      0.43       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1105.csv ---\n",
      "[16:31:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5480769230769231 and f1 score is: 0.5384760645831366\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.44      0.47        95\n",
      "           1       0.58      0.64      0.61       113\n",
      "\n",
      "    accuracy                           0.55       208\n",
      "   macro avg       0.54      0.54      0.54       208\n",
      "weighted avg       0.54      0.55      0.54       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5817307692307693 and f1 score is: 0.5814889336016096\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.61      0.57        95\n",
      "           1       0.63      0.56      0.59       113\n",
      "\n",
      "    accuracy                           0.58       208\n",
      "   macro avg       0.58      0.58      0.58       208\n",
      "weighted avg       0.59      0.58      0.58       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8707482993197279 and f1 score is: 0.551901171185625\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.12      0.17        16\n",
      "           1       0.90      0.96      0.93       131\n",
      "\n",
      "    accuracy                           0.87       147\n",
      "   macro avg       0.59      0.54      0.55       147\n",
      "weighted avg       0.83      0.87      0.85       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7551020408163265 and f1 score is: 0.5189090909090909\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.25      0.18        16\n",
      "           1       0.90      0.82      0.86       131\n",
      "\n",
      "    accuracy                           0.76       147\n",
      "   macro avg       0.52      0.53      0.52       147\n",
      "weighted avg       0.82      0.76      0.78       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7755102040816326 and f1 score is: 0.5821345507795677\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.44      0.30        16\n",
      "           1       0.92      0.82      0.87       131\n",
      "\n",
      "    accuracy                           0.78       147\n",
      "   macro avg       0.57      0.63      0.58       147\n",
      "weighted avg       0.85      0.78      0.80       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.5306122448979592 and f1 score is: 0.4440668676349685\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.62      0.22        16\n",
      "           1       0.92      0.52      0.66       131\n",
      "\n",
      "    accuracy                           0.53       147\n",
      "   macro avg       0.53      0.57      0.44       147\n",
      "weighted avg       0.83      0.53      0.62       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7619047619047619 and f1 score is: 0.5408299866131192\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.31      0.22        16\n",
      "           1       0.91      0.82      0.86       131\n",
      "\n",
      "    accuracy                           0.76       147\n",
      "   macro avg       0.54      0.56      0.54       147\n",
      "weighted avg       0.83      0.76      0.79       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.782312925170068 and f1 score is: 0.5876577840112203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.44      0.30        16\n",
      "           1       0.92      0.82      0.87       131\n",
      "\n",
      "    accuracy                           0.78       147\n",
      "   macro avg       0.58      0.63      0.59       147\n",
      "weighted avg       0.85      0.78      0.81       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1106.csv ---\n",
      "[16:33:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7959183673469388 and f1 score is: 0.5251937984496123\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.19      0.17        16\n",
      "           1       0.90      0.87      0.88       131\n",
      "\n",
      "    accuracy                           0.80       147\n",
      "   macro avg       0.52      0.53      0.53       147\n",
      "weighted avg       0.82      0.80      0.81       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8503401360544217 and f1 score is: 0.6142652671755725\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.31      0.31        16\n",
      "           1       0.92      0.92      0.92       131\n",
      "\n",
      "    accuracy                           0.85       147\n",
      "   macro avg       0.61      0.61      0.61       147\n",
      "weighted avg       0.85      0.85      0.85       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.536723163841808 and f1 score is: 0.3799555707450444\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.04      0.07        84\n",
      "           1       0.53      0.99      0.69        93\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.64      0.51      0.38       177\n",
      "weighted avg       0.64      0.54      0.40       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5706214689265536 and f1 score is: 0.48261538461538456\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.17      0.27        84\n",
      "           1       0.55      0.94      0.70        93\n",
      "\n",
      "    accuracy                           0.57       177\n",
      "   macro avg       0.63      0.55      0.48       177\n",
      "weighted avg       0.62      0.57      0.49       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5536723163841808 and f1 score is: 0.46517498565691334\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.15      0.25        84\n",
      "           1       0.54      0.91      0.68        93\n",
      "\n",
      "    accuracy                           0.55       177\n",
      "   macro avg       0.58      0.53      0.47       177\n",
      "weighted avg       0.58      0.55      0.48       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5649717514124294 and f1 score is: 0.516582130316036\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.26      0.36        84\n",
      "           1       0.56      0.84      0.67        93\n",
      "\n",
      "    accuracy                           0.56       177\n",
      "   macro avg       0.58      0.55      0.52       177\n",
      "weighted avg       0.57      0.56      0.52       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.536723163841808 and f1 score is: 0.4645070838252656\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.18      0.27        84\n",
      "           1       0.54      0.86      0.66        93\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.54      0.52      0.46       177\n",
      "weighted avg       0.54      0.54      0.47       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5423728813559322 and f1 score is: 0.4248866781659914\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.10      0.16        84\n",
      "           1       0.54      0.95      0.68        93\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.58      0.52      0.42       177\n",
      "weighted avg       0.57      0.54      0.44       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1175.csv ---\n",
      "[16:35:05] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4915254237288136 and f1 score is: 0.4915091930541369\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.51      0.49        84\n",
      "           1       0.52      0.47      0.49        93\n",
      "\n",
      "    accuracy                           0.49       177\n",
      "   macro avg       0.49      0.49      0.49       177\n",
      "weighted avg       0.49      0.49      0.49       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5028248587570622 and f1 score is: 0.4970291914234048\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.42      0.44        84\n",
      "           1       0.52      0.58      0.55        93\n",
      "\n",
      "    accuracy                           0.50       177\n",
      "   macro avg       0.50      0.50      0.50       177\n",
      "weighted avg       0.50      0.50      0.50       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5462962962962963 and f1 score is: 0.5227272727272727\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.31      0.42       113\n",
      "           1       0.52      0.81      0.63       103\n",
      "\n",
      "    accuracy                           0.55       216\n",
      "   macro avg       0.58      0.56      0.52       216\n",
      "weighted avg       0.58      0.55      0.52       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6435185185185185 and f1 score is: 0.6435108777194298\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.64       113\n",
      "           1       0.61      0.68      0.65       103\n",
      "\n",
      "    accuracy                           0.64       216\n",
      "   macro avg       0.65      0.65      0.64       216\n",
      "weighted avg       0.65      0.64      0.64       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6527777777777778 and f1 score is: 0.6515154774453074\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.57      0.63       113\n",
      "           1       0.61      0.75      0.67       103\n",
      "\n",
      "    accuracy                           0.65       216\n",
      "   macro avg       0.66      0.66      0.65       216\n",
      "weighted avg       0.66      0.65      0.65       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6296296296296297 and f1 score is: 0.62642684192321\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.51      0.59       113\n",
      "           1       0.59      0.76      0.66       103\n",
      "\n",
      "    accuracy                           0.63       216\n",
      "   macro avg       0.64      0.64      0.63       216\n",
      "weighted avg       0.65      0.63      0.62       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6342592592592593 and f1 score is: 0.6324869160690056\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.54      0.61       113\n",
      "           1       0.59      0.74      0.66       103\n",
      "\n",
      "    accuracy                           0.63       216\n",
      "   macro avg       0.64      0.64      0.63       216\n",
      "weighted avg       0.65      0.63      0.63       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.49537037037037035 and f1 score is: 0.4745463878411855\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.28      0.37       113\n",
      "           1       0.48      0.73      0.58       103\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.51      0.51      0.47       216\n",
      "weighted avg       0.51      0.50      0.47       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1337.csv ---\n",
      "[16:37:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6481481481481481 and f1 score is: 0.6444598457939876\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.52      0.61       113\n",
      "           1       0.60      0.79      0.68       103\n",
      "\n",
      "    accuracy                           0.65       216\n",
      "   macro avg       0.66      0.65      0.64       216\n",
      "weighted avg       0.67      0.65      0.64       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6388888888888888 and f1 score is: 0.638392857142857\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.58      0.62       113\n",
      "           1       0.60      0.71      0.65       103\n",
      "\n",
      "    accuracy                           0.64       216\n",
      "   macro avg       0.64      0.64      0.64       216\n",
      "weighted avg       0.65      0.64      0.64       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5727699530516432 and f1 score is: 0.48483720930232554\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.18      0.27        95\n",
      "           1       0.57      0.89      0.70       118\n",
      "\n",
      "    accuracy                           0.57       213\n",
      "   macro avg       0.57      0.53      0.48       213\n",
      "weighted avg       0.57      0.57      0.51       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.568075117370892 and f1 score is: 0.5676081200353045\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.67      0.58        95\n",
      "           1       0.65      0.48      0.55       118\n",
      "\n",
      "    accuracy                           0.57       213\n",
      "   macro avg       0.58      0.58      0.57       213\n",
      "weighted avg       0.59      0.57      0.57       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.596244131455399 and f1 score is: 0.5896505376344086\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.53      0.54        95\n",
      "           1       0.63      0.65      0.64       118\n",
      "\n",
      "    accuracy                           0.60       213\n",
      "   macro avg       0.59      0.59      0.59       213\n",
      "weighted avg       0.59      0.60      0.60       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.596244131455399 and f1 score is: 0.5695958646616541\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.39      0.46        95\n",
      "           1       0.61      0.76      0.68       118\n",
      "\n",
      "    accuracy                           0.60       213\n",
      "   macro avg       0.59      0.58      0.57       213\n",
      "weighted avg       0.59      0.60      0.58       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5868544600938967 and f1 score is: 0.5857496463932108\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.72      0.61        95\n",
      "           1       0.68      0.48      0.56       118\n",
      "\n",
      "    accuracy                           0.59       213\n",
      "   macro avg       0.60      0.60      0.59       213\n",
      "weighted avg       0.61      0.59      0.58       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5258215962441315 and f1 score is: 0.47200883543993133\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.95      0.64        95\n",
      "           1       0.81      0.19      0.30       118\n",
      "\n",
      "    accuracy                           0.53       213\n",
      "   macro avg       0.65      0.57      0.47       213\n",
      "weighted avg       0.67      0.53      0.45       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1390.csv ---\n",
      "[16:39:03] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.6338028169014085 and f1 score is: 0.6055555555555556\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.41      0.50        95\n",
      "           1       0.63      0.81      0.71       118\n",
      "\n",
      "    accuracy                           0.63       213\n",
      "   macro avg       0.64      0.61      0.61       213\n",
      "weighted avg       0.64      0.63      0.62       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.647887323943662 and f1 score is: 0.6363118952760387\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57        95\n",
      "           1       0.66      0.75      0.70       118\n",
      "\n",
      "    accuracy                           0.65       213\n",
      "   macro avg       0.64      0.64      0.64       213\n",
      "weighted avg       0.65      0.65      0.64       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6714285714285714 and f1 score is: 0.4819634621572343\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.99      0.80       136\n",
      "           1       0.78      0.09      0.17        74\n",
      "\n",
      "    accuracy                           0.67       210\n",
      "   macro avg       0.72      0.54      0.48       210\n",
      "weighted avg       0.71      0.67      0.57       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6761904761904762 and f1 score is: 0.5112267250821467\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.97      0.80       136\n",
      "           1       0.71      0.14      0.23        74\n",
      "\n",
      "    accuracy                           0.68       210\n",
      "   macro avg       0.69      0.55      0.51       210\n",
      "weighted avg       0.69      0.68      0.60       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6761904761904762 and f1 score is: 0.5709650282417978\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78       136\n",
      "           1       0.59      0.26      0.36        74\n",
      "\n",
      "    accuracy                           0.68       210\n",
      "   macro avg       0.64      0.58      0.57       210\n",
      "weighted avg       0.66      0.68      0.63       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.638095238095238 and f1 score is: 0.43452380952380953\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.96      0.77       136\n",
      "           1       0.40      0.05      0.10        74\n",
      "\n",
      "    accuracy                           0.64       210\n",
      "   macro avg       0.53      0.50      0.43       210\n",
      "weighted avg       0.56      0.64      0.53       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6666666666666666 and f1 score is: 0.4882328366522768\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.97      0.79       136\n",
      "           1       0.67      0.11      0.19        74\n",
      "\n",
      "    accuracy                           0.67       210\n",
      "   macro avg       0.67      0.54      0.49       210\n",
      "weighted avg       0.67      0.67      0.58       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6571428571428571 and f1 score is: 0.6142857142857143\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       136\n",
      "           1       0.52      0.46      0.49        74\n",
      "\n",
      "    accuracy                           0.66       210\n",
      "   macro avg       0.62      0.61      0.61       210\n",
      "weighted avg       0.65      0.66      0.65       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1400.csv ---\n",
      "[16:41:03] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6714285714285714 and f1 score is: 0.5081299433110424\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.96      0.79       136\n",
      "           1       0.67      0.14      0.22        74\n",
      "\n",
      "    accuracy                           0.67       210\n",
      "   macro avg       0.67      0.55      0.51       210\n",
      "weighted avg       0.67      0.67      0.59       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6476190476190476 and f1 score is: 0.48502120890774125\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.93      0.77       136\n",
      "           1       0.50      0.12      0.20        74\n",
      "\n",
      "    accuracy                           0.65       210\n",
      "   macro avg       0.58      0.53      0.49       210\n",
      "weighted avg       0.60      0.65      0.57       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.42990654205607476 and f1 score is: 0.42910872037085634\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.53      0.45        95\n",
      "           1       0.48      0.35      0.41       119\n",
      "\n",
      "    accuracy                           0.43       214\n",
      "   macro avg       0.44      0.44      0.43       214\n",
      "weighted avg       0.44      0.43      0.43       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.4719626168224299 and f1 score is: 0.37305229317362787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.98      0.62        95\n",
      "           1       0.80      0.07      0.12       119\n",
      "\n",
      "    accuracy                           0.47       214\n",
      "   macro avg       0.63      0.52      0.37       214\n",
      "weighted avg       0.65      0.47      0.35       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.48130841121495327 and f1 score is: 0.4752468685797602\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.66      0.53        95\n",
      "           1       0.56      0.34      0.42       119\n",
      "\n",
      "    accuracy                           0.48       214\n",
      "   macro avg       0.50      0.50      0.48       214\n",
      "weighted avg       0.51      0.48      0.47       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.6121495327102804 and f1 score is: 0.55095436733662\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.27      0.39        95\n",
      "           1       0.60      0.88      0.72       119\n",
      "\n",
      "    accuracy                           0.61       214\n",
      "   macro avg       0.63      0.58      0.55       214\n",
      "weighted avg       0.62      0.61      0.57       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.45794392523364486 and f1 score is: 0.36988526753985174\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.94      0.61        95\n",
      "           1       0.60      0.08      0.13       119\n",
      "\n",
      "    accuracy                           0.46       214\n",
      "   macro avg       0.52      0.51      0.37       214\n",
      "weighted avg       0.53      0.46      0.34       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5327102803738317 and f1 score is: 0.5277189265536723\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.72      0.58        95\n",
      "           1       0.63      0.39      0.48       119\n",
      "\n",
      "    accuracy                           0.53       214\n",
      "   macro avg       0.56      0.55      0.53       214\n",
      "weighted avg       0.56      0.53      0.52       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1419.csv ---\n",
      "[16:42:59] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.514018691588785 and f1 score is: 0.5119298245614035\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.65      0.54        95\n",
      "           1       0.59      0.40      0.48       119\n",
      "\n",
      "    accuracy                           0.51       214\n",
      "   macro avg       0.53      0.53      0.51       214\n",
      "weighted avg       0.54      0.51      0.51       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5186915887850467 and f1 score is: 0.5069675889681705\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.76      0.58        95\n",
      "           1       0.63      0.33      0.43       119\n",
      "\n",
      "    accuracy                           0.52       214\n",
      "   macro avg       0.55      0.54      0.51       214\n",
      "weighted avg       0.56      0.52      0.50       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.4012345679012346 and f1 score is: 0.40066364087112405\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.25      0.38       122\n",
      "           1       0.28      0.88      0.42        40\n",
      "\n",
      "    accuracy                           0.40       162\n",
      "   macro avg       0.57      0.56      0.40       162\n",
      "weighted avg       0.71      0.40      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.42592592592592593 and f1 score is: 0.4259040506039706\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.29      0.43       122\n",
      "           1       0.28      0.85      0.42        40\n",
      "\n",
      "    accuracy                           0.43       162\n",
      "   macro avg       0.57      0.57      0.43       162\n",
      "weighted avg       0.71      0.43      0.43       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.49382716049382713 and f1 score is: 0.44943633952254647\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.52      0.61       122\n",
      "           1       0.22      0.42      0.29        40\n",
      "\n",
      "    accuracy                           0.49       162\n",
      "   macro avg       0.48      0.47      0.45       162\n",
      "weighted avg       0.61      0.49      0.53       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5 and f1 score is: 0.4581939799331104\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.52      0.61       122\n",
      "           1       0.23      0.45      0.31        40\n",
      "\n",
      "    accuracy                           0.50       162\n",
      "   macro avg       0.49      0.48      0.46       162\n",
      "weighted avg       0.62      0.50      0.53       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.4567901234567901 and f1 score is: 0.45546218487394957\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.34      0.48       122\n",
      "           1       0.29      0.82      0.43        40\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.57      0.58      0.46       162\n",
      "weighted avg       0.71      0.46      0.47       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5123456790123457 and f1 score is: 0.4962012360744794\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.46      0.59       122\n",
      "           1       0.29      0.68      0.41        40\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.55      0.57      0.50       162\n",
      "weighted avg       0.68      0.51      0.54       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1517.csv ---\n",
      "[16:45:00] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5493827160493827 and f1 score is: 0.49980966882375333\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.57      0.66       122\n",
      "           1       0.27      0.47      0.34        40\n",
      "\n",
      "    accuracy                           0.55       162\n",
      "   macro avg       0.52      0.52      0.50       162\n",
      "weighted avg       0.65      0.55      0.58       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5061728395061729 and f1 score is: 0.46286472148541113\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.52      0.62       122\n",
      "           1       0.24      0.45      0.31        40\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.49      0.49      0.46       162\n",
      "weighted avg       0.62      0.51      0.54       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.7391304347826086 and f1 score is: 0.425\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.77      0.94      0.85        36\n",
      "\n",
      "    accuracy                           0.74        46\n",
      "   macro avg       0.39      0.47      0.42        46\n",
      "weighted avg       0.60      0.74      0.67        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6086956521739131 and f1 score is: 0.37837837837837834\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.74      0.78      0.76        36\n",
      "\n",
      "    accuracy                           0.61        46\n",
      "   macro avg       0.37      0.39      0.38        46\n",
      "weighted avg       0.58      0.61      0.59        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6956521739130435 and f1 score is: 0.5165165165165165\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.20      0.22        10\n",
      "           1       0.79      0.83      0.81        36\n",
      "\n",
      "    accuracy                           0.70        46\n",
      "   macro avg       0.52      0.52      0.52        46\n",
      "weighted avg       0.67      0.70      0.68        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.5652173913043478 and f1 score is: 0.3611111111111111\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.72      0.72      0.72        36\n",
      "\n",
      "    accuracy                           0.57        46\n",
      "   macro avg       0.36      0.36      0.36        46\n",
      "weighted avg       0.57      0.57      0.57        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1544.csv ---\n",
      "[16:47:01] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6521739130434783 and f1 score is: 0.5892857142857143\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.60      0.43        10\n",
      "           1       0.86      0.67      0.75        36\n",
      "\n",
      "    accuracy                           0.65        46\n",
      "   macro avg       0.60      0.63      0.59        46\n",
      "weighted avg       0.74      0.65      0.68        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.4782608695652174 and f1 score is: 0.40645161290322573\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.30      0.20        10\n",
      "           1       0.73      0.53      0.61        36\n",
      "\n",
      "    accuracy                           0.48        46\n",
      "   macro avg       0.44      0.41      0.41        46\n",
      "weighted avg       0.60      0.48      0.52        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.610062893081761 and f1 score is: 0.6017291531997415\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.51      0.54        73\n",
      "           1       0.62      0.70      0.66        86\n",
      "\n",
      "    accuracy                           0.61       159\n",
      "   macro avg       0.61      0.60      0.60       159\n",
      "weighted avg       0.61      0.61      0.61       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5786163522012578 and f1 score is: 0.5501456864152696\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.90      0.66        73\n",
      "           1       0.79      0.30      0.44        86\n",
      "\n",
      "    accuracy                           0.58       159\n",
      "   macro avg       0.66      0.60      0.55       159\n",
      "weighted avg       0.67      0.58      0.54       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5974842767295597 and f1 score is: 0.5947754061803122\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56        73\n",
      "           1       0.63      0.63      0.63        86\n",
      "\n",
      "    accuracy                           0.60       159\n",
      "   macro avg       0.59      0.59      0.59       159\n",
      "weighted avg       0.60      0.60      0.60       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5723270440251572 and f1 score is: 0.567381562099872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.51      0.52        73\n",
      "           1       0.60      0.63      0.61        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.57      0.57      0.57       159\n",
      "weighted avg       0.57      0.57      0.57       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5534591194968553 and f1 score is: 0.5232887124699126\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.88      0.64        73\n",
      "           1       0.73      0.28      0.40        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.62      0.58      0.52       159\n",
      "weighted avg       0.63      0.55      0.51       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5283018867924528 and f1 score is: 0.4852147636520613\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.89      0.63        73\n",
      "           1       0.70      0.22      0.34        86\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.60      0.56      0.49       159\n",
      "weighted avg       0.61      0.53      0.47       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1624.csv ---\n",
      "[16:49:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5723270440251572 and f1 score is: 0.570952380952381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.56      0.55        73\n",
      "           1       0.61      0.58      0.60        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.57      0.57      0.57       159\n",
      "weighted avg       0.57      0.57      0.57       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5974842767295597 and f1 score is: 0.59708584098828\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        73\n",
      "           1       0.66      0.52      0.58        86\n",
      "\n",
      "    accuracy                           0.60       159\n",
      "   macro avg       0.61      0.60      0.60       159\n",
      "weighted avg       0.61      0.60      0.60       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6629834254143646 and f1 score is: 0.39867109634551495\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.66       181\n",
      "   macro avg       0.33      0.50      0.40       181\n",
      "weighted avg       0.45      0.66      0.53       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6132596685082873 and f1 score is: 0.46621166161105493\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.13      0.19        60\n",
      "           1       0.66      0.85      0.75       121\n",
      "\n",
      "    accuracy                           0.61       181\n",
      "   macro avg       0.49      0.49      0.47       181\n",
      "weighted avg       0.55      0.61      0.56       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6408839779005525 and f1 score is: 0.49194627974262645\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.15      0.22        60\n",
      "           1       0.68      0.88      0.77       121\n",
      "\n",
      "    accuracy                           0.64       181\n",
      "   macro avg       0.53      0.52      0.49       181\n",
      "weighted avg       0.58      0.64      0.58       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6629834254143646 and f1 score is: 0.39867109634551495\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.66       181\n",
      "   macro avg       0.33      0.50      0.40       181\n",
      "weighted avg       0.45      0.66      0.53       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6022099447513812 and f1 score is: 0.4753623188405798\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.17      0.22        60\n",
      "           1       0.66      0.82      0.73       121\n",
      "\n",
      "    accuracy                           0.60       181\n",
      "   macro avg       0.49      0.49      0.48       181\n",
      "weighted avg       0.55      0.60      0.56       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5248618784530387 and f1 score is: 0.4803018162393163\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.35      0.33        60\n",
      "           1       0.65      0.61      0.63       121\n",
      "\n",
      "    accuracy                           0.52       181\n",
      "   macro avg       0.48      0.48      0.48       181\n",
      "weighted avg       0.54      0.52      0.53       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1688.csv ---\n",
      "[16:51:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6353591160220995 and f1 score is: 0.43947072072072074\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.07      0.11        60\n",
      "           1       0.66      0.92      0.77       121\n",
      "\n",
      "    accuracy                           0.64       181\n",
      "   macro avg       0.48      0.49      0.44       181\n",
      "weighted avg       0.54      0.64      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5911602209944752 and f1 score is: 0.46078904991948466\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.15      0.20        60\n",
      "           1       0.66      0.81      0.73       121\n",
      "\n",
      "    accuracy                           0.59       181\n",
      "   macro avg       0.47      0.48      0.46       181\n",
      "weighted avg       0.53      0.59      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.7407407407407407 and f1 score is: 0.5704545454545454\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.30        34\n",
      "           1       0.73      1.00      0.84        74\n",
      "\n",
      "    accuracy                           0.74       108\n",
      "   macro avg       0.86      0.59      0.57       108\n",
      "weighted avg       0.81      0.74      0.67       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.3888888888888889 and f1 score is: 0.38699690402476783\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.53      0.35        34\n",
      "           1       0.60      0.32      0.42        74\n",
      "\n",
      "    accuracy                           0.39       108\n",
      "   macro avg       0.43      0.43      0.39       108\n",
      "weighted avg       0.49      0.39      0.40       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6759259259259259 and f1 score is: 0.562449357564533\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.26      0.34        34\n",
      "           1       0.72      0.86      0.79        74\n",
      "\n",
      "    accuracy                           0.68       108\n",
      "   macro avg       0.60      0.56      0.56       108\n",
      "weighted avg       0.64      0.68      0.64       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.49074074074074076 and f1 score is: 0.4778021978021978\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.53      0.40        34\n",
      "           1       0.69      0.47      0.56        74\n",
      "\n",
      "    accuracy                           0.49       108\n",
      "   macro avg       0.50      0.50      0.48       108\n",
      "weighted avg       0.57      0.49      0.51       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.4074074074074074 and f1 score is: 0.4065934065934066\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.59      0.38        34\n",
      "           1       0.63      0.32      0.43        74\n",
      "\n",
      "    accuracy                           0.41       108\n",
      "   macro avg       0.46      0.46      0.41       108\n",
      "weighted avg       0.52      0.41      0.41       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6574074074074074 and f1 score is: 0.6506687647521636\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.82      0.60        34\n",
      "           1       0.88      0.58      0.70        74\n",
      "\n",
      "    accuracy                           0.66       108\n",
      "   macro avg       0.68      0.70      0.65       108\n",
      "weighted avg       0.75      0.66      0.67       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1717.csv ---\n",
      "[16:53:06] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6944444444444444 and f1 score is: 0.564462910912868\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.24      0.33        34\n",
      "           1       0.72      0.91      0.80        74\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.63      0.57      0.56       108\n",
      "weighted avg       0.66      0.69      0.65       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6851851851851852 and f1 score is: 0.6290909090909091\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.47      0.48        34\n",
      "           1       0.76      0.78      0.77        74\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.63      0.63      0.63       108\n",
      "weighted avg       0.68      0.69      0.68       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5061728395061729 and f1 score is: 0.4741113455607856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.24      0.34        86\n",
      "           1       0.48      0.80      0.60        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.53      0.52      0.47       162\n",
      "weighted avg       0.54      0.51      0.47       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.49382716049382713 and f1 score is: 0.46096412919980523\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.23      0.33        86\n",
      "           1       0.48      0.79      0.59        76\n",
      "\n",
      "    accuracy                           0.49       162\n",
      "   macro avg       0.52      0.51      0.46       162\n",
      "weighted avg       0.52      0.49      0.45       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.49382716049382713 and f1 score is: 0.4758522727272727\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.29      0.38        86\n",
      "           1       0.47      0.72      0.57        76\n",
      "\n",
      "    accuracy                           0.49       162\n",
      "   macro avg       0.51      0.51      0.48       162\n",
      "weighted avg       0.51      0.49      0.47       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.46296296296296297 and f1 score is: 0.3985918497973117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.13      0.20        86\n",
      "           1       0.46      0.84      0.60        76\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.47      0.49      0.40       162\n",
      "weighted avg       0.47      0.46      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5061728395061729 and f1 score is: 0.4950911640953717\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.34      0.42        86\n",
      "           1       0.48      0.70      0.57        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.52      0.52      0.50       162\n",
      "weighted avg       0.52      0.51      0.49       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5246913580246914 and f1 score is: 0.5041144901610018\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.30      0.40        86\n",
      "           1       0.50      0.78      0.61        76\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.55      0.54      0.50       162\n",
      "weighted avg       0.55      0.52      0.50       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1765.csv ---\n",
      "[16:55:05] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.46296296296296297 and f1 score is: 0.44761904761904764\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.28      0.36        86\n",
      "           1       0.45      0.67      0.54        76\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.47      0.48      0.45       162\n",
      "weighted avg       0.47      0.46      0.44       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5555555555555556 and f1 score is: 0.5511774665230107\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.43      0.51        86\n",
      "           1       0.52      0.70      0.60        76\n",
      "\n",
      "    accuracy                           0.56       162\n",
      "   macro avg       0.57      0.56      0.55       162\n",
      "weighted avg       0.57      0.56      0.55       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8962264150943396 and f1 score is: 0.5141666666666667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.06      0.08        16\n",
      "           1       0.93      0.96      0.95       196\n",
      "\n",
      "    accuracy                           0.90       212\n",
      "   macro avg       0.53      0.51      0.51       212\n",
      "weighted avg       0.87      0.90      0.88       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.9056603773584906 and f1 score is: 0.5205789235639982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.06      0.09        16\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.91       212\n",
      "   macro avg       0.55      0.52      0.52       212\n",
      "weighted avg       0.87      0.91      0.89       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7405660377358491 and f1 score is: 0.5239844866299245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.44      0.20        16\n",
      "           1       0.94      0.77      0.85       196\n",
      "\n",
      "    accuracy                           0.74       212\n",
      "   macro avg       0.54      0.60      0.52       212\n",
      "weighted avg       0.88      0.74      0.80       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7169811320754716 and f1 score is: 0.5286794130724767\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.56      0.23        16\n",
      "           1       0.95      0.73      0.83       196\n",
      "\n",
      "    accuracy                           0.72       212\n",
      "   macro avg       0.55      0.65      0.53       212\n",
      "weighted avg       0.89      0.72      0.78       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8867924528301887 and f1 score is: 0.5411255411255411\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.12      0.14        16\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.89       212\n",
      "   macro avg       0.55      0.54      0.54       212\n",
      "weighted avg       0.87      0.89      0.88       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.660377358490566 and f1 score is: 0.48376623376623373\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.50      0.18        16\n",
      "           1       0.94      0.67      0.79       196\n",
      "\n",
      "    accuracy                           0.66       212\n",
      "   macro avg       0.53      0.59      0.48       212\n",
      "weighted avg       0.88      0.66      0.74       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1818.csv ---\n",
      "[16:57:00] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7264150943396226 and f1 score is: 0.49206873760740255\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.31      0.15        16\n",
      "           1       0.93      0.76      0.84       196\n",
      "\n",
      "    accuracy                           0.73       212\n",
      "   macro avg       0.51      0.54      0.49       212\n",
      "weighted avg       0.87      0.73      0.79       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7735849056603774 and f1 score is: 0.45582887700534763\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.06      0.04        16\n",
      "           1       0.92      0.83      0.87       196\n",
      "\n",
      "    accuracy                           0.77       212\n",
      "   macro avg       0.47      0.45      0.46       212\n",
      "weighted avg       0.85      0.77      0.81       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5231481481481481 and f1 score is: 0.48470179502026634\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.53      0.63       162\n",
      "           1       0.26      0.50      0.34        54\n",
      "\n",
      "    accuracy                           0.52       216\n",
      "   macro avg       0.51      0.52      0.48       216\n",
      "weighted avg       0.64      0.52      0.56       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4537037037037037 and f1 score is: 0.4506896551724138\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.35      0.49       162\n",
      "           1       0.28      0.76      0.41        54\n",
      "\n",
      "    accuracy                           0.45       216\n",
      "   macro avg       0.55      0.56      0.45       216\n",
      "weighted avg       0.68      0.45      0.47       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.49074074074074076 and f1 score is: 0.47619047619047616\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.44      0.56       162\n",
      "           1       0.28      0.65      0.39        54\n",
      "\n",
      "    accuracy                           0.49       216\n",
      "   macro avg       0.53      0.54      0.48       216\n",
      "weighted avg       0.66      0.49      0.52       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5462962962962963 and f1 score is: 0.5055591890124265\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65       162\n",
      "           1       0.28      0.52      0.36        54\n",
      "\n",
      "    accuracy                           0.55       216\n",
      "   macro avg       0.53      0.54      0.51       216\n",
      "weighted avg       0.65      0.55      0.58       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4861111111111111 and f1 score is: 0.48021765993886445\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.40      0.54       162\n",
      "           1       0.29      0.76      0.42        54\n",
      "\n",
      "    accuracy                           0.49       216\n",
      "   macro avg       0.56      0.58      0.48       216\n",
      "weighted avg       0.70      0.49      0.51       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4074074074074074 and f1 score is: 0.4011955297582951\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.34      0.46       162\n",
      "           1       0.24      0.61      0.34        54\n",
      "\n",
      "    accuracy                           0.41       216\n",
      "   macro avg       0.48      0.48      0.40       216\n",
      "weighted avg       0.60      0.41      0.43       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1892.csv ---\n",
      "[16:58:55] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5231481481481481 and f1 score is: 0.4900873232334808\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.52      0.62       162\n",
      "           1       0.27      0.54      0.36        54\n",
      "\n",
      "    accuracy                           0.52       216\n",
      "   macro avg       0.52      0.53      0.49       216\n",
      "weighted avg       0.65      0.52      0.56       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5925925925925926 and f1 score is: 0.515843097300051\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.66      0.71       162\n",
      "           1       0.28      0.39      0.32        54\n",
      "\n",
      "    accuracy                           0.59       216\n",
      "   macro avg       0.52      0.52      0.52       216\n",
      "weighted avg       0.64      0.59      0.61       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6084905660377359 and f1 score is: 0.5200610970187929\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.29      0.31        65\n",
      "           1       0.71      0.75      0.73       147\n",
      "\n",
      "    accuracy                           0.61       212\n",
      "   macro avg       0.52      0.52      0.52       212\n",
      "weighted avg       0.59      0.61      0.60       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6698113207547169 and f1 score is: 0.5063206919494345\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.15      0.22        65\n",
      "           1       0.71      0.90      0.79       147\n",
      "\n",
      "    accuracy                           0.67       212\n",
      "   macro avg       0.55      0.53      0.51       212\n",
      "weighted avg       0.61      0.67      0.62       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6037735849056604 and f1 score is: 0.5166648572359136\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.29      0.31        65\n",
      "           1       0.70      0.74      0.72       147\n",
      "\n",
      "    accuracy                           0.60       212\n",
      "   macro avg       0.52      0.52      0.52       212\n",
      "weighted avg       0.59      0.60      0.60       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6084905660377359 and f1 score is: 0.499302848362405\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.23      0.27        65\n",
      "           1       0.70      0.78      0.73       147\n",
      "\n",
      "    accuracy                           0.61       212\n",
      "   macro avg       0.50      0.50      0.50       212\n",
      "weighted avg       0.58      0.61      0.59       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6320754716981132 and f1 score is: 0.4896296296296296\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.17      0.22        65\n",
      "           1       0.69      0.84      0.76       147\n",
      "\n",
      "    accuracy                           0.63       212\n",
      "   macro avg       0.50      0.50      0.49       212\n",
      "weighted avg       0.58      0.63      0.59       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.589622641509434 and f1 score is: 0.5110156684959836\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.31      0.31        65\n",
      "           1       0.70      0.71      0.71       147\n",
      "\n",
      "    accuracy                           0.59       212\n",
      "   macro avg       0.51      0.51      0.51       212\n",
      "weighted avg       0.58      0.59      0.59       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1929.csv ---\n",
      "[17:00:54] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5566037735849056 and f1 score is: 0.5233448143895905\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.48      0.40        65\n",
      "           1       0.72      0.59      0.65       147\n",
      "\n",
      "    accuracy                           0.56       212\n",
      "   macro avg       0.53      0.53      0.52       212\n",
      "weighted avg       0.60      0.56      0.57       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5235849056603774 and f1 score is: 0.498958698958699\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.49      0.39        65\n",
      "           1       0.71      0.54      0.61       147\n",
      "\n",
      "    accuracy                           0.52       212\n",
      "   macro avg       0.51      0.51      0.50       212\n",
      "weighted avg       0.59      0.52      0.54       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5510204081632653 and f1 score is: 0.5271929824561403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.44      0.42        36\n",
      "           1       0.66      0.61      0.63        62\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.53      0.53      0.53        98\n",
      "weighted avg       0.56      0.55      0.56        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5204081632653061 and f1 score is: 0.5203582213891493\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.69      0.52        36\n",
      "           1       0.70      0.42      0.53        62\n",
      "\n",
      "    accuracy                           0.52        98\n",
      "   macro avg       0.56      0.56      0.52        98\n",
      "weighted avg       0.60      0.52      0.52        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5714285714285714 and f1 score is: 0.5564655172413794\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.53      0.48        36\n",
      "           1       0.69      0.60      0.64        62\n",
      "\n",
      "    accuracy                           0.57        98\n",
      "   macro avg       0.56      0.56      0.56        98\n",
      "weighted avg       0.59      0.57      0.58        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6020408163265306 and f1 score is: 0.5176069670579326\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.25      0.32        36\n",
      "           1       0.65      0.81      0.72        62\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.54      0.53      0.52        98\n",
      "weighted avg       0.57      0.60      0.57        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5612244897959183 and f1 score is: 0.5611787982922003\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.78      0.57        36\n",
      "           1       0.77      0.44      0.56        62\n",
      "\n",
      "    accuracy                           0.56        98\n",
      "   macro avg       0.61      0.61      0.56        98\n",
      "weighted avg       0.65      0.56      0.56        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5612244897959183 and f1 score is: 0.4970760233918129\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.28      0.32        36\n",
      "           1       0.63      0.73      0.68        62\n",
      "\n",
      "    accuracy                           0.56        98\n",
      "   macro avg       0.50      0.50      0.50        98\n",
      "weighted avg       0.54      0.56      0.54        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1933.csv ---\n",
      "[17:02:53] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5612244897959183 and f1 score is: 0.544087417505139\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.50      0.46        36\n",
      "           1       0.67      0.60      0.63        62\n",
      "\n",
      "    accuracy                           0.56        98\n",
      "   macro avg       0.55      0.55      0.54        98\n",
      "weighted avg       0.58      0.56      0.57        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5102040816326531 and f1 score is: 0.5027484143763213\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.53      0.44        36\n",
      "           1       0.65      0.50      0.56        62\n",
      "\n",
      "    accuracy                           0.51        98\n",
      "   macro avg       0.51      0.51      0.50        98\n",
      "weighted avg       0.55      0.51      0.52        98\n",
      "\n",
      "----- Running Modality Combination ECG_EDA_EEG\n",
      "Saved Directory: 2022_08_11_17_03\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5721153846153846 and f1 score is: 0.41813609932421814\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.06      0.12        95\n",
      "           1       0.56      1.00      0.72       113\n",
      "\n",
      "    accuracy                           0.57       208\n",
      "   macro avg       0.78      0.53      0.42       208\n",
      "weighted avg       0.76      0.57      0.44       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5240384615384616 and f1 score is: 0.4792504362339731\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.25      0.33        95\n",
      "           1       0.54      0.75      0.63       113\n",
      "\n",
      "    accuracy                           0.52       208\n",
      "   macro avg       0.50      0.50      0.48       208\n",
      "weighted avg       0.51      0.52      0.49       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5865384615384616 and f1 score is: 0.5188811188811189\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.23      0.34        95\n",
      "           1       0.58      0.88      0.70       113\n",
      "\n",
      "    accuracy                           0.59       208\n",
      "   macro avg       0.60      0.56      0.52       208\n",
      "weighted avg       0.60      0.59      0.53       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5817307692307693 and f1 score is: 0.5112227534235475\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.22      0.33        95\n",
      "           1       0.57      0.88      0.70       113\n",
      "\n",
      "    accuracy                           0.58       208\n",
      "   macro avg       0.60      0.55      0.51       208\n",
      "weighted avg       0.59      0.58      0.53       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5096153846153846 and f1 score is: 0.4887710843373494\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.34      0.39        95\n",
      "           1       0.54      0.65      0.59       113\n",
      "\n",
      "    accuracy                           0.51       208\n",
      "   macro avg       0.50      0.50      0.49       208\n",
      "weighted avg       0.50      0.51      0.50       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5625 and f1 score is: 0.5321221109875169\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.34      0.41        95\n",
      "           1       0.57      0.75      0.65       113\n",
      "\n",
      "    accuracy                           0.56       208\n",
      "   macro avg       0.55      0.54      0.53       208\n",
      "weighted avg       0.56      0.56      0.54       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1105.csv ---\n",
      "[17:05:03] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5625 and f1 score is: 0.4842928370977849\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.19      0.28        95\n",
      "           1       0.56      0.88      0.69       113\n",
      "\n",
      "    accuracy                           0.56       208\n",
      "   macro avg       0.56      0.53      0.48       208\n",
      "weighted avg       0.56      0.56      0.50       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5576923076923077 and f1 score is: 0.5047619047619047\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.25      0.34        95\n",
      "           1       0.56      0.81      0.67       113\n",
      "\n",
      "    accuracy                           0.56       208\n",
      "   macro avg       0.55      0.53      0.50       208\n",
      "weighted avg       0.55      0.56      0.52       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8367346938775511 and f1 score is: 0.5791984732824427\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25        16\n",
      "           1       0.91      0.91      0.91       131\n",
      "\n",
      "    accuracy                           0.84       147\n",
      "   macro avg       0.58      0.58      0.58       147\n",
      "weighted avg       0.84      0.84      0.84       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8503401360544217 and f1 score is: 0.6142652671755725\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.31      0.31        16\n",
      "           1       0.92      0.92      0.92       131\n",
      "\n",
      "    accuracy                           0.85       147\n",
      "   macro avg       0.61      0.61      0.61       147\n",
      "weighted avg       0.85      0.85      0.85       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8095238095238095 and f1 score is: 0.6514227642276422\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.62      0.42        16\n",
      "           1       0.95      0.83      0.89       131\n",
      "\n",
      "    accuracy                           0.81       147\n",
      "   macro avg       0.63      0.73      0.65       147\n",
      "weighted avg       0.88      0.81      0.84       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.782312925170068 and f1 score is: 0.5555555555555556\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.31      0.24        16\n",
      "           1       0.91      0.84      0.87       131\n",
      "\n",
      "    accuracy                           0.78       147\n",
      "   macro avg       0.55      0.58      0.56       147\n",
      "weighted avg       0.83      0.78      0.80       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8707482993197279 and f1 score is: 0.6918918918918918\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.50      0.46        16\n",
      "           1       0.94      0.92      0.93       131\n",
      "\n",
      "    accuracy                           0.87       147\n",
      "   macro avg       0.68      0.71      0.69       147\n",
      "weighted avg       0.88      0.87      0.88       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.4489795918367347 and f1 score is: 0.413823659725299\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.94      0.27        16\n",
      "           1       0.98      0.39      0.56       131\n",
      "\n",
      "    accuracy                           0.45       147\n",
      "   macro avg       0.57      0.66      0.41       147\n",
      "weighted avg       0.89      0.45      0.53       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1106.csv ---\n",
      "[17:07:22] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8707482993197279 and f1 score is: 0.675722744688262\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.44      0.42        16\n",
      "           1       0.93      0.92      0.93       131\n",
      "\n",
      "    accuracy                           0.87       147\n",
      "   macro avg       0.67      0.68      0.68       147\n",
      "weighted avg       0.87      0.87      0.87       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.782312925170068 and f1 score is: 0.5723636363636364\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.38      0.27        16\n",
      "           1       0.92      0.83      0.87       131\n",
      "\n",
      "    accuracy                           0.78       147\n",
      "   macro avg       0.57      0.60      0.57       147\n",
      "weighted avg       0.84      0.78      0.81       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5649717514124294 and f1 score is: 0.4385119268322828\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.10      0.17        84\n",
      "           1       0.55      0.99      0.70        93\n",
      "\n",
      "    accuracy                           0.56       177\n",
      "   macro avg       0.72      0.54      0.44       177\n",
      "weighted avg       0.71      0.56      0.45       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5254237288135594 and f1 score is: 0.5104056902002108\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.74      0.60        84\n",
      "           1       0.58      0.33      0.42        93\n",
      "\n",
      "    accuracy                           0.53       177\n",
      "   macro avg       0.54      0.54      0.51       177\n",
      "weighted avg       0.54      0.53      0.51       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.615819209039548 and f1 score is: 0.5839325221238939\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.36      0.47        84\n",
      "           1       0.59      0.85      0.70        93\n",
      "\n",
      "    accuracy                           0.62       177\n",
      "   macro avg       0.64      0.60      0.58       177\n",
      "weighted avg       0.64      0.62      0.59       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5988700564971752 and f1 score is: 0.5853159544629599\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.44      0.51        84\n",
      "           1       0.59      0.74      0.66        93\n",
      "\n",
      "    accuracy                           0.60       177\n",
      "   macro avg       0.60      0.59      0.59       177\n",
      "weighted avg       0.60      0.60      0.59       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.4915254237288136 and f1 score is: 0.4811750911933298\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.67      0.55        84\n",
      "           1       0.53      0.33      0.41        93\n",
      "\n",
      "    accuracy                           0.49       177\n",
      "   macro avg       0.50      0.50      0.48       177\n",
      "weighted avg       0.50      0.49      0.48       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5706214689265536 and f1 score is: 0.5510013351134846\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.38      0.46        84\n",
      "           1       0.57      0.74      0.64        93\n",
      "\n",
      "    accuracy                           0.57       177\n",
      "   macro avg       0.57      0.56      0.55       177\n",
      "weighted avg       0.57      0.57      0.56       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1175.csv ---\n",
      "[17:09:41] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.6271186440677966 and f1 score is: 0.6013513513513513\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.39      0.50        84\n",
      "           1       0.60      0.84      0.70        93\n",
      "\n",
      "    accuracy                           0.63       177\n",
      "   macro avg       0.65      0.62      0.60       177\n",
      "weighted avg       0.64      0.63      0.61       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5819209039548022 and f1 score is: 0.5649083178315174\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.40      0.48        84\n",
      "           1       0.58      0.74      0.65        93\n",
      "\n",
      "    accuracy                           0.58       177\n",
      "   macro avg       0.58      0.57      0.56       177\n",
      "weighted avg       0.58      0.58      0.57       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5648148148148148 and f1 score is: 0.5033268101761252\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.20      0.33       113\n",
      "           1       0.52      0.96      0.68       103\n",
      "\n",
      "    accuracy                           0.56       216\n",
      "   macro avg       0.69      0.58      0.50       216\n",
      "weighted avg       0.70      0.56      0.50       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5092592592592593 and f1 score is: 0.4996066089693155\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.62      0.57       113\n",
      "           1       0.48      0.39      0.43       103\n",
      "\n",
      "    accuracy                           0.51       216\n",
      "   macro avg       0.50      0.50      0.50       216\n",
      "weighted avg       0.51      0.51      0.50       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6990740740740741 and f1 score is: 0.6942974720752497\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.55      0.66       113\n",
      "           1       0.64      0.86      0.73       103\n",
      "\n",
      "    accuracy                           0.70       216\n",
      "   macro avg       0.73      0.71      0.69       216\n",
      "weighted avg       0.73      0.70      0.69       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5046296296296297 and f1 score is: 0.5022291141694126\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.42      0.47       113\n",
      "           1       0.48      0.60      0.54       103\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.51      0.51      0.50       216\n",
      "weighted avg       0.51      0.50      0.50       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.49074074074074076 and f1 score is: 0.48203697244506455\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.59      0.55       113\n",
      "           1       0.46      0.38      0.41       103\n",
      "\n",
      "    accuracy                           0.49       216\n",
      "   macro avg       0.49      0.49      0.48       216\n",
      "weighted avg       0.49      0.49      0.49       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5 and f1 score is: 0.4947587282335615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.58      0.55       113\n",
      "           1       0.47      0.42      0.44       103\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.50      0.50      0.49       216\n",
      "weighted avg       0.50      0.50      0.50       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1337.csv ---\n",
      "[17:11:58] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5925925925925926 and f1 score is: 0.5856295779560516\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.44      0.53       113\n",
      "           1       0.55      0.76      0.64       103\n",
      "\n",
      "    accuracy                           0.59       216\n",
      "   macro avg       0.61      0.60      0.59       216\n",
      "weighted avg       0.61      0.59      0.58       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6481481481481481 and f1 score is: 0.6470588235294118\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.57      0.63       113\n",
      "           1       0.61      0.74      0.67       103\n",
      "\n",
      "    accuracy                           0.65       216\n",
      "   macro avg       0.66      0.65      0.65       216\n",
      "weighted avg       0.66      0.65      0.65       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.49295774647887325 and f1 score is: 0.44434782608695644\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.22      0.28        95\n",
      "           1       0.53      0.71      0.61       118\n",
      "\n",
      "    accuracy                           0.49       213\n",
      "   macro avg       0.46      0.47      0.44       213\n",
      "weighted avg       0.46      0.49      0.46       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.45539906103286387 and f1 score is: 0.4322610294117647\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.74      0.55        95\n",
      "           1       0.52      0.23      0.32       118\n",
      "\n",
      "    accuracy                           0.46       213\n",
      "   macro avg       0.48      0.48      0.43       213\n",
      "weighted avg       0.48      0.46      0.42       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5070422535211268 and f1 score is: 0.44735476537596675\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.94      0.63        95\n",
      "           1       0.76      0.16      0.27       118\n",
      "\n",
      "    accuracy                           0.51       213\n",
      "   macro avg       0.62      0.55      0.45       213\n",
      "weighted avg       0.63      0.51      0.43       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5727699530516432 and f1 score is: 0.5714096185737977\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.58      0.55        95\n",
      "           1       0.63      0.57      0.60       118\n",
      "\n",
      "    accuracy                           0.57       213\n",
      "   macro avg       0.57      0.57      0.57       213\n",
      "weighted avg       0.58      0.57      0.57       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.4413145539906103 and f1 score is: 0.36924225457260174\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.87      0.58        95\n",
      "           1       0.48      0.09      0.16       118\n",
      "\n",
      "    accuracy                           0.44       213\n",
      "   macro avg       0.46      0.48      0.37       213\n",
      "weighted avg       0.46      0.44      0.35       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.4835680751173709 and f1 score is: 0.4340579710144927\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.87      0.60        95\n",
      "           1       0.62      0.17      0.27       118\n",
      "\n",
      "    accuracy                           0.48       213\n",
      "   macro avg       0.54      0.52      0.43       213\n",
      "weighted avg       0.55      0.48      0.42       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1390.csv ---\n",
      "[17:14:14] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5117370892018779 and f1 score is: 0.47951127819548867\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.29      0.35        95\n",
      "           1       0.55      0.69      0.61       118\n",
      "\n",
      "    accuracy                           0.51       213\n",
      "   macro avg       0.49      0.49      0.48       213\n",
      "weighted avg       0.50      0.51      0.49       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5117370892018779 and f1 score is: 0.48204264870931535\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.31      0.36        95\n",
      "           1       0.55      0.68      0.61       118\n",
      "\n",
      "    accuracy                           0.51       213\n",
      "   macro avg       0.49      0.49      0.48       213\n",
      "weighted avg       0.50      0.51      0.50       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6333333333333333 and f1 score is: 0.44185564875220046\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.94      0.77       136\n",
      "           1       0.38      0.07      0.11        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.52      0.50      0.44       210\n",
      "weighted avg       0.56      0.63      0.54       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.47619047619047616 and f1 score is: 0.4543650793650793\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.52      0.56       136\n",
      "           1       0.31      0.39      0.35        74\n",
      "\n",
      "    accuracy                           0.48       210\n",
      "   macro avg       0.46      0.46      0.45       210\n",
      "weighted avg       0.51      0.48      0.49       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6095238095238096 and f1 score is: 0.4105969331872946\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.92      0.75       136\n",
      "           1       0.21      0.04      0.07        74\n",
      "\n",
      "    accuracy                           0.61       210\n",
      "   macro avg       0.43      0.48      0.41       210\n",
      "weighted avg       0.49      0.61      0.51       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5761904761904761 and f1 score is: 0.5021177974906097\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69       136\n",
      "           1       0.36      0.27      0.31        74\n",
      "\n",
      "    accuracy                           0.58       210\n",
      "   macro avg       0.51      0.51      0.50       210\n",
      "weighted avg       0.55      0.58      0.56       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.45714285714285713 and f1 score is: 0.43452380952380953\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.51      0.55       136\n",
      "           1       0.29      0.36      0.32        74\n",
      "\n",
      "    accuracy                           0.46       210\n",
      "   macro avg       0.44      0.44      0.43       210\n",
      "weighted avg       0.49      0.46      0.47       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.4523809523809524 and f1 score is: 0.4523685344338874\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.35      0.45       136\n",
      "           1       0.35      0.65      0.45        74\n",
      "\n",
      "    accuracy                           0.45       210\n",
      "   macro avg       0.50      0.50      0.45       210\n",
      "weighted avg       0.54      0.45      0.45       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1400.csv ---\n",
      "[17:16:31] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.46190476190476193 and f1 score is: 0.44058087177915556\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55       136\n",
      "           1       0.29      0.38      0.33        74\n",
      "\n",
      "    accuracy                           0.46       210\n",
      "   macro avg       0.45      0.44      0.44       210\n",
      "weighted avg       0.49      0.46      0.47       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5571428571428572 and f1 score is: 0.4601840846900136\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69       136\n",
      "           1       0.30      0.19      0.23        74\n",
      "\n",
      "    accuracy                           0.56       210\n",
      "   macro avg       0.46      0.47      0.46       210\n",
      "weighted avg       0.51      0.56      0.53       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.514018691588785 and f1 score is: 0.5119298245614035\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.65      0.54        95\n",
      "           1       0.59      0.40      0.48       119\n",
      "\n",
      "    accuracy                           0.51       214\n",
      "   macro avg       0.53      0.53      0.51       214\n",
      "weighted avg       0.54      0.51      0.51       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.45794392523364486 and f1 score is: 0.4421573033707865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.71      0.54        95\n",
      "           1       0.53      0.26      0.35       119\n",
      "\n",
      "    accuracy                           0.46       214\n",
      "   macro avg       0.48      0.48      0.44       214\n",
      "weighted avg       0.48      0.46      0.43       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5327102803738317 and f1 score is: 0.532669461914745\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.59      0.53        95\n",
      "           1       0.60      0.49      0.54       119\n",
      "\n",
      "    accuracy                           0.53       214\n",
      "   macro avg       0.54      0.54      0.53       214\n",
      "weighted avg       0.54      0.53      0.53       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5 and f1 score is: 0.4997269013130585\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.54      0.49        95\n",
      "           1       0.56      0.47      0.51       119\n",
      "\n",
      "    accuracy                           0.50       214\n",
      "   macro avg       0.50      0.50      0.50       214\n",
      "weighted avg       0.51      0.50      0.50       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.4485981308411215 and f1 score is: 0.41675905395417595\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.77      0.55        95\n",
      "           1       0.51      0.19      0.28       119\n",
      "\n",
      "    accuracy                           0.45       214\n",
      "   macro avg       0.47      0.48      0.42       214\n",
      "weighted avg       0.48      0.45      0.40       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5514018691588785 and f1 score is: 0.5507740750459197\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.58      0.53        95\n",
      "           1       0.61      0.53      0.57       119\n",
      "\n",
      "    accuracy                           0.55       214\n",
      "   macro avg       0.55      0.55      0.55       214\n",
      "weighted avg       0.56      0.55      0.55       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1419.csv ---\n",
      "[17:18:47] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.602803738317757 and f1 score is: 0.5676767676767677\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.36      0.44        95\n",
      "           1       0.61      0.80      0.69       119\n",
      "\n",
      "    accuracy                           0.60       214\n",
      "   macro avg       0.60      0.58      0.57       214\n",
      "weighted avg       0.60      0.60      0.58       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.514018691588785 and f1 score is: 0.5112867808519983\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.49      0.47        95\n",
      "           1       0.57      0.53      0.55       119\n",
      "\n",
      "    accuracy                           0.51       214\n",
      "   macro avg       0.51      0.51      0.51       214\n",
      "weighted avg       0.52      0.51      0.52       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.46296296296296297 and f1 score is: 0.46195838900553543\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.34      0.49       122\n",
      "           1       0.30      0.85      0.44        40\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.58      0.59      0.46       162\n",
      "weighted avg       0.73      0.46      0.47       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.37037037037037035 and f1 score is: 0.37027439024390246\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.24      0.36       122\n",
      "           1       0.25      0.78      0.38        40\n",
      "\n",
      "    accuracy                           0.37       162\n",
      "   macro avg       0.51      0.51      0.37       162\n",
      "weighted avg       0.64      0.37      0.37       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.49382716049382713 and f1 score is: 0.47824037706205813\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.44      0.57       122\n",
      "           1       0.28      0.65      0.39        40\n",
      "\n",
      "    accuracy                           0.49       162\n",
      "   macro avg       0.54      0.55      0.48       162\n",
      "weighted avg       0.67      0.49      0.52       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.4382716049382716 and f1 score is: 0.3956958393113343\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.47      0.56       122\n",
      "           1       0.18      0.35      0.24        40\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.43      0.41      0.40       162\n",
      "weighted avg       0.56      0.44      0.48       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.3888888888888889 and f1 score is: 0.38886560225583966\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.25      0.39       122\n",
      "           1       0.26      0.80      0.39        40\n",
      "\n",
      "    accuracy                           0.39       162\n",
      "   macro avg       0.53      0.53      0.39       162\n",
      "weighted avg       0.66      0.39      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.32098765432098764 and f1 score is: 0.30303504380475593\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.11      0.19       122\n",
      "           1       0.26      0.97      0.41        40\n",
      "\n",
      "    accuracy                           0.32       162\n",
      "   macro avg       0.60      0.54      0.30       162\n",
      "weighted avg       0.76      0.32      0.25       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1517.csv ---\n",
      "[17:21:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5061728395061729 and f1 score is: 0.493116395494368\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.44      0.57       122\n",
      "           1       0.29      0.70      0.41        40\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.55      0.57      0.49       162\n",
      "weighted avg       0.69      0.51      0.53       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.47530864197530864 and f1 score is: 0.46799057296294866\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.39      0.53       122\n",
      "           1       0.28      0.72      0.41        40\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.55      0.56      0.47       162\n",
      "weighted avg       0.68      0.48      0.50       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6739130434782609 and f1 score is: 0.5880597014925373\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40        10\n",
      "           1       0.84      0.72      0.78        36\n",
      "\n",
      "    accuracy                           0.67        46\n",
      "   macro avg       0.59      0.61      0.59        46\n",
      "weighted avg       0.73      0.67      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.2391304347826087 and f1 score is: 0.20884520884520882\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36        10\n",
      "           1       1.00      0.03      0.05        36\n",
      "\n",
      "    accuracy                           0.24        46\n",
      "   macro avg       0.61      0.51      0.21        46\n",
      "weighted avg       0.83      0.24      0.12        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.4782608695652174 and f1 score is: 0.4619883040935673\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.70      0.37        10\n",
      "           1       0.83      0.42      0.56        36\n",
      "\n",
      "    accuracy                           0.48        46\n",
      "   macro avg       0.54      0.56      0.46        46\n",
      "weighted avg       0.71      0.48      0.51        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.30434782608695654 and f1 score is: 0.30434782608695654\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.70      0.30        10\n",
      "           1       0.70      0.19      0.30        36\n",
      "\n",
      "    accuracy                           0.30        46\n",
      "   macro avg       0.45      0.45      0.30        46\n",
      "weighted avg       0.59      0.30      0.30        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.21739130434782608 and f1 score is: 0.17857142857142855\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36        10\n",
      "           1       1.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.22        46\n",
      "   macro avg       0.61      0.50      0.18        46\n",
      "weighted avg       0.83      0.22      0.08        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6739130434782609 and f1 score is: 0.5880597014925373\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40        10\n",
      "           1       0.84      0.72      0.78        36\n",
      "\n",
      "    accuracy                           0.67        46\n",
      "   macro avg       0.59      0.61      0.59        46\n",
      "weighted avg       0.73      0.67      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1544.csv ---\n",
      "[17:23:29] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.8695652173913043 and f1 score is: 0.7472527472527473\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57        10\n",
      "           1       0.86      1.00      0.92        36\n",
      "\n",
      "    accuracy                           0.87        46\n",
      "   macro avg       0.93      0.70      0.75        46\n",
      "weighted avg       0.89      0.87      0.85        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.7391304347826086 and f1 score is: 0.6415584415584416\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.50      0.45        10\n",
      "           1       0.85      0.81      0.83        36\n",
      "\n",
      "    accuracy                           0.74        46\n",
      "   macro avg       0.63      0.65      0.64        46\n",
      "weighted avg       0.76      0.74      0.75        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5345911949685535 and f1 score is: 0.5108912537412703\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.34      0.40        73\n",
      "           1       0.56      0.70      0.62        86\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.52      0.52      0.51       159\n",
      "weighted avg       0.53      0.53      0.52       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5345911949685535 and f1 score is: 0.5185761047463175\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.38      0.43        73\n",
      "           1       0.56      0.66      0.61        86\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.53      0.52      0.52       159\n",
      "weighted avg       0.53      0.53      0.53       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5471698113207547 and f1 score is: 0.5356911096690461\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.42      0.46        73\n",
      "           1       0.57      0.65      0.61        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.54      0.54      0.54       159\n",
      "weighted avg       0.54      0.55      0.54       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5094339622641509 and f1 score is: 0.5037612035851472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.44      0.45        73\n",
      "           1       0.54      0.57      0.56        86\n",
      "\n",
      "    accuracy                           0.51       159\n",
      "   macro avg       0.50      0.50      0.50       159\n",
      "weighted avg       0.51      0.51      0.51       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5094339622641509 and f1 score is: 0.4311009174311926\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.15      0.22        73\n",
      "           1       0.53      0.81      0.64        86\n",
      "\n",
      "    accuracy                           0.51       159\n",
      "   macro avg       0.47      0.48      0.43       159\n",
      "weighted avg       0.47      0.51      0.45       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5345911949685535 and f1 score is: 0.38203781512605034\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.04      0.07        73\n",
      "           1       0.54      0.95      0.69        86\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.48      0.50      0.38       159\n",
      "weighted avg       0.49      0.53      0.41       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1624.csv ---\n",
      "[17:25:51] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5094339622641509 and f1 score is: 0.5050287356321839\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.66      0.55        73\n",
      "           1       0.57      0.38      0.46        86\n",
      "\n",
      "    accuracy                           0.51       159\n",
      "   macro avg       0.52      0.52      0.51       159\n",
      "weighted avg       0.53      0.51      0.50       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5157232704402516 and f1 score is: 0.4925181347150259\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.79      0.60        73\n",
      "           1       0.62      0.28      0.38        86\n",
      "\n",
      "    accuracy                           0.52       159\n",
      "   macro avg       0.55      0.54      0.49       159\n",
      "weighted avg       0.55      0.52      0.48       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6740331491712708 and f1 score is: 0.41838679810467844\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.03        60\n",
      "           1       0.67      1.00      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.84      0.51      0.42       181\n",
      "weighted avg       0.78      0.67      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6685082872928176 and f1 score is: 0.41612903225806447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.02      0.03        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.59      0.50      0.42       181\n",
      "weighted avg       0.61      0.67      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.712707182320442 and f1 score is: 0.5583708708708709\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.18      0.30        60\n",
      "           1       0.71      0.98      0.82       121\n",
      "\n",
      "    accuracy                           0.71       181\n",
      "   macro avg       0.75      0.58      0.56       181\n",
      "weighted avg       0.73      0.71      0.65       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.35911602209944754 and f1 score is: 0.35197530864197535\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.38      0.28        60\n",
      "           1       0.53      0.35      0.42       121\n",
      "\n",
      "    accuracy                           0.36       181\n",
      "   macro avg       0.38      0.37      0.35       181\n",
      "weighted avg       0.43      0.36      0.37       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6629834254143646 and f1 score is: 0.4280756280756281\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.03      0.06        60\n",
      "           1       0.67      0.98      0.79       121\n",
      "\n",
      "    accuracy                           0.66       181\n",
      "   macro avg       0.54      0.50      0.43       181\n",
      "weighted avg       0.58      0.66      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6685082872928176 and f1 score is: 0.43057885906040266\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.03      0.06        60\n",
      "           1       0.67      0.98      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.59      0.51      0.43       181\n",
      "weighted avg       0.62      0.67      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1688.csv ---\n",
      "[17:28:09] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6685082872928176 and f1 score is: 0.5496018579960186\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.23      0.32        60\n",
      "           1       0.70      0.88      0.78       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.60      0.56      0.55       181\n",
      "weighted avg       0.63      0.67      0.63       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6132596685082873 and f1 score is: 0.5852971982194292\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.53      0.48        60\n",
      "           1       0.74      0.65      0.69       121\n",
      "\n",
      "    accuracy                           0.61       181\n",
      "   macro avg       0.59      0.59      0.59       181\n",
      "weighted avg       0.64      0.61      0.62       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.7314814814814815 and f1 score is: 0.546284224250326\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.15      0.26        34\n",
      "           1       0.72      1.00      0.84        74\n",
      "\n",
      "    accuracy                           0.73       108\n",
      "   macro avg       0.86      0.57      0.55       108\n",
      "weighted avg       0.81      0.73      0.65       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.39814814814814814 and f1 score is: 0.39560912613000426\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.74      0.43        34\n",
      "           1       0.67      0.24      0.36        74\n",
      "\n",
      "    accuracy                           0.40       108\n",
      "   macro avg       0.49      0.49      0.40       108\n",
      "weighted avg       0.55      0.40      0.38       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5648148148148148 and f1 score is: 0.5309987988542919\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.47      0.41        34\n",
      "           1       0.71      0.61      0.66        74\n",
      "\n",
      "    accuracy                           0.56       108\n",
      "   macro avg       0.53      0.54      0.53       108\n",
      "weighted avg       0.60      0.56      0.58       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5833333333333334 and f1 score is: 0.5804195804195804\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.79      0.55        34\n",
      "           1       0.84      0.49      0.62        74\n",
      "\n",
      "    accuracy                           0.58       108\n",
      "   macro avg       0.63      0.64      0.58       108\n",
      "weighted avg       0.70      0.58      0.59       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.37962962962962965 and f1 score is: 0.3795764383091829\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.62      0.39        34\n",
      "           1       0.61      0.27      0.37        74\n",
      "\n",
      "    accuracy                           0.38       108\n",
      "   macro avg       0.44      0.44      0.38       108\n",
      "weighted avg       0.50      0.38      0.38       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6574074074074074 and f1 score is: 0.5686062830616431\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.32      0.37        34\n",
      "           1       0.72      0.81      0.76        74\n",
      "\n",
      "    accuracy                           0.66       108\n",
      "   macro avg       0.58      0.57      0.57       108\n",
      "weighted avg       0.63      0.66      0.64       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1717.csv ---\n",
      "[17:30:29] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6759259259259259 and f1 score is: 0.6273291925465838\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.50      0.49        34\n",
      "           1       0.77      0.76      0.76        74\n",
      "\n",
      "    accuracy                           0.68       108\n",
      "   macro avg       0.63      0.63      0.63       108\n",
      "weighted avg       0.68      0.68      0.68       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6666666666666666 and f1 score is: 0.5927943024717218\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.38      0.42        34\n",
      "           1       0.74      0.80      0.77        74\n",
      "\n",
      "    accuracy                           0.67       108\n",
      "   macro avg       0.60      0.59      0.59       108\n",
      "weighted avg       0.65      0.67      0.66       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.47530864197530864 and f1 score is: 0.38181818181818183\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.08      0.14        86\n",
      "           1       0.47      0.92      0.62        76\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.50      0.50      0.38       162\n",
      "weighted avg       0.51      0.48      0.37       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5617283950617284 and f1 score is: 0.49470632166234674\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.19      0.31        86\n",
      "           1       0.52      0.99      0.68        76\n",
      "\n",
      "    accuracy                           0.56       162\n",
      "   macro avg       0.73      0.59      0.49       162\n",
      "weighted avg       0.74      0.56      0.48       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5 and f1 score is: 0.41739555121431426\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.12      0.20        86\n",
      "           1       0.48      0.93      0.64        76\n",
      "\n",
      "    accuracy                           0.50       162\n",
      "   macro avg       0.57      0.53      0.42       162\n",
      "weighted avg       0.58      0.50      0.40       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4567901234567901 and f1 score is: 0.3635714285714286\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.07      0.12        86\n",
      "           1       0.46      0.89      0.61        76\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.44      0.48      0.36       162\n",
      "weighted avg       0.44      0.46      0.35       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5370370370370371 and f1 score is: 0.45454545454545453\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.14      0.24        86\n",
      "           1       0.50      0.99      0.67        76\n",
      "\n",
      "    accuracy                           0.54       162\n",
      "   macro avg       0.71      0.56      0.45       162\n",
      "weighted avg       0.73      0.54      0.44       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4506172839506173 and f1 score is: 0.37904302510874716\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.10      0.17        86\n",
      "           1       0.45      0.84      0.59        76\n",
      "\n",
      "    accuracy                           0.45       162\n",
      "   macro avg       0.44      0.47      0.38       162\n",
      "weighted avg       0.44      0.45      0.37       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1765.csv ---\n",
      "[17:32:50] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5 and f1 score is: 0.41090909090909095\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.10      0.18        86\n",
      "           1       0.48      0.95      0.64        76\n",
      "\n",
      "    accuracy                           0.50       162\n",
      "   macro avg       0.59      0.53      0.41       162\n",
      "weighted avg       0.59      0.50      0.40       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5061728395061729 and f1 score is: 0.46286472148541113\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.21      0.31        86\n",
      "           1       0.48      0.84      0.62        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.54      0.53      0.46       162\n",
      "weighted avg       0.55      0.51      0.45       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8915094339622641 and f1 score is: 0.64186558942343\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.38      0.34        16\n",
      "           1       0.95      0.93      0.94       196\n",
      "\n",
      "    accuracy                           0.89       212\n",
      "   macro avg       0.63      0.65      0.64       212\n",
      "weighted avg       0.90      0.89      0.90       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7830188679245284 and f1 score is: 0.4596631205673759\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.06      0.04        16\n",
      "           1       0.92      0.84      0.88       196\n",
      "\n",
      "    accuracy                           0.78       212\n",
      "   macro avg       0.47      0.45      0.46       212\n",
      "weighted avg       0.85      0.78      0.81       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6792452830188679 and f1 score is: 0.48595064898017404\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.44      0.17        16\n",
      "           1       0.94      0.70      0.80       196\n",
      "\n",
      "    accuracy                           0.68       212\n",
      "   macro avg       0.52      0.57      0.49       212\n",
      "weighted avg       0.88      0.68      0.75       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6179245283018868 and f1 score is: 0.4421596335639802\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.38      0.13        16\n",
      "           1       0.93      0.64      0.76       196\n",
      "\n",
      "    accuracy                           0.62       212\n",
      "   macro avg       0.50      0.51      0.44       212\n",
      "weighted avg       0.86      0.62      0.71       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7452830188679245 and f1 score is: 0.46071226681741095\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.12      0.07        16\n",
      "           1       0.92      0.80      0.85       196\n",
      "\n",
      "    accuracy                           0.75       212\n",
      "   macro avg       0.48      0.46      0.46       212\n",
      "weighted avg       0.85      0.75      0.79       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7358490566037735 and f1 score is: 0.5315656565656566\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.50      0.22        16\n",
      "           1       0.95      0.76      0.84       196\n",
      "\n",
      "    accuracy                           0.74       212\n",
      "   macro avg       0.55      0.63      0.53       212\n",
      "weighted avg       0.89      0.74      0.79       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1818.csv ---\n",
      "[17:35:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8066037735849056 and f1 score is: 0.5717171717171717\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.44      0.25        16\n",
      "           1       0.95      0.84      0.89       196\n",
      "\n",
      "    accuracy                           0.81       212\n",
      "   macro avg       0.56      0.64      0.57       212\n",
      "weighted avg       0.89      0.81      0.84       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7783018867924528 and f1 score is: 0.5236866006979302\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.31      0.18        16\n",
      "           1       0.94      0.82      0.87       196\n",
      "\n",
      "    accuracy                           0.78       212\n",
      "   macro avg       0.53      0.56      0.52       212\n",
      "weighted avg       0.87      0.78      0.82       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.6157407407407407 and f1 score is: 0.4844572250179727\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74       162\n",
      "           1       0.23      0.22      0.22        54\n",
      "\n",
      "    accuracy                           0.62       216\n",
      "   macro avg       0.48      0.48      0.48       216\n",
      "weighted avg       0.61      0.62      0.61       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.46296296296296297 and f1 score is: 0.42426470588235293\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.48      0.57       162\n",
      "           1       0.21      0.41      0.28        54\n",
      "\n",
      "    accuracy                           0.46       216\n",
      "   macro avg       0.46      0.44      0.42       216\n",
      "weighted avg       0.58      0.46      0.50       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5462962962962963 and f1 score is: 0.48958333333333337\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66       162\n",
      "           1       0.26      0.43      0.32        54\n",
      "\n",
      "    accuracy                           0.55       216\n",
      "   macro avg       0.50      0.51      0.49       216\n",
      "weighted avg       0.63      0.55      0.57       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4583333333333333 and f1 score is: 0.4483902651969879\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.40      0.52       162\n",
      "           1       0.26      0.65      0.37        54\n",
      "\n",
      "    accuracy                           0.46       216\n",
      "   macro avg       0.52      0.52      0.45       216\n",
      "weighted avg       0.64      0.46      0.49       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4305555555555556 and f1 score is: 0.4022543703737035\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.43      0.53       162\n",
      "           1       0.20      0.43      0.27        54\n",
      "\n",
      "    accuracy                           0.43       216\n",
      "   macro avg       0.45      0.43      0.40       216\n",
      "weighted avg       0.57      0.43      0.47       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4861111111111111 and f1 score is: 0.4504824551351103\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.49      0.59       162\n",
      "           1       0.23      0.46      0.31        54\n",
      "\n",
      "    accuracy                           0.49       216\n",
      "   macro avg       0.48      0.48      0.45       216\n",
      "weighted avg       0.61      0.49      0.52       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1892.csv ---\n",
      "[17:37:24] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5740740740740741 and f1 score is: 0.4938359653591442\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.70       162\n",
      "           1       0.25      0.35      0.29        54\n",
      "\n",
      "    accuracy                           0.57       216\n",
      "   macro avg       0.50      0.50      0.49       216\n",
      "weighted avg       0.62      0.57      0.59       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.6712962962962963 and f1 score is: 0.520974543182883\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       162\n",
      "           1       0.29      0.22      0.25        54\n",
      "\n",
      "    accuracy                           0.67       216\n",
      "   macro avg       0.53      0.52      0.52       216\n",
      "weighted avg       0.64      0.67      0.66       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5330188679245284 and f1 score is: 0.4740245094353809\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.32      0.30        65\n",
      "           1       0.68      0.63      0.65       147\n",
      "\n",
      "    accuracy                           0.53       212\n",
      "   macro avg       0.48      0.47      0.47       212\n",
      "weighted avg       0.55      0.53      0.54       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.41037735849056606 and f1 score is: 0.40206232090074234\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.48      0.33        65\n",
      "           1       0.62      0.38      0.47       147\n",
      "\n",
      "    accuracy                           0.41       212\n",
      "   macro avg       0.44      0.43      0.40       212\n",
      "weighted avg       0.51      0.41      0.43       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5141509433962265 and f1 score is: 0.4637392863282497\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.34      0.30        65\n",
      "           1       0.67      0.59      0.63       147\n",
      "\n",
      "    accuracy                           0.51       212\n",
      "   macro avg       0.47      0.47      0.46       212\n",
      "weighted avg       0.55      0.51      0.53       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.6698113207547169 and f1 score is: 0.49810606060606066\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.14      0.20        65\n",
      "           1       0.70      0.90      0.79       147\n",
      "\n",
      "    accuracy                           0.67       212\n",
      "   macro avg       0.55      0.52      0.50       212\n",
      "weighted avg       0.61      0.67      0.61       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.42924528301886794 and f1 score is: 0.4167746629379533\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.46      0.33        65\n",
      "           1       0.64      0.41      0.50       147\n",
      "\n",
      "    accuracy                           0.43       212\n",
      "   macro avg       0.45      0.44      0.42       212\n",
      "weighted avg       0.52      0.43      0.45       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.38207547169811323 and f1 score is: 0.38173156125470287\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.37        65\n",
      "           1       0.61      0.29      0.40       147\n",
      "\n",
      "    accuracy                           0.38       212\n",
      "   macro avg       0.44      0.44      0.38       212\n",
      "weighted avg       0.51      0.38      0.39       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1929.csv ---\n",
      "[17:39:41] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5613207547169812 and f1 score is: 0.4905821254166343\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.31      0.30        65\n",
      "           1       0.69      0.67      0.68       147\n",
      "\n",
      "    accuracy                           0.56       212\n",
      "   macro avg       0.49      0.49      0.49       212\n",
      "weighted avg       0.57      0.56      0.56       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5330188679245284 and f1 score is: 0.47020068156001515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.31      0.29        65\n",
      "           1       0.67      0.63      0.65       147\n",
      "\n",
      "    accuracy                           0.53       212\n",
      "   macro avg       0.47      0.47      0.47       212\n",
      "weighted avg       0.55      0.53      0.54       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5204081632653061 and f1 score is: 0.39226810924924127\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.08      0.11        36\n",
      "           1       0.59      0.77      0.67        62\n",
      "\n",
      "    accuracy                           0.52        98\n",
      "   macro avg       0.38      0.43      0.39        98\n",
      "weighted avg       0.44      0.52      0.47        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6122448979591837 and f1 score is: 0.5828853046594982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.47      0.47        36\n",
      "           1       0.69      0.69      0.69        62\n",
      "\n",
      "    accuracy                           0.61        98\n",
      "   macro avg       0.58      0.58      0.58        98\n",
      "weighted avg       0.61      0.61      0.61        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5204081632653061 and f1 score is: 0.4186545500441752\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.14      0.18        36\n",
      "           1       0.60      0.74      0.66        62\n",
      "\n",
      "    accuracy                           0.52        98\n",
      "   macro avg       0.42      0.44      0.42        98\n",
      "weighted avg       0.47      0.52      0.48        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5612244897959183 and f1 score is: 0.4681307585510539\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.19      0.25        36\n",
      "           1       0.62      0.77      0.69        62\n",
      "\n",
      "    accuracy                           0.56        98\n",
      "   macro avg       0.48      0.48      0.47        98\n",
      "weighted avg       0.52      0.56      0.53        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6122448979591837 and f1 score is: 0.5916666666666667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.53      0.50        36\n",
      "           1       0.71      0.66      0.68        62\n",
      "\n",
      "    accuracy                           0.61        98\n",
      "   macro avg       0.59      0.59      0.59        98\n",
      "weighted avg       0.62      0.61      0.62        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6122448979591837 and f1 score is: 0.4602898550724637\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.11      0.17        36\n",
      "           1       0.64      0.90      0.75        62\n",
      "\n",
      "    accuracy                           0.61        98\n",
      "   macro avg       0.52      0.51      0.46        98\n",
      "weighted avg       0.55      0.61      0.54        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1933.csv ---\n",
      "[17:42:01] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5816326530612245 and f1 score is: 0.52046783625731\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.31      0.35        36\n",
      "           1       0.65      0.74      0.69        62\n",
      "\n",
      "    accuracy                           0.58        98\n",
      "   macro avg       0.53      0.52      0.52        98\n",
      "weighted avg       0.56      0.58      0.57        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5408163265306123 and f1 score is: 0.4897604998264492\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.31      0.33        36\n",
      "           1       0.63      0.68      0.65        62\n",
      "\n",
      "    accuracy                           0.54        98\n",
      "   macro avg       0.49      0.49      0.49        98\n",
      "weighted avg       0.53      0.54      0.53        98\n",
      "\n",
      "----- Running Modality Combination ECG_EDA_GAZE\n",
      "Saved Directory: 2022_08_11_17_43\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5817307692307693 and f1 score is: 0.43869226712987375\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.16        95\n",
      "           1       0.56      1.00      0.72       113\n",
      "\n",
      "    accuracy                           0.58       208\n",
      "   macro avg       0.78      0.54      0.44       208\n",
      "weighted avg       0.76      0.58      0.46       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5817307692307693 and f1 score is: 0.5153073523503415\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.23      0.34        95\n",
      "           1       0.58      0.88      0.69       113\n",
      "\n",
      "    accuracy                           0.58       208\n",
      "   macro avg       0.59      0.55      0.52       208\n",
      "weighted avg       0.59      0.58      0.53       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6057692307692307 and f1 score is: 0.5554165363361485\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.29      0.41        95\n",
      "           1       0.59      0.87      0.71       113\n",
      "\n",
      "    accuracy                           0.61       208\n",
      "   macro avg       0.62      0.58      0.56       208\n",
      "weighted avg       0.62      0.61      0.57       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5769230769230769 and f1 score is: 0.5356671740233384\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.31      0.40        95\n",
      "           1       0.58      0.81      0.67       113\n",
      "\n",
      "    accuracy                           0.58       208\n",
      "   macro avg       0.57      0.56      0.54       208\n",
      "weighted avg       0.57      0.58      0.55       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5817307692307693 and f1 score is: 0.5025154639175258\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.20      0.30        95\n",
      "           1       0.57      0.90      0.70       113\n",
      "\n",
      "    accuracy                           0.58       208\n",
      "   macro avg       0.60      0.55      0.50       208\n",
      "weighted avg       0.60      0.58      0.52       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6298076923076923 and f1 score is: 0.6061284214150456\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.42      0.51        95\n",
      "           1       0.62      0.81      0.70       113\n",
      "\n",
      "    accuracy                           0.63       208\n",
      "   macro avg       0.63      0.61      0.61       208\n",
      "weighted avg       0.63      0.63      0.61       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1105.csv ---\n",
      "[17:43:44] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5961538461538461 and f1 score is: 0.5081081081081081\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.19      0.30        95\n",
      "           1       0.58      0.94      0.72       113\n",
      "\n",
      "    accuracy                           0.60       208\n",
      "   macro avg       0.65      0.56      0.51       208\n",
      "weighted avg       0.64      0.60      0.53       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5817307692307693 and f1 score is: 0.5153073523503415\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.23      0.34        95\n",
      "           1       0.58      0.88      0.69       113\n",
      "\n",
      "    accuracy                           0.58       208\n",
      "   macro avg       0.59      0.55      0.52       208\n",
      "weighted avg       0.59      0.58      0.53       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.891156462585034 and f1 score is: 0.7030303030303031\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.44      0.47        16\n",
      "           1       0.93      0.95      0.94       131\n",
      "\n",
      "    accuracy                           0.89       147\n",
      "   macro avg       0.72      0.69      0.70       147\n",
      "weighted avg       0.89      0.89      0.89       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.9455782312925171 and f1 score is: 0.8421052631578948\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.62      0.71        16\n",
      "           1       0.96      0.98      0.97       131\n",
      "\n",
      "    accuracy                           0.95       147\n",
      "   macro avg       0.89      0.80      0.84       147\n",
      "weighted avg       0.94      0.95      0.94       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.9115646258503401 and f1 score is: 0.7513337670787248\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.55        16\n",
      "           1       0.94      0.96      0.95       131\n",
      "\n",
      "    accuracy                           0.91       147\n",
      "   macro avg       0.78      0.73      0.75       147\n",
      "weighted avg       0.90      0.91      0.91       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.7891156462585034 and f1 score is: 0.6322924231420963\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.62      0.39        16\n",
      "           1       0.95      0.81      0.87       131\n",
      "\n",
      "    accuracy                           0.79       147\n",
      "   macro avg       0.62      0.72      0.63       147\n",
      "weighted avg       0.87      0.79      0.82       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.9387755102040817 and f1 score is: 0.8164794007490637\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.56      0.67        16\n",
      "           1       0.95      0.98      0.97       131\n",
      "\n",
      "    accuracy                           0.94       147\n",
      "   macro avg       0.88      0.77      0.82       147\n",
      "weighted avg       0.93      0.94      0.93       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8503401360544217 and f1 score is: 0.6944444444444445\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.62      0.48        16\n",
      "           1       0.95      0.88      0.91       131\n",
      "\n",
      "    accuracy                           0.85       147\n",
      "   macro avg       0.67      0.75      0.69       147\n",
      "weighted avg       0.89      0.85      0.87       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1106.csv ---\n",
      "[17:44:56] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8979591836734694 and f1 score is: 0.7439916405433646\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.56      0.55        16\n",
      "           1       0.95      0.94      0.94       131\n",
      "\n",
      "    accuracy                           0.90       147\n",
      "   macro avg       0.74      0.75      0.74       147\n",
      "weighted avg       0.90      0.90      0.90       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8027210884353742 and f1 score is: 0.6560154926167998\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.69      0.43        16\n",
      "           1       0.96      0.82      0.88       131\n",
      "\n",
      "    accuracy                           0.80       147\n",
      "   macro avg       0.63      0.75      0.66       147\n",
      "weighted avg       0.89      0.80      0.83       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.6101694915254238 and f1 score is: 0.5632755229751475\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.30      0.42        84\n",
      "           1       0.58      0.89      0.71        93\n",
      "\n",
      "    accuracy                           0.61       177\n",
      "   macro avg       0.65      0.60      0.56       177\n",
      "weighted avg       0.65      0.61      0.57       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.6497175141242938 and f1 score is: 0.6091880341880342\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.35      0.48        84\n",
      "           1       0.61      0.92      0.74        93\n",
      "\n",
      "    accuracy                           0.65       177\n",
      "   macro avg       0.71      0.63      0.61       177\n",
      "weighted avg       0.70      0.65      0.62       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.559322033898305 and f1 score is: 0.48561847988077494\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.19      0.29        84\n",
      "           1       0.55      0.89      0.68        93\n",
      "\n",
      "    accuracy                           0.56       177\n",
      "   macro avg       0.58      0.54      0.49       177\n",
      "weighted avg       0.58      0.56      0.50       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.6271186440677966 and f1 score is: 0.6256729043834913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.73      0.65        84\n",
      "           1       0.68      0.54      0.60        93\n",
      "\n",
      "    accuracy                           0.63       177\n",
      "   macro avg       0.64      0.63      0.63       177\n",
      "weighted avg       0.64      0.63      0.62       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.6440677966101694 and f1 score is: 0.5978578383641675\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.32      0.46        84\n",
      "           1       0.60      0.94      0.73        93\n",
      "\n",
      "    accuracy                           0.64       177\n",
      "   macro avg       0.71      0.63      0.60       177\n",
      "weighted avg       0.71      0.64      0.60       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.615819209039548 and f1 score is: 0.5600877192982456\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.27      0.40        84\n",
      "           1       0.59      0.92      0.72        93\n",
      "\n",
      "    accuracy                           0.62       177\n",
      "   macro avg       0.68      0.60      0.56       177\n",
      "weighted avg       0.67      0.62      0.57       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1175.csv ---\n",
      "[17:46:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5875706214689266 and f1 score is: 0.5822367357496201\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.50      0.54        84\n",
      "           1       0.60      0.67      0.63        93\n",
      "\n",
      "    accuracy                           0.59       177\n",
      "   macro avg       0.59      0.58      0.58       177\n",
      "weighted avg       0.59      0.59      0.58       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.6045197740112994 and f1 score is: 0.6008376288659794\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.54      0.56        84\n",
      "           1       0.61      0.67      0.64        93\n",
      "\n",
      "    accuracy                           0.60       177\n",
      "   macro avg       0.60      0.60      0.60       177\n",
      "weighted avg       0.60      0.60      0.60       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5601851851851852 and f1 score is: 0.4922677223803043\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.19      0.31       113\n",
      "           1       0.52      0.97      0.68       103\n",
      "\n",
      "    accuracy                           0.56       216\n",
      "   macro avg       0.70      0.58      0.49       216\n",
      "weighted avg       0.71      0.56      0.48       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5 and f1 score is: 0.38919145370758274\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.07      0.13       113\n",
      "           1       0.49      0.97      0.65       103\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.61      0.52      0.39       216\n",
      "weighted avg       0.61      0.50      0.38       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5462962962962963 and f1 score is: 0.460825267447784\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.14      0.25       113\n",
      "           1       0.51      0.99      0.68       103\n",
      "\n",
      "    accuracy                           0.55       216\n",
      "   macro avg       0.73      0.57      0.46       216\n",
      "weighted avg       0.74      0.55      0.45       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.49074074074074076 and f1 score is: 0.40498848041670843\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.11      0.18       113\n",
      "           1       0.48      0.91      0.63       103\n",
      "\n",
      "    accuracy                           0.49       216\n",
      "   macro avg       0.53      0.51      0.40       216\n",
      "weighted avg       0.53      0.49      0.39       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5092592592592593 and f1 score is: 0.39460602855631943\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.07      0.13       113\n",
      "           1       0.49      0.99      0.66       103\n",
      "\n",
      "    accuracy                           0.51       216\n",
      "   macro avg       0.69      0.53      0.39       216\n",
      "weighted avg       0.70      0.51      0.38       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5416666666666666 and f1 score is: 0.4960288468336829\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.23      0.34       113\n",
      "           1       0.51      0.88      0.65       103\n",
      "\n",
      "    accuracy                           0.54       216\n",
      "   macro avg       0.60      0.56      0.50       216\n",
      "weighted avg       0.60      0.54      0.49       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1337.csv ---\n",
      "[17:47:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5787037037037037 and f1 score is: 0.5577654284878619\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.35      0.46       113\n",
      "           1       0.54      0.83      0.65       103\n",
      "\n",
      "    accuracy                           0.58       216\n",
      "   macro avg       0.62      0.59      0.56       216\n",
      "weighted avg       0.62      0.58      0.55       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5462962962962963 and f1 score is: 0.5443822643133878\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.46      0.51       113\n",
      "           1       0.52      0.64      0.57       103\n",
      "\n",
      "    accuracy                           0.55       216\n",
      "   macro avg       0.55      0.55      0.54       216\n",
      "weighted avg       0.55      0.55      0.54       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.6056338028169014 and f1 score is: 0.5835970955129399\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.42      0.49        95\n",
      "           1       0.62      0.75      0.68       118\n",
      "\n",
      "    accuracy                           0.61       213\n",
      "   macro avg       0.60      0.59      0.58       213\n",
      "weighted avg       0.60      0.61      0.59       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.4788732394366197 and f1 score is: 0.3828987549917783\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.98      0.63        95\n",
      "           1       0.82      0.08      0.14       118\n",
      "\n",
      "    accuracy                           0.48       213\n",
      "   macro avg       0.64      0.53      0.38       213\n",
      "weighted avg       0.66      0.48      0.36       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5446009389671361 and f1 score is: 0.5279535744476684\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.82      0.62        95\n",
      "           1       0.69      0.32      0.44       118\n",
      "\n",
      "    accuracy                           0.54       213\n",
      "   macro avg       0.59      0.57      0.53       213\n",
      "weighted avg       0.60      0.54      0.52       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5868544600938967 and f1 score is: 0.5472463768115942\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.33      0.41        95\n",
      "           1       0.59      0.80      0.68       118\n",
      "\n",
      "    accuracy                           0.59       213\n",
      "   macro avg       0.58      0.56      0.55       213\n",
      "weighted avg       0.58      0.59      0.56       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.47417840375586856 and f1 score is: 0.3745805369127517\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.98      0.62        95\n",
      "           1       0.80      0.07      0.12       118\n",
      "\n",
      "    accuracy                           0.47       213\n",
      "   macro avg       0.63      0.52      0.37       213\n",
      "weighted avg       0.65      0.47      0.35       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5164319248826291 and f1 score is: 0.5066450785940767\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.74      0.58        95\n",
      "           1       0.62      0.34      0.44       118\n",
      "\n",
      "    accuracy                           0.52       213\n",
      "   macro avg       0.54      0.54      0.51       213\n",
      "weighted avg       0.55      0.52      0.50       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1390.csv ---\n",
      "[17:48:27] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5023474178403756 and f1 score is: 0.49986709197235507\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.64      0.54        95\n",
      "           1       0.57      0.39      0.46       118\n",
      "\n",
      "    accuracy                           0.50       213\n",
      "   macro avg       0.52      0.52      0.50       213\n",
      "weighted avg       0.52      0.50      0.50       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.6009389671361502 and f1 score is: 0.6009037804474815\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.66      0.60        95\n",
      "           1       0.67      0.55      0.60       118\n",
      "\n",
      "    accuracy                           0.60       213\n",
      "   macro avg       0.61      0.61      0.60       213\n",
      "weighted avg       0.61      0.60      0.60       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.46190476190476193 and f1 score is: 0.4615995462280204\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.38      0.47       136\n",
      "           1       0.35      0.62      0.45        74\n",
      "\n",
      "    accuracy                           0.46       210\n",
      "   macro avg       0.50      0.50      0.46       210\n",
      "weighted avg       0.54      0.46      0.47       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.4523809523809524 and f1 score is: 0.43851572853456094\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.23      0.35       136\n",
      "           1       0.38      0.86      0.53        74\n",
      "\n",
      "    accuracy                           0.45       210\n",
      "   macro avg       0.57      0.55      0.44       210\n",
      "weighted avg       0.62      0.45      0.41       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.49047619047619045 and f1 score is: 0.48711510807788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.32      0.45       136\n",
      "           1       0.39      0.81      0.53        74\n",
      "\n",
      "    accuracy                           0.49       210\n",
      "   macro avg       0.57      0.56      0.49       210\n",
      "weighted avg       0.63      0.49      0.47       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5857142857142857 and f1 score is: 0.4544803081424861\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.83      0.72       136\n",
      "           1       0.30      0.14      0.19        74\n",
      "\n",
      "    accuracy                           0.59       210\n",
      "   macro avg       0.47      0.48      0.45       210\n",
      "weighted avg       0.52      0.59      0.53       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.4238095238095238 and f1 score is: 0.3985941161155949\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.17      0.28       136\n",
      "           1       0.37      0.89      0.52        74\n",
      "\n",
      "    accuracy                           0.42       210\n",
      "   macro avg       0.56      0.53      0.40       210\n",
      "weighted avg       0.61      0.42      0.36       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5095238095238095 and f1 score is: 0.508621277175765\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.43      0.53       136\n",
      "           1       0.39      0.66      0.49        74\n",
      "\n",
      "    accuracy                           0.51       210\n",
      "   macro avg       0.54      0.54      0.51       210\n",
      "weighted avg       0.59      0.51      0.51       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1400.csv ---\n",
      "[17:49:37] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.49523809523809526 and f1 score is: 0.49450449632119176\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.41      0.51       136\n",
      "           1       0.38      0.65      0.48        74\n",
      "\n",
      "    accuracy                           0.50       210\n",
      "   macro avg       0.53      0.53      0.49       210\n",
      "weighted avg       0.57      0.50      0.50       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.5238095238095238 and f1 score is: 0.5202850877192982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.47      0.56       136\n",
      "           1       0.39      0.62      0.48        74\n",
      "\n",
      "    accuracy                           0.52       210\n",
      "   macro avg       0.54      0.55      0.52       210\n",
      "weighted avg       0.59      0.52      0.53       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.602803738317757 and f1 score is: 0.5768488147579501\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.40      0.47        95\n",
      "           1       0.61      0.76      0.68       119\n",
      "\n",
      "    accuracy                           0.60       214\n",
      "   macro avg       0.60      0.58      0.58       214\n",
      "weighted avg       0.60      0.60      0.59       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5747663551401869 and f1 score is: 0.503657448706512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.22      0.32        95\n",
      "           1       0.58      0.86      0.69       119\n",
      "\n",
      "    accuracy                           0.57       214\n",
      "   macro avg       0.57      0.54      0.50       214\n",
      "weighted avg       0.57      0.57      0.52       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5794392523364486 and f1 score is: 0.5698204234789601\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.48      0.51        95\n",
      "           1       0.61      0.66      0.63       119\n",
      "\n",
      "    accuracy                           0.58       214\n",
      "   macro avg       0.57      0.57      0.57       214\n",
      "weighted avg       0.58      0.58      0.58       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5794392523364486 and f1 score is: 0.5625908430232558\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.43      0.48        95\n",
      "           1       0.61      0.70      0.65       119\n",
      "\n",
      "    accuracy                           0.58       214\n",
      "   macro avg       0.57      0.56      0.56       214\n",
      "weighted avg       0.57      0.58      0.57       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5887850467289719 and f1 score is: 0.5138874548270521\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.22      0.32        95\n",
      "           1       0.59      0.88      0.70       119\n",
      "\n",
      "    accuracy                           0.59       214\n",
      "   macro avg       0.59      0.55      0.51       214\n",
      "weighted avg       0.59      0.59      0.54       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5841121495327103 and f1 score is: 0.579251993726114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.53        95\n",
      "           1       0.63      0.62      0.62       119\n",
      "\n",
      "    accuracy                           0.58       214\n",
      "   macro avg       0.58      0.58      0.58       214\n",
      "weighted avg       0.58      0.58      0.58       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1419.csv ---\n",
      "[17:50:47] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5373831775700935 and f1 score is: 0.4964705882352941\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.28      0.35        95\n",
      "           1       0.56      0.74      0.64       119\n",
      "\n",
      "    accuracy                           0.54       214\n",
      "   macro avg       0.51      0.51      0.50       214\n",
      "weighted avg       0.52      0.54      0.51       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5186915887850467 and f1 score is: 0.4790972468391823\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.27      0.34        95\n",
      "           1       0.55      0.71      0.62       119\n",
      "\n",
      "    accuracy                           0.52       214\n",
      "   macro avg       0.49      0.49      0.48       214\n",
      "weighted avg       0.50      0.52      0.50       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.691358024691358 and f1 score is: 0.5013543462201429\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81       122\n",
      "           1       0.27      0.15      0.19        40\n",
      "\n",
      "    accuracy                           0.69       162\n",
      "   macro avg       0.51      0.51      0.50       162\n",
      "weighted avg       0.64      0.69      0.66       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.6790123456790124 and f1 score is: 0.49375\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80       122\n",
      "           1       0.25      0.15      0.19        40\n",
      "\n",
      "    accuracy                           0.68       162\n",
      "   macro avg       0.50      0.50      0.49       162\n",
      "weighted avg       0.63      0.68      0.65       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.7530864197530864 and f1 score is: 0.452887537993921\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86       122\n",
      "           1       0.50      0.03      0.05        40\n",
      "\n",
      "    accuracy                           0.75       162\n",
      "   macro avg       0.63      0.51      0.45       162\n",
      "weighted avg       0.69      0.75      0.66       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.6111111111111112 and f1 score is: 0.5753692531724568\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.60      0.70       122\n",
      "           1       0.35      0.65      0.45        40\n",
      "\n",
      "    accuracy                           0.61       162\n",
      "   macro avg       0.59      0.62      0.58       162\n",
      "weighted avg       0.72      0.61      0.64       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.6604938271604939 and f1 score is: 0.5137259182448289\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       122\n",
      "           1       0.27      0.23      0.25        40\n",
      "\n",
      "    accuracy                           0.66       162\n",
      "   macro avg       0.52      0.51      0.51       162\n",
      "weighted avg       0.64      0.66      0.65       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.6296296296296297 and f1 score is: 0.5660714285714286\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73       122\n",
      "           1       0.33      0.50      0.40        40\n",
      "\n",
      "    accuracy                           0.63       162\n",
      "   macro avg       0.57      0.59      0.57       162\n",
      "weighted avg       0.69      0.63      0.65       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1517.csv ---\n",
      "[17:51:58] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.7716049382716049 and f1 score is: 0.5225806451612903\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87       122\n",
      "           1       0.80      0.10      0.18        40\n",
      "\n",
      "    accuracy                           0.77       162\n",
      "   macro avg       0.79      0.55      0.52       162\n",
      "weighted avg       0.78      0.77      0.70       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.7345679012345679 and f1 score is: 0.5291652585332882\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84       122\n",
      "           1       0.40      0.15      0.22        40\n",
      "\n",
      "    accuracy                           0.73       162\n",
      "   macro avg       0.58      0.54      0.53       162\n",
      "weighted avg       0.68      0.73      0.69       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.8043478260869565 and f1 score is: 0.5353535353535354\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18        10\n",
      "           1       0.80      1.00      0.89        36\n",
      "\n",
      "    accuracy                           0.80        46\n",
      "   macro avg       0.90      0.55      0.54        46\n",
      "weighted avg       0.84      0.80      0.74        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.5208333333333334\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.10      0.17        10\n",
      "           1       0.80      0.97      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.65      0.54      0.52        46\n",
      "weighted avg       0.73      0.78      0.72        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6739130434782609 and f1 score is: 0.6068376068376068\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.60      0.44        10\n",
      "           1       0.86      0.69      0.77        36\n",
      "\n",
      "    accuracy                           0.67        46\n",
      "   macro avg       0.61      0.65      0.61        46\n",
      "weighted avg       0.75      0.67      0.70        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.5208333333333334\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.10      0.17        10\n",
      "           1       0.80      0.97      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.65      0.54      0.52        46\n",
      "weighted avg       0.73      0.78      0.72        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1544.csv ---\n",
      "[17:53:11] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.717391304347826 and f1 score is: 0.6726874657909141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.80      0.55        10\n",
      "           1       0.93      0.69      0.79        36\n",
      "\n",
      "    accuracy                           0.72        46\n",
      "   macro avg       0.67      0.75      0.67        46\n",
      "weighted avg       0.82      0.72      0.74        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.7181372549019608\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.70      0.58        10\n",
      "           1       0.91      0.81      0.85        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.70      0.75      0.72        46\n",
      "weighted avg       0.82      0.78      0.79        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5660377358490566 and f1 score is: 0.48822129962214866\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.19      0.29        73\n",
      "           1       0.56      0.88      0.69        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.57      0.54      0.49       159\n",
      "weighted avg       0.57      0.57      0.50       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.49056603773584906 and f1 score is: 0.39921630825208754\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.96      0.63        73\n",
      "           1       0.73      0.09      0.16        86\n",
      "\n",
      "    accuracy                           0.49       159\n",
      "   macro avg       0.60      0.53      0.40       159\n",
      "weighted avg       0.61      0.49      0.38       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5220125786163522 and f1 score is: 0.5204761904761904\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.63      0.55        73\n",
      "           1       0.58      0.43      0.49        86\n",
      "\n",
      "    accuracy                           0.52       159\n",
      "   macro avg       0.53      0.53      0.52       159\n",
      "weighted avg       0.54      0.52      0.52       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5534591194968553 and f1 score is: 0.5411908148750254\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.42      0.47        73\n",
      "           1       0.58      0.66      0.62        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.55      0.54      0.54       159\n",
      "weighted avg       0.55      0.55      0.55       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.46540880503144655 and f1 score is: 0.4210751766973656\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.81      0.58        73\n",
      "           1       0.52      0.17      0.26        86\n",
      "\n",
      "    accuracy                           0.47       159\n",
      "   macro avg       0.49      0.49      0.42       159\n",
      "weighted avg       0.49      0.47      0.41       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5408805031446541 and f1 score is: 0.4304989941612286\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.11      0.18        73\n",
      "           1       0.55      0.91      0.68        86\n",
      "\n",
      "    accuracy                           0.54       159\n",
      "   macro avg       0.52      0.51      0.43       159\n",
      "weighted avg       0.52      0.54      0.45       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1624.csv ---\n",
      "[17:54:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5471698113207547 and f1 score is: 0.541933418693982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.71      0.59        73\n",
      "           1       0.62      0.41      0.49        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.56      0.56      0.54       159\n",
      "weighted avg       0.57      0.55      0.54       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5220125786163522 and f1 score is: 0.5135265700483091\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.71      0.58        73\n",
      "           1       0.60      0.36      0.45        86\n",
      "\n",
      "    accuracy                           0.52       159\n",
      "   macro avg       0.54      0.54      0.51       159\n",
      "weighted avg       0.55      0.52      0.51       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6740331491712708 and f1 score is: 0.41838679810467844\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.03        60\n",
      "           1       0.67      1.00      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.84      0.51      0.42       181\n",
      "weighted avg       0.78      0.67      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.3370165745856354 and f1 score is: 0.2581967213114754\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50        60\n",
      "           1       1.00      0.01      0.02       121\n",
      "\n",
      "    accuracy                           0.34       181\n",
      "   macro avg       0.67      0.50      0.26       181\n",
      "weighted avg       0.78      0.34      0.18       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6464088397790055 and f1 score is: 0.5682766845557543\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.33      0.38        60\n",
      "           1       0.71      0.80      0.75       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.58      0.57      0.57       181\n",
      "weighted avg       0.62      0.65      0.63       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6740331491712708 and f1 score is: 0.4330838243881722\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.03      0.06        60\n",
      "           1       0.67      0.99      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.67      0.51      0.43       181\n",
      "weighted avg       0.67      0.67      0.56       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.3370165745856354 and f1 score is: 0.2581967213114754\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50        60\n",
      "           1       1.00      0.01      0.02       121\n",
      "\n",
      "    accuracy                           0.34       181\n",
      "   macro avg       0.67      0.50      0.26       181\n",
      "weighted avg       0.78      0.34      0.18       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.4419889502762431 and f1 score is: 0.4336214642005143\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.85      0.50        60\n",
      "           1       0.76      0.24      0.36       121\n",
      "\n",
      "    accuracy                           0.44       181\n",
      "   macro avg       0.56      0.54      0.43       181\n",
      "weighted avg       0.63      0.44      0.41       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1688.csv ---\n",
      "[17:55:34] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6906077348066298 and f1 score is: 0.6030701754385965\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.33      0.42        60\n",
      "           1       0.72      0.87      0.79       121\n",
      "\n",
      "    accuracy                           0.69       181\n",
      "   macro avg       0.64      0.60      0.60       181\n",
      "weighted avg       0.67      0.69      0.67       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5469613259668509 and f1 score is: 0.531384187926244\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.55      0.45        60\n",
      "           1       0.71      0.55      0.62       121\n",
      "\n",
      "    accuracy                           0.55       181\n",
      "   macro avg       0.54      0.55      0.53       181\n",
      "weighted avg       0.60      0.55      0.56       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6944444444444444 and f1 score is: 0.6486246672582077\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.53      0.52        34\n",
      "           1       0.78      0.77      0.78        74\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.65      0.65      0.65       108\n",
      "weighted avg       0.70      0.69      0.70       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5092592592592593 and f1 score is: 0.5058275058275059\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.68      0.46        34\n",
      "           1       0.74      0.43      0.55        74\n",
      "\n",
      "    accuracy                           0.51       108\n",
      "   macro avg       0.55      0.55      0.51       108\n",
      "weighted avg       0.62      0.51      0.52       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.7222222222222222 and f1 score is: 0.6606619187264349\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.47      0.52        34\n",
      "           1       0.78      0.84      0.81        74\n",
      "\n",
      "    accuracy                           0.72       108\n",
      "   macro avg       0.67      0.65      0.66       108\n",
      "weighted avg       0.71      0.72      0.71       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6018518518518519 and f1 score is: 0.5959982601130926\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.76      0.55        34\n",
      "           1       0.83      0.53      0.64        74\n",
      "\n",
      "    accuracy                           0.60       108\n",
      "   macro avg       0.63      0.65      0.60       108\n",
      "weighted avg       0.70      0.60      0.61       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5370370370370371 and f1 score is: 0.516994633273703\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.53      0.42        34\n",
      "           1       0.71      0.54      0.62        74\n",
      "\n",
      "    accuracy                           0.54       108\n",
      "   macro avg       0.53      0.53      0.52       108\n",
      "weighted avg       0.60      0.54      0.55       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.4722222222222222 and f1 score is: 0.4710885814932555\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.82      0.50        34\n",
      "           1       0.79      0.31      0.45        74\n",
      "\n",
      "    accuracy                           0.47       108\n",
      "   macro avg       0.57      0.57      0.47       108\n",
      "weighted avg       0.66      0.47      0.46       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1717.csv ---\n",
      "[17:56:46] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6203703703703703 and f1 score is: 0.556445958128819\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.38      0.39        34\n",
      "           1       0.72      0.73      0.72        74\n",
      "\n",
      "    accuracy                           0.62       108\n",
      "   macro avg       0.56      0.56      0.56       108\n",
      "weighted avg       0.62      0.62      0.62       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.7037037037037037 and f1 score is: 0.661839530332681\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.56      0.54        34\n",
      "           1       0.79      0.77      0.78        74\n",
      "\n",
      "    accuracy                           0.70       108\n",
      "   macro avg       0.66      0.66      0.66       108\n",
      "weighted avg       0.71      0.70      0.71       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5185185185185185 and f1 score is: 0.4358928571428572\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.13      0.22        86\n",
      "           1       0.49      0.96      0.65        76\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.64      0.54      0.44       162\n",
      "weighted avg       0.65      0.52      0.42       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5185185185185185 and f1 score is: 0.4155411655874191\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.17        86\n",
      "           1       0.49      1.00      0.66        76\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.75      0.55      0.42       162\n",
      "weighted avg       0.76      0.52      0.40       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.49382716049382713 and f1 score is: 0.4069642857142857\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.10      0.18        86\n",
      "           1       0.48      0.93      0.63        76\n",
      "\n",
      "    accuracy                           0.49       162\n",
      "   macro avg       0.56      0.52      0.41       162\n",
      "weighted avg       0.57      0.49      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4691358024691358 and f1 score is: 0.4268553562613132\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.19      0.27        86\n",
      "           1       0.46      0.79      0.58        76\n",
      "\n",
      "    accuracy                           0.47       162\n",
      "   macro avg       0.48      0.49      0.43       162\n",
      "weighted avg       0.48      0.47      0.42       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5123456790123457 and f1 score is: 0.4042731462086301\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.15        86\n",
      "           1       0.49      1.00      0.66        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.75      0.54      0.40       162\n",
      "weighted avg       0.76      0.51      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5123456790123457 and f1 score is: 0.4377718226947239\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.14      0.23        86\n",
      "           1       0.49      0.93      0.64        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.60      0.54      0.44       162\n",
      "weighted avg       0.60      0.51      0.43       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1765.csv ---\n",
      "[17:57:58] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4691358024691358 and f1 score is: 0.37095900307025464\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.07      0.12        86\n",
      "           1       0.47      0.92      0.62        76\n",
      "\n",
      "    accuracy                           0.47       162\n",
      "   macro avg       0.48      0.50      0.37       162\n",
      "weighted avg       0.48      0.47      0.36       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.48148148148148145 and f1 score is: 0.3782894736842105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.07      0.12        86\n",
      "           1       0.47      0.95      0.63        76\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.54      0.51      0.38       162\n",
      "weighted avg       0.54      0.48      0.36       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8160377358490566 and f1 score is: 0.5333822450476889\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.25      0.17        16\n",
      "           1       0.93      0.86      0.90       196\n",
      "\n",
      "    accuracy                           0.82       212\n",
      "   macro avg       0.53      0.56      0.53       212\n",
      "weighted avg       0.87      0.82      0.84       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6745283018867925 and f1 score is: 0.41635079599409486\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.06      0.03        16\n",
      "           1       0.90      0.72      0.80       196\n",
      "\n",
      "    accuracy                           0.67       212\n",
      "   macro avg       0.46      0.39      0.42       212\n",
      "weighted avg       0.84      0.67      0.75       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7264150943396226 and f1 score is: 0.49206873760740255\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.31      0.15        16\n",
      "           1       0.93      0.76      0.84       196\n",
      "\n",
      "    accuracy                           0.73       212\n",
      "   macro avg       0.51      0.54      0.49       212\n",
      "weighted avg       0.87      0.73      0.79       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6179245283018868 and f1 score is: 0.4421596335639802\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.38      0.13        16\n",
      "           1       0.93      0.64      0.76       196\n",
      "\n",
      "    accuracy                           0.62       212\n",
      "   macro avg       0.50      0.51      0.44       212\n",
      "weighted avg       0.86      0.62      0.71       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6509433962264151 and f1 score is: 0.4299418604651163\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.19      0.07        16\n",
      "           1       0.91      0.69      0.78       196\n",
      "\n",
      "    accuracy                           0.65       212\n",
      "   macro avg       0.48      0.44      0.43       212\n",
      "weighted avg       0.85      0.65      0.73       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.75 and f1 score is: 0.5184915363188344\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.38      0.18        16\n",
      "           1       0.94      0.78      0.85       196\n",
      "\n",
      "    accuracy                           0.75       212\n",
      "   macro avg       0.53      0.58      0.52       212\n",
      "weighted avg       0.88      0.75      0.80       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1818.csv ---\n",
      "[17:59:08] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7924528301886793 and f1 score is: 0.547360248447205\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.38      0.21        16\n",
      "           1       0.94      0.83      0.88       196\n",
      "\n",
      "    accuracy                           0.79       212\n",
      "   macro avg       0.55      0.60      0.55       212\n",
      "weighted avg       0.88      0.79      0.83       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7075471698113207 and f1 score is: 0.48137626262626265\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.31      0.14        16\n",
      "           1       0.93      0.74      0.82       196\n",
      "\n",
      "    accuracy                           0.71       212\n",
      "   macro avg       0.51      0.53      0.48       212\n",
      "weighted avg       0.87      0.71      0.77       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4583333333333333 and f1 score is: 0.4453881098163144\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.41      0.53       162\n",
      "           1       0.26      0.61      0.36        54\n",
      "\n",
      "    accuracy                           0.46       216\n",
      "   macro avg       0.51      0.51      0.45       216\n",
      "weighted avg       0.63      0.46      0.49       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5 and f1 score is: 0.4293542074363992\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.57      0.63       162\n",
      "           1       0.19      0.30      0.23        54\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.45      0.43      0.43       216\n",
      "weighted avg       0.58      0.50      0.53       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4583333333333333 and f1 score is: 0.4483902651969879\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.40      0.52       162\n",
      "           1       0.26      0.65      0.37        54\n",
      "\n",
      "    accuracy                           0.46       216\n",
      "   macro avg       0.52      0.52      0.45       216\n",
      "weighted avg       0.64      0.46      0.49       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.30092592592592593 and f1 score is: 0.2997101449275362\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.17      0.27       162\n",
      "           1       0.22      0.69      0.33        54\n",
      "\n",
      "    accuracy                           0.30       216\n",
      "   macro avg       0.42      0.43      0.30       216\n",
      "weighted avg       0.52      0.30      0.29       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.49537037037037035 and f1 score is: 0.4416486826191097\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.54      0.61       162\n",
      "           1       0.21      0.37      0.27        54\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.46      0.45      0.44       216\n",
      "weighted avg       0.59      0.50      0.53       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4027777777777778 and f1 score is: 0.40122488449554106\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.30      0.43       162\n",
      "           1       0.25      0.70      0.37        54\n",
      "\n",
      "    accuracy                           0.40       216\n",
      "   macro avg       0.50      0.50      0.40       216\n",
      "weighted avg       0.63      0.40      0.42       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1892.csv ---\n",
      "[18:00:18] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4305555555555556 and f1 score is: 0.4251217137293086\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.35      0.48       162\n",
      "           1       0.26      0.67      0.37        54\n",
      "\n",
      "    accuracy                           0.43       216\n",
      "   macro avg       0.51      0.51      0.43       216\n",
      "weighted avg       0.63      0.43      0.45       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5601851851851852 and f1 score is: 0.5133635307230773\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.58      0.66       162\n",
      "           1       0.28      0.50      0.36        54\n",
      "\n",
      "    accuracy                           0.56       216\n",
      "   macro avg       0.53      0.54      0.51       216\n",
      "weighted avg       0.65      0.56      0.59       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5754716981132075 and f1 score is: 0.4715852442671984\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.22      0.24        65\n",
      "           1       0.68      0.73      0.71       147\n",
      "\n",
      "    accuracy                           0.58       212\n",
      "   macro avg       0.47      0.48      0.47       212\n",
      "weighted avg       0.55      0.58      0.56       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.4481132075471698 and f1 score is: 0.4287819818989936\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.43      0.32        65\n",
      "           1       0.64      0.46      0.53       147\n",
      "\n",
      "    accuracy                           0.45       212\n",
      "   macro avg       0.45      0.44      0.43       212\n",
      "weighted avg       0.53      0.45      0.47       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.4716981132075472 and f1 score is: 0.45416091954022997\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.48      0.36        65\n",
      "           1       0.67      0.47      0.55       147\n",
      "\n",
      "    accuracy                           0.47       212\n",
      "   macro avg       0.48      0.47      0.45       212\n",
      "weighted avg       0.55      0.47      0.49       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5518867924528302 and f1 score is: 0.4752885391970404\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.28      0.27        65\n",
      "           1       0.68      0.67      0.68       147\n",
      "\n",
      "    accuracy                           0.55       212\n",
      "   macro avg       0.48      0.48      0.48       212\n",
      "weighted avg       0.55      0.55      0.55       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.44339622641509435 and f1 score is: 0.4133208255159475\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.35      0.28        65\n",
      "           1       0.63      0.48      0.55       147\n",
      "\n",
      "    accuracy                           0.44       212\n",
      "   macro avg       0.43      0.42      0.41       212\n",
      "weighted avg       0.51      0.44      0.46       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.42452830188679247 and f1 score is: 0.42200768749441314\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.58      0.38        65\n",
      "           1       0.66      0.35      0.46       147\n",
      "\n",
      "    accuracy                           0.42       212\n",
      "   macro avg       0.47      0.47      0.42       212\n",
      "weighted avg       0.54      0.42      0.44       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1929.csv ---\n",
      "[18:01:28] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5188679245283019 and f1 score is: 0.4599940065927479\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.31      0.28        65\n",
      "           1       0.67      0.61      0.64       147\n",
      "\n",
      "    accuracy                           0.52       212\n",
      "   macro avg       0.46      0.46      0.46       212\n",
      "weighted avg       0.54      0.52      0.53       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5424528301886793 and f1 score is: 0.46867167919799496\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.28      0.27        65\n",
      "           1       0.67      0.66      0.67       147\n",
      "\n",
      "    accuracy                           0.54       212\n",
      "   macro avg       0.47      0.47      0.47       212\n",
      "weighted avg       0.55      0.54      0.55       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6020408163265306 and f1 score is: 0.4542338997572469\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.11      0.17        36\n",
      "           1       0.63      0.89      0.74        62\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.50      0.50      0.45        98\n",
      "weighted avg       0.53      0.60      0.53        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6020408163265306 and f1 score is: 0.5828877005347594\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.53      0.49        36\n",
      "           1       0.70      0.65      0.67        62\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.58      0.59      0.58        98\n",
      "weighted avg       0.61      0.60      0.61        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.45918367346938777 and f1 score is: 0.4494965553789083\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.81      0.52        36\n",
      "           1       0.70      0.26      0.38        62\n",
      "\n",
      "    accuracy                           0.46        98\n",
      "   macro avg       0.54      0.53      0.45        98\n",
      "weighted avg       0.58      0.46      0.43        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5816326530612245 and f1 score is: 0.4928688628044932\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.22      0.28        36\n",
      "           1       0.64      0.79      0.71        62\n",
      "\n",
      "    accuracy                           0.58        98\n",
      "   macro avg       0.51      0.51      0.49        98\n",
      "weighted avg       0.54      0.58      0.55        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5612244897959183 and f1 score is: 0.5533651298357181\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.58      0.49        36\n",
      "           1       0.69      0.55      0.61        62\n",
      "\n",
      "    accuracy                           0.56        98\n",
      "   macro avg       0.56      0.57      0.55        98\n",
      "weighted avg       0.60      0.56      0.57        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6632653061224489 and f1 score is: 0.6501135994806881\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.64      0.58        36\n",
      "           1       0.76      0.68      0.72        62\n",
      "\n",
      "    accuracy                           0.66        98\n",
      "   macro avg       0.65      0.66      0.65        98\n",
      "weighted avg       0.68      0.66      0.67        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1933.csv ---\n",
      "[18:02:40] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6224489795918368 and f1 score is: 0.6077031266904684\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.58      0.53        36\n",
      "           1       0.73      0.65      0.68        62\n",
      "\n",
      "    accuracy                           0.62        98\n",
      "   macro avg       0.61      0.61      0.61        98\n",
      "weighted avg       0.64      0.62      0.63        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5204081632653061 and f1 score is: 0.4870252812117162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.36      0.36        36\n",
      "           1       0.62      0.61      0.62        62\n",
      "\n",
      "    accuracy                           0.52        98\n",
      "   macro avg       0.49      0.49      0.49        98\n",
      "weighted avg       0.52      0.52      0.52        98\n",
      "\n",
      "----- Running Modality Combination ECG_EEG_GAZE\n",
      "Saved Directory: 2022_08_11_18_03\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5576923076923077 and f1 score is: 0.4025227925565131\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.05      0.10        95\n",
      "           1       0.55      0.98      0.71       113\n",
      "\n",
      "    accuracy                           0.56       208\n",
      "   macro avg       0.63      0.52      0.40       208\n",
      "weighted avg       0.63      0.56      0.43       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.4855769230769231 and f1 score is: 0.449857866765542\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.25      0.31        95\n",
      "           1       0.52      0.68      0.59       113\n",
      "\n",
      "    accuracy                           0.49       208\n",
      "   macro avg       0.46      0.47      0.45       208\n",
      "weighted avg       0.47      0.49      0.46       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5384615384615384 and f1 score is: 0.5373922713372254\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.54      0.52        95\n",
      "           1       0.58      0.54      0.56       113\n",
      "\n",
      "    accuracy                           0.54       208\n",
      "   macro avg       0.54      0.54      0.54       208\n",
      "weighted avg       0.54      0.54      0.54       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5336538461538461 and f1 score is: 0.4897706294413676\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.26      0.34        95\n",
      "           1       0.55      0.76      0.64       113\n",
      "\n",
      "    accuracy                           0.53       208\n",
      "   macro avg       0.52      0.51      0.49       208\n",
      "weighted avg       0.52      0.53      0.50       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.49038461538461536 and f1 score is: 0.46872289156626507\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.32      0.36        95\n",
      "           1       0.53      0.64      0.58       113\n",
      "\n",
      "    accuracy                           0.49       208\n",
      "   macro avg       0.47      0.48      0.47       208\n",
      "weighted avg       0.48      0.49      0.48       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.47596153846153844 and f1 score is: 0.4451704475931772\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.78      0.58        95\n",
      "           1       0.54      0.22      0.31       113\n",
      "\n",
      "    accuracy                           0.48       208\n",
      "   macro avg       0.50      0.50      0.45       208\n",
      "weighted avg       0.50      0.48      0.43       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1105.csv ---\n",
      "[18:04:25] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5817307692307693 and f1 score is: 0.5364635364635365\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.29      0.39        95\n",
      "           1       0.58      0.82      0.68       113\n",
      "\n",
      "    accuracy                           0.58       208\n",
      "   macro avg       0.58      0.56      0.54       208\n",
      "weighted avg       0.58      0.58      0.55       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6057692307692307 and f1 score is: 0.5973940137852894\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.51      0.54        95\n",
      "           1       0.62      0.69      0.66       113\n",
      "\n",
      "    accuracy                           0.61       208\n",
      "   macro avg       0.60      0.60      0.60       208\n",
      "weighted avg       0.60      0.61      0.60       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8843537414965986 and f1 score is: 0.6284014869888476\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.25      0.32        16\n",
      "           1       0.91      0.96      0.94       131\n",
      "\n",
      "    accuracy                           0.88       147\n",
      "   macro avg       0.68      0.61      0.63       147\n",
      "weighted avg       0.86      0.88      0.87       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8775510204081632 and f1 score is: 0.6659090909090909\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.38      0.40        16\n",
      "           1       0.92      0.94      0.93       131\n",
      "\n",
      "    accuracy                           0.88       147\n",
      "   macro avg       0.68      0.66      0.67       147\n",
      "weighted avg       0.87      0.88      0.87       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8163265306122449 and f1 score is: 0.5826059522557577\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.31      0.27        16\n",
      "           1       0.91      0.88      0.89       131\n",
      "\n",
      "    accuracy                           0.82       147\n",
      "   macro avg       0.58      0.60      0.58       147\n",
      "weighted avg       0.84      0.82      0.83       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8503401360544217 and f1 score is: 0.6341628959276018\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.38      0.35        16\n",
      "           1       0.92      0.91      0.92       131\n",
      "\n",
      "    accuracy                           0.85       147\n",
      "   macro avg       0.63      0.64      0.63       147\n",
      "weighted avg       0.86      0.85      0.85       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8843537414965986 and f1 score is: 0.6533499791926758\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.31      0.37        16\n",
      "           1       0.92      0.95      0.94       131\n",
      "\n",
      "    accuracy                           0.88       147\n",
      "   macro avg       0.69      0.63      0.65       147\n",
      "weighted avg       0.87      0.88      0.87       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8231292517006803 and f1 score is: 0.6238188976377953\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.44      0.35        16\n",
      "           1       0.93      0.87      0.90       131\n",
      "\n",
      "    accuracy                           0.82       147\n",
      "   macro avg       0.61      0.65      0.62       147\n",
      "weighted avg       0.86      0.82      0.84       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1106.csv ---\n",
      "[18:06:40] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8503401360544217 and f1 score is: 0.5916666666666667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.25      0.27        16\n",
      "           1       0.91      0.92      0.92       131\n",
      "\n",
      "    accuracy                           0.85       147\n",
      "   macro avg       0.60      0.59      0.59       147\n",
      "weighted avg       0.84      0.85      0.85       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8503401360544217 and f1 score is: 0.6142652671755725\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.31      0.31        16\n",
      "           1       0.92      0.92      0.92       131\n",
      "\n",
      "    accuracy                           0.85       147\n",
      "   macro avg       0.61      0.61      0.61       147\n",
      "weighted avg       0.85      0.85      0.85       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.536723163841808 and f1 score is: 0.3799555707450444\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.04      0.07        84\n",
      "           1       0.53      0.99      0.69        93\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.64      0.51      0.38       177\n",
      "weighted avg       0.64      0.54      0.40       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5819209039548022 and f1 score is: 0.4904295051353874\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.17      0.27        84\n",
      "           1       0.56      0.96      0.71        93\n",
      "\n",
      "    accuracy                           0.58       177\n",
      "   macro avg       0.67      0.56      0.49       177\n",
      "weighted avg       0.66      0.58      0.50       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.559322033898305 and f1 score is: 0.48035230352303526\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.18      0.28        84\n",
      "           1       0.55      0.90      0.68        93\n",
      "\n",
      "    accuracy                           0.56       177\n",
      "   macro avg       0.59      0.54      0.48       177\n",
      "weighted avg       0.59      0.56      0.49       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.6214689265536724 and f1 score is: 0.5886433799299317\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.36      0.47        84\n",
      "           1       0.60      0.86      0.70        93\n",
      "\n",
      "    accuracy                           0.62       177\n",
      "   macro avg       0.65      0.61      0.59       177\n",
      "weighted avg       0.64      0.62      0.59       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5988700564971752 and f1 score is: 0.5193344807802639\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.20      0.32        84\n",
      "           1       0.57      0.96      0.71        93\n",
      "\n",
      "    accuracy                           0.60       177\n",
      "   macro avg       0.69      0.58      0.52       177\n",
      "weighted avg       0.68      0.60      0.53       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5310734463276836 and f1 score is: 0.37710409158363367\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.04      0.07        84\n",
      "           1       0.53      0.98      0.69        93\n",
      "\n",
      "    accuracy                           0.53       177\n",
      "   macro avg       0.56      0.51      0.38       177\n",
      "weighted avg       0.56      0.53      0.39       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1175.csv ---\n",
      "[18:08:53] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.519774011299435 and f1 score is: 0.5035472694274872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.36      0.41        84\n",
      "           1       0.53      0.67      0.59        93\n",
      "\n",
      "    accuracy                           0.52       177\n",
      "   macro avg       0.51      0.51      0.50       177\n",
      "weighted avg       0.51      0.52      0.51       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5875706214689266 and f1 score is: 0.5717694627647234\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.42      0.49        84\n",
      "           1       0.58      0.74      0.65        93\n",
      "\n",
      "    accuracy                           0.59       177\n",
      "   macro avg       0.59      0.58      0.57       177\n",
      "weighted avg       0.59      0.59      0.58       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5231481481481481 and f1 score is: 0.4256357299599845\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.11      0.19       113\n",
      "           1       0.50      0.98      0.66       103\n",
      "\n",
      "    accuracy                           0.52       216\n",
      "   macro avg       0.68      0.54      0.43       216\n",
      "weighted avg       0.69      0.52      0.41       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6064814814814815 and f1 score is: 0.6062705067444405\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60       113\n",
      "           1       0.58      0.66      0.62       103\n",
      "\n",
      "    accuracy                           0.61       216\n",
      "   macro avg       0.61      0.61      0.61       216\n",
      "weighted avg       0.61      0.61      0.61       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6157407407407407 and f1 score is: 0.5869790586771719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.34      0.48       113\n",
      "           1       0.56      0.92      0.70       103\n",
      "\n",
      "    accuracy                           0.62       216\n",
      "   macro avg       0.69      0.63      0.59       216\n",
      "weighted avg       0.70      0.62      0.58       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5277777777777778 and f1 score is: 0.49108380301210386\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.25      0.35       113\n",
      "           1       0.50      0.83      0.63       103\n",
      "\n",
      "    accuracy                           0.53       216\n",
      "   macro avg       0.56      0.54      0.49       216\n",
      "weighted avg       0.57      0.53      0.48       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6157407407407407 and f1 score is: 0.6105233429645238\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.48      0.57       113\n",
      "           1       0.57      0.77      0.66       103\n",
      "\n",
      "    accuracy                           0.62       216\n",
      "   macro avg       0.63      0.62      0.61       216\n",
      "weighted avg       0.64      0.62      0.61       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.47685185185185186 and f1 score is: 0.4735911316237842\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.38      0.43       113\n",
      "           1       0.46      0.58      0.52       103\n",
      "\n",
      "    accuracy                           0.48       216\n",
      "   macro avg       0.48      0.48      0.47       216\n",
      "weighted avg       0.48      0.48      0.47       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1337.csv ---\n",
      "[18:11:06] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5972222222222222 and f1 score is: 0.575370014687606\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.35      0.48       113\n",
      "           1       0.55      0.86      0.67       103\n",
      "\n",
      "    accuracy                           0.60       216\n",
      "   macro avg       0.65      0.61      0.58       216\n",
      "weighted avg       0.65      0.60      0.57       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6018518518518519 and f1 score is: 0.5773571168547507\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.35      0.48       113\n",
      "           1       0.55      0.88      0.68       103\n",
      "\n",
      "    accuracy                           0.60       216\n",
      "   macro avg       0.66      0.61      0.58       216\n",
      "weighted avg       0.66      0.60      0.57       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.568075117370892 and f1 score is: 0.49505256648113793\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.21      0.30        95\n",
      "           1       0.57      0.86      0.69       118\n",
      "\n",
      "    accuracy                           0.57       213\n",
      "   macro avg       0.56      0.53      0.50       213\n",
      "weighted avg       0.56      0.57      0.52       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.47417840375586856 and f1 score is: 0.4164383561643836\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.88      0.60        95\n",
      "           1       0.61      0.14      0.23       118\n",
      "\n",
      "    accuracy                           0.47       213\n",
      "   macro avg       0.53      0.51      0.42       213\n",
      "weighted avg       0.54      0.47      0.40       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5164319248826291 and f1 score is: 0.47475400416576885\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.89      0.62        95\n",
      "           1       0.71      0.21      0.33       118\n",
      "\n",
      "    accuracy                           0.52       213\n",
      "   macro avg       0.60      0.55      0.47       213\n",
      "weighted avg       0.61      0.52      0.46       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.6150234741784038 and f1 score is: 0.6148112208892025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.66      0.61        95\n",
      "           1       0.68      0.58      0.62       118\n",
      "\n",
      "    accuracy                           0.62       213\n",
      "   macro avg       0.62      0.62      0.61       213\n",
      "weighted avg       0.63      0.62      0.62       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.49765258215962443 and f1 score is: 0.4406430236838875\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.92      0.62        95\n",
      "           1       0.70      0.16      0.26       118\n",
      "\n",
      "    accuracy                           0.50       213\n",
      "   macro avg       0.59      0.54      0.44       213\n",
      "weighted avg       0.60      0.50      0.42       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.4694835680751174 and f1 score is: 0.3823552054196926\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.95      0.61        95\n",
      "           1       0.67      0.08      0.15       118\n",
      "\n",
      "    accuracy                           0.47       213\n",
      "   macro avg       0.56      0.52      0.38       213\n",
      "weighted avg       0.57      0.47      0.36       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1390.csv ---\n",
      "[18:13:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.596244131455399 and f1 score is: 0.5695958646616541\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.39      0.46        95\n",
      "           1       0.61      0.76      0.68       118\n",
      "\n",
      "    accuracy                           0.60       213\n",
      "   macro avg       0.59      0.58      0.57       213\n",
      "weighted avg       0.59      0.60      0.58       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.568075117370892 and f1 score is: 0.5664601769911505\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.57      0.54        95\n",
      "           1       0.62      0.57      0.59       118\n",
      "\n",
      "    accuracy                           0.57       213\n",
      "   macro avg       0.57      0.57      0.57       213\n",
      "weighted avg       0.57      0.57      0.57       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6476190476190476 and f1 score is: 0.4393130321835763\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78       136\n",
      "           1       0.50      0.05      0.10        74\n",
      "\n",
      "    accuracy                           0.65       210\n",
      "   macro avg       0.58      0.51      0.44       210\n",
      "weighted avg       0.60      0.65      0.54       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6238095238095238 and f1 score is: 0.5688109161793373\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72       136\n",
      "           1       0.46      0.38      0.41        74\n",
      "\n",
      "    accuracy                           0.62       210\n",
      "   macro avg       0.58      0.57      0.57       210\n",
      "weighted avg       0.61      0.62      0.61       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6666666666666666 and f1 score is: 0.6411483253588517\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74       136\n",
      "           1       0.53      0.57      0.55        74\n",
      "\n",
      "    accuracy                           0.67       210\n",
      "   macro avg       0.64      0.64      0.64       210\n",
      "weighted avg       0.67      0.67      0.67       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.580952380952381 and f1 score is: 0.5512820512820513\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67       136\n",
      "           1       0.41      0.46      0.44        74\n",
      "\n",
      "    accuracy                           0.58       210\n",
      "   macro avg       0.55      0.55      0.55       210\n",
      "weighted avg       0.59      0.58      0.59       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6428571428571429 and f1 score is: 0.5873830918760317\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74       136\n",
      "           1       0.49      0.39      0.44        74\n",
      "\n",
      "    accuracy                           0.64       210\n",
      "   macro avg       0.60      0.59      0.59       210\n",
      "weighted avg       0.63      0.64      0.63       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6285714285714286 and f1 score is: 0.6115169338772413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.69       136\n",
      "           1       0.48      0.59      0.53        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.61      0.62      0.61       210\n",
      "weighted avg       0.65      0.63      0.64       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1400.csv ---\n",
      "[18:15:29] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.680952380952381 and f1 score is: 0.6515515490725377\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75       136\n",
      "           1       0.55      0.55      0.55        74\n",
      "\n",
      "    accuracy                           0.68       210\n",
      "   macro avg       0.65      0.65      0.65       210\n",
      "weighted avg       0.68      0.68      0.68       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6761904761904762 and f1 score is: 0.6072175156782924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77       136\n",
      "           1       0.56      0.36      0.44        74\n",
      "\n",
      "    accuracy                           0.68       210\n",
      "   macro avg       0.64      0.61      0.61       210\n",
      "weighted avg       0.66      0.68      0.66       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.48130841121495327 and f1 score is: 0.4771871904919116\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.64      0.52        95\n",
      "           1       0.55      0.35      0.43       119\n",
      "\n",
      "    accuracy                           0.48       214\n",
      "   macro avg       0.50      0.50      0.48       214\n",
      "weighted avg       0.50      0.48      0.47       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5373831775700935 and f1 score is: 0.48710872249255577\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.96      0.65        95\n",
      "           1       0.86      0.20      0.33       119\n",
      "\n",
      "    accuracy                           0.54       214\n",
      "   macro avg       0.67      0.58      0.49       214\n",
      "weighted avg       0.69      0.54      0.47       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.48598130841121495 and f1 score is: 0.48145211031808965\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.65      0.53        95\n",
      "           1       0.56      0.35      0.43       119\n",
      "\n",
      "    accuracy                           0.49       214\n",
      "   macro avg       0.50      0.50      0.48       214\n",
      "weighted avg       0.51      0.49      0.48       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5794392523364486 and f1 score is: 0.5757335448057097\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54        95\n",
      "           1       0.63      0.61      0.62       119\n",
      "\n",
      "    accuracy                           0.58       214\n",
      "   macro avg       0.58      0.58      0.58       214\n",
      "weighted avg       0.58      0.58      0.58       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5046728971962616 and f1 score is: 0.4624134989098493\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.88      0.61        95\n",
      "           1       0.69      0.20      0.31       119\n",
      "\n",
      "    accuracy                           0.50       214\n",
      "   macro avg       0.58      0.54      0.46       214\n",
      "weighted avg       0.59      0.50      0.45       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5654205607476636 and f1 score is: 0.559407584512187\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.51      0.51        95\n",
      "           1       0.61      0.61      0.61       119\n",
      "\n",
      "    accuracy                           0.57       214\n",
      "   macro avg       0.56      0.56      0.56       214\n",
      "weighted avg       0.56      0.57      0.57       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1419.csv ---\n",
      "[18:17:40] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5514018691588785 and f1 score is: 0.5512450851900393\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.54        95\n",
      "           1       0.62      0.51      0.56       119\n",
      "\n",
      "    accuracy                           0.55       214\n",
      "   macro avg       0.56      0.56      0.55       214\n",
      "weighted avg       0.56      0.55      0.55       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5327102803738317 and f1 score is: 0.5285928275618997\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.71      0.57        95\n",
      "           1       0.63      0.39      0.48       119\n",
      "\n",
      "    accuracy                           0.53       214\n",
      "   macro avg       0.55      0.55      0.53       214\n",
      "weighted avg       0.56      0.53      0.52       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.43209876543209874 and f1 score is: 0.4320121951219512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.28      0.42       122\n",
      "           1       0.29      0.90      0.44        40\n",
      "\n",
      "    accuracy                           0.43       162\n",
      "   macro avg       0.59      0.59      0.43       162\n",
      "weighted avg       0.75      0.43      0.43       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.4691358024691358 and f1 score is: 0.4671052631578947\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.35      0.50       122\n",
      "           1       0.29      0.82      0.43        40\n",
      "\n",
      "    accuracy                           0.47       162\n",
      "   macro avg       0.58      0.59      0.47       162\n",
      "weighted avg       0.72      0.47      0.48       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.4444444444444444 and f1 score is: 0.44308632543926657\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.33      0.47       122\n",
      "           1       0.28      0.80      0.42        40\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.56      0.56      0.44       162\n",
      "weighted avg       0.70      0.44      0.46       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.42592592592592593 and f1 score is: 0.4257289879931389\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.30      0.44       122\n",
      "           1       0.28      0.82      0.42        40\n",
      "\n",
      "    accuracy                           0.43       162\n",
      "   macro avg       0.56      0.56      0.43       162\n",
      "weighted avg       0.70      0.43      0.43       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5 and f1 score is: 0.49443267193219037\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.40      0.55       122\n",
      "           1       0.30      0.80      0.44        40\n",
      "\n",
      "    accuracy                           0.50       162\n",
      "   macro avg       0.58      0.60      0.49       162\n",
      "weighted avg       0.72      0.50      0.52       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.47530864197530864 and f1 score is: 0.4719079578139981\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.37      0.51       122\n",
      "           1       0.29      0.80      0.43        40\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.57      0.58      0.47       162\n",
      "weighted avg       0.71      0.48      0.49       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1517.csv ---\n",
      "[18:19:56] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5185185185185185 and f1 score is: 0.4963329081632653\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.48      0.60       122\n",
      "           1       0.28      0.62      0.39        40\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.54      0.55      0.50       162\n",
      "weighted avg       0.67      0.52      0.55       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5061728395061729 and f1 score is: 0.4586466165413533\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.53      0.62       122\n",
      "           1       0.23      0.42      0.30        40\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.48      0.48      0.46       162\n",
      "weighted avg       0.61      0.51      0.54       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.5652173913043478 and f1 score is: 0.4866071428571429\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.40      0.29        10\n",
      "           1       0.79      0.61      0.69        36\n",
      "\n",
      "    accuracy                           0.57        46\n",
      "   macro avg       0.50      0.51      0.49        46\n",
      "weighted avg       0.66      0.57      0.60        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.7391304347826086 and f1 score is: 0.425\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.77      0.94      0.85        36\n",
      "\n",
      "    accuracy                           0.74        46\n",
      "   macro avg       0.39      0.47      0.42        46\n",
      "weighted avg       0.60      0.74      0.67        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.5652173913043478 and f1 score is: 0.5053763440860215\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.50      0.33        10\n",
      "           1       0.81      0.58      0.68        36\n",
      "\n",
      "    accuracy                           0.57        46\n",
      "   macro avg       0.53      0.54      0.51        46\n",
      "weighted avg       0.69      0.57      0.60        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1544.csv ---\n",
      "[18:22:13] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6956521739130435 and f1 score is: 0.5527777777777778\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.30      0.30        10\n",
      "           1       0.81      0.81      0.81        36\n",
      "\n",
      "    accuracy                           0.70        46\n",
      "   macro avg       0.55      0.55      0.55        46\n",
      "weighted avg       0.70      0.70      0.70        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.5434782608695652 and f1 score is: 0.42328358208955225\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.20      0.16        10\n",
      "           1       0.74      0.64      0.69        36\n",
      "\n",
      "    accuracy                           0.54        46\n",
      "   macro avg       0.44      0.42      0.42        46\n",
      "weighted avg       0.61      0.54      0.57        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.6226415094339622 and f1 score is: 0.6114369501466277\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.49      0.55        73\n",
      "           1       0.63      0.73      0.68        86\n",
      "\n",
      "    accuracy                           0.62       159\n",
      "   macro avg       0.62      0.61      0.61       159\n",
      "weighted avg       0.62      0.62      0.62       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5660377358490566 and f1 score is: 0.49398090493980906\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.21      0.30        73\n",
      "           1       0.56      0.87      0.68        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.57      0.54      0.49       159\n",
      "weighted avg       0.57      0.57      0.51       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5660377358490566 and f1 score is: 0.5541150172729119\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.44      0.48        73\n",
      "           1       0.59      0.67      0.63        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.56      0.56      0.55       159\n",
      "weighted avg       0.56      0.57      0.56       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5534591194968553 and f1 score is: 0.3805761316872428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.05        73\n",
      "           1       0.55      1.00      0.71        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.77      0.51      0.38       159\n",
      "weighted avg       0.76      0.55      0.41       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5471698113207547 and f1 score is: 0.4748623853211009\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.19      0.28        73\n",
      "           1       0.55      0.85      0.67        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.54      0.52      0.47       159\n",
      "weighted avg       0.54      0.55      0.49       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5345911949685535 and f1 score is: 0.4412044072948328\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.14      0.21        73\n",
      "           1       0.54      0.87      0.67        86\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.51      0.50      0.44       159\n",
      "weighted avg       0.51      0.53      0.46       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1624.csv ---\n",
      "[18:24:30] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5660377358490566 and f1 score is: 0.5654188948306595\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.55        73\n",
      "           1       0.61      0.56      0.58        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.57      0.57      0.57       159\n",
      "weighted avg       0.57      0.57      0.57       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5031446540880503 and f1 score is: 0.5018836499187056\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.60      0.53        73\n",
      "           1       0.55      0.42      0.48        86\n",
      "\n",
      "    accuracy                           0.50       159\n",
      "   macro avg       0.51      0.51      0.50       159\n",
      "weighted avg       0.51      0.50      0.50       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6685082872928176 and f1 score is: 0.40066225165562913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        60\n",
      "           1       0.67      1.00      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.83      0.50      0.40       181\n",
      "weighted avg       0.78      0.67      0.54       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5966850828729282 and f1 score is: 0.4790853538340232\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.18      0.23        60\n",
      "           1       0.66      0.80      0.73       121\n",
      "\n",
      "    accuracy                           0.60       181\n",
      "   macro avg       0.49      0.49      0.48       181\n",
      "weighted avg       0.55      0.60      0.56       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6022099447513812 and f1 score is: 0.4676470588235294\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.15      0.20        60\n",
      "           1       0.66      0.83      0.74       121\n",
      "\n",
      "    accuracy                           0.60       181\n",
      "   macro avg       0.48      0.49      0.47       181\n",
      "weighted avg       0.54      0.60      0.56       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6574585635359116 and f1 score is: 0.4509784735812133\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.07      0.11        60\n",
      "           1       0.67      0.95      0.79       121\n",
      "\n",
      "    accuracy                           0.66       181\n",
      "   macro avg       0.54      0.51      0.45       181\n",
      "weighted avg       0.58      0.66      0.56       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5580110497237569 and f1 score is: 0.47763347763347763\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.25      0.27        60\n",
      "           1       0.66      0.71      0.68       121\n",
      "\n",
      "    accuracy                           0.56       181\n",
      "   macro avg       0.48      0.48      0.48       181\n",
      "weighted avg       0.54      0.56      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5193370165745856 and f1 score is: 0.4643330952137973\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.30      0.29        60\n",
      "           1       0.64      0.63      0.64       121\n",
      "\n",
      "    accuracy                           0.52       181\n",
      "   macro avg       0.46      0.46      0.46       181\n",
      "weighted avg       0.53      0.52      0.52       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1688.csv ---\n",
      "[18:26:44] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6574585635359116 and f1 score is: 0.4837136547662864\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.12      0.18        60\n",
      "           1       0.68      0.93      0.78       121\n",
      "\n",
      "    accuracy                           0.66       181\n",
      "   macro avg       0.56      0.52      0.48       181\n",
      "weighted avg       0.60      0.66      0.58       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5966850828729282 and f1 score is: 0.4477324973876698\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.12      0.16        60\n",
      "           1       0.66      0.83      0.73       121\n",
      "\n",
      "    accuracy                           0.60       181\n",
      "   macro avg       0.46      0.48      0.45       181\n",
      "weighted avg       0.52      0.60      0.54       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.7129629629629629 and f1 score is: 0.4944889023101314\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.16        34\n",
      "           1       0.70      1.00      0.83        74\n",
      "\n",
      "    accuracy                           0.71       108\n",
      "   macro avg       0.85      0.54      0.49       108\n",
      "weighted avg       0.80      0.71      0.62       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.3888888888888889 and f1 score is: 0.3880494505494505\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.68      0.41        34\n",
      "           1       0.63      0.26      0.37        74\n",
      "\n",
      "    accuracy                           0.39       108\n",
      "   macro avg       0.46      0.47      0.39       108\n",
      "weighted avg       0.53      0.39      0.38       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6944444444444444 and f1 score is: 0.5874522514179882\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.29      0.38        34\n",
      "           1       0.73      0.88      0.80        74\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.63      0.59      0.59       108\n",
      "weighted avg       0.67      0.69      0.67       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5092592592592593 and f1 score is: 0.44400194269062654\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.26      0.25        34\n",
      "           1       0.65      0.62      0.63        74\n",
      "\n",
      "    accuracy                           0.51       108\n",
      "   macro avg       0.45      0.44      0.44       108\n",
      "weighted avg       0.52      0.51      0.51       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.3888888888888889 and f1 score is: 0.3888888888888889\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.62      0.39        34\n",
      "           1       0.62      0.28      0.39        74\n",
      "\n",
      "    accuracy                           0.39       108\n",
      "   macro avg       0.45      0.45      0.39       108\n",
      "weighted avg       0.51      0.39      0.39       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6759259259259259 and f1 score is: 0.654320987654321\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.68      0.57        34\n",
      "           1       0.82      0.68      0.74        74\n",
      "\n",
      "    accuracy                           0.68       108\n",
      "   macro avg       0.65      0.68      0.65       108\n",
      "weighted avg       0.72      0.68      0.69       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1717.csv ---\n",
      "[18:29:00] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.7129629629629629 and f1 score is: 0.5649122807017544\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.21      0.31        34\n",
      "           1       0.72      0.95      0.82        74\n",
      "\n",
      "    accuracy                           0.71       108\n",
      "   macro avg       0.68      0.58      0.56       108\n",
      "weighted avg       0.69      0.71      0.66       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6759259259259259 and f1 score is: 0.562449357564533\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.26      0.34        34\n",
      "           1       0.72      0.86      0.79        74\n",
      "\n",
      "    accuracy                           0.68       108\n",
      "   macro avg       0.60      0.56      0.56       108\n",
      "weighted avg       0.64      0.68      0.64       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5123456790123457 and f1 score is: 0.46752652381943\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.21      0.31        86\n",
      "           1       0.49      0.86      0.62        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.55      0.53      0.47       162\n",
      "weighted avg       0.56      0.51      0.46       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.46296296296296297 and f1 score is: 0.3929971144321461\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.12      0.19        86\n",
      "           1       0.46      0.86      0.60        76\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.47      0.49      0.39       162\n",
      "weighted avg       0.47      0.46      0.38       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4382716049382716 and f1 score is: 0.3998290111142776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.17      0.25        86\n",
      "           1       0.44      0.74      0.55        76\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.43      0.46      0.40       162\n",
      "weighted avg       0.43      0.44      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4444444444444444 and f1 score is: 0.4155844155844156\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.21      0.29        86\n",
      "           1       0.44      0.71      0.55        76\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.45      0.46      0.42       162\n",
      "weighted avg       0.45      0.44      0.41       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.46296296296296297 and f1 score is: 0.403882755995432\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.14      0.22        86\n",
      "           1       0.46      0.83      0.59        76\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.47      0.48      0.40       162\n",
      "weighted avg       0.47      0.46      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4074074074074074 and f1 score is: 0.3647058823529412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.14      0.20        86\n",
      "           1       0.42      0.71      0.53        76\n",
      "\n",
      "    accuracy                           0.41       162\n",
      "   macro avg       0.39      0.43      0.36       162\n",
      "weighted avg       0.39      0.41      0.35       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1765.csv ---\n",
      "[18:31:15] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4382716049382716 and f1 score is: 0.41395348837209295\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.22      0.29        86\n",
      "           1       0.44      0.68      0.53        76\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.44      0.45      0.41       162\n",
      "weighted avg       0.44      0.44      0.41       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.48148148148148145 and f1 score is: 0.45129032258064516\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.23      0.32        86\n",
      "           1       0.47      0.76      0.58        76\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.50      0.50      0.45       162\n",
      "weighted avg       0.50      0.48      0.44       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7735849056603774 and f1 score is: 0.5340659340659342\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.38      0.20        16\n",
      "           1       0.94      0.81      0.87       196\n",
      "\n",
      "    accuracy                           0.77       212\n",
      "   macro avg       0.54      0.59      0.53       212\n",
      "weighted avg       0.88      0.77      0.82       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8726415094339622 and f1 score is: 0.5003055434308162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.06      0.07        16\n",
      "           1       0.92      0.94      0.93       196\n",
      "\n",
      "    accuracy                           0.87       212\n",
      "   macro avg       0.50      0.50      0.50       212\n",
      "weighted avg       0.86      0.87      0.87       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7216981132075472 and f1 score is: 0.5221394460362941\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.50      0.21        16\n",
      "           1       0.95      0.74      0.83       196\n",
      "\n",
      "    accuracy                           0.72       212\n",
      "   macro avg       0.54      0.62      0.52       212\n",
      "weighted avg       0.89      0.72      0.78       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.589622641509434 and f1 score is: 0.4562339691618268\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.62      0.19        16\n",
      "           1       0.95      0.59      0.73       196\n",
      "\n",
      "    accuracy                           0.59       212\n",
      "   macro avg       0.53      0.61      0.46       212\n",
      "weighted avg       0.89      0.59      0.68       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8773584905660378 and f1 score is: 0.5843137254901961\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.25      0.24        16\n",
      "           1       0.94      0.93      0.93       196\n",
      "\n",
      "    accuracy                           0.88       212\n",
      "   macro avg       0.58      0.59      0.58       212\n",
      "weighted avg       0.88      0.88      0.88       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.4858490566037736 and f1 score is: 0.3873644582305999\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.56      0.14        16\n",
      "           1       0.93      0.48      0.63       196\n",
      "\n",
      "    accuracy                           0.49       212\n",
      "   macro avg       0.51      0.52      0.39       212\n",
      "weighted avg       0.87      0.49      0.60       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1818.csv ---\n",
      "[18:33:28] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6415094339622641 and f1 score is: 0.4724986904138292\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.50      0.17        16\n",
      "           1       0.94      0.65      0.77       196\n",
      "\n",
      "    accuracy                           0.64       212\n",
      "   macro avg       0.52      0.58      0.47       212\n",
      "weighted avg       0.88      0.64      0.73       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.5471698113207547 and f1 score is: 0.41758241758241765\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.50      0.14        16\n",
      "           1       0.93      0.55      0.69       196\n",
      "\n",
      "    accuracy                           0.55       212\n",
      "   macro avg       0.51      0.53      0.42       212\n",
      "weighted avg       0.87      0.55      0.65       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.49537037037037035 and f1 score is: 0.4630419412958697\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.49      0.59       162\n",
      "           1       0.25      0.50      0.33        54\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.50      0.50      0.46       216\n",
      "weighted avg       0.62      0.50      0.53       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.49537037037037035 and f1 score is: 0.4745463878411855\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.46      0.58       162\n",
      "           1       0.27      0.59      0.37        54\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.52      0.53      0.47       216\n",
      "weighted avg       0.65      0.50      0.53       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4861111111111111 and f1 score is: 0.4627949183303085\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.46      0.57       162\n",
      "           1       0.26      0.56      0.35        54\n",
      "\n",
      "    accuracy                           0.49       216\n",
      "   macro avg       0.51      0.51      0.46       216\n",
      "weighted avg       0.63      0.49      0.52       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4074074074074074 and f1 score is: 0.4041379310344827\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.32      0.45       162\n",
      "           1       0.25      0.67      0.36        54\n",
      "\n",
      "    accuracy                           0.41       216\n",
      "   macro avg       0.49      0.49      0.40       216\n",
      "weighted avg       0.62      0.41      0.43       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4675925925925926 and f1 score is: 0.45149822244794313\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.43      0.55       162\n",
      "           1       0.26      0.59      0.36        54\n",
      "\n",
      "    accuracy                           0.47       216\n",
      "   macro avg       0.51      0.51      0.45       216\n",
      "weighted avg       0.63      0.47      0.50       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.39351851851851855 and f1 score is: 0.3919415493714409\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.30      0.42       162\n",
      "           1       0.25      0.69      0.36        54\n",
      "\n",
      "    accuracy                           0.39       216\n",
      "   macro avg       0.49      0.49      0.39       216\n",
      "weighted avg       0.62      0.39      0.41       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1892.csv ---\n",
      "[18:35:40] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5324074074074074 and f1 score is: 0.4999885402580733\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.52      0.63       162\n",
      "           1       0.28      0.56      0.37        54\n",
      "\n",
      "    accuracy                           0.53       216\n",
      "   macro avg       0.53      0.54      0.50       216\n",
      "weighted avg       0.65      0.53      0.56       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5879629629629629 and f1 score is: 0.5205387205387205\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.64      0.70       162\n",
      "           1       0.28      0.43      0.34        54\n",
      "\n",
      "    accuracy                           0.59       216\n",
      "   macro avg       0.53      0.53      0.52       216\n",
      "weighted avg       0.65      0.59      0.61       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5283018867924528 and f1 score is: 0.5005183300348695\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.48      0.38        65\n",
      "           1       0.70      0.55      0.62       147\n",
      "\n",
      "    accuracy                           0.53       212\n",
      "   macro avg       0.51      0.51      0.50       212\n",
      "weighted avg       0.59      0.53      0.55       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5707547169811321 and f1 score is: 0.5093466263129784\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.35      0.34        65\n",
      "           1       0.70      0.67      0.68       147\n",
      "\n",
      "    accuracy                           0.57       212\n",
      "   macro avg       0.51      0.51      0.51       212\n",
      "weighted avg       0.58      0.57      0.58       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5094339622641509 and f1 score is: 0.5007246376811594\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.62      0.43        65\n",
      "           1       0.73      0.46      0.57       147\n",
      "\n",
      "    accuracy                           0.51       212\n",
      "   macro avg       0.53      0.54      0.50       212\n",
      "weighted avg       0.61      0.51      0.53       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5660377358490566 and f1 score is: 0.48055821881325234\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.26      0.27        65\n",
      "           1       0.68      0.70      0.69       147\n",
      "\n",
      "    accuracy                           0.57       212\n",
      "   macro avg       0.48      0.48      0.48       212\n",
      "weighted avg       0.56      0.57      0.56       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5707547169811321 and f1 score is: 0.4973816533361124\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.31      0.31        65\n",
      "           1       0.69      0.69      0.69       147\n",
      "\n",
      "    accuracy                           0.57       212\n",
      "   macro avg       0.50      0.50      0.50       212\n",
      "weighted avg       0.57      0.57      0.57       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.45754716981132076 and f1 score is: 0.4531547899423547\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.60      0.40        65\n",
      "           1       0.69      0.39      0.50       147\n",
      "\n",
      "    accuracy                           0.46       212\n",
      "   macro avg       0.50      0.50      0.45       212\n",
      "weighted avg       0.57      0.46      0.47       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1929.csv ---\n",
      "[18:37:52] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.4858490566037736 and f1 score is: 0.48168584438014495\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.65      0.44        65\n",
      "           1       0.73      0.41      0.53       147\n",
      "\n",
      "    accuracy                           0.49       212\n",
      "   macro avg       0.53      0.53      0.48       212\n",
      "weighted avg       0.60      0.49      0.50       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.4669811320754717 and f1 score is: 0.4635315194267159\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.63      0.42        65\n",
      "           1       0.71      0.39      0.51       147\n",
      "\n",
      "    accuracy                           0.47       212\n",
      "   macro avg       0.51      0.51      0.46       212\n",
      "weighted avg       0.59      0.47      0.48       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5306122448979592 and f1 score is: 0.5006645990252548\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.39      0.38        36\n",
      "           1       0.63      0.61      0.62        62\n",
      "\n",
      "    accuracy                           0.53        98\n",
      "   macro avg       0.50      0.50      0.50        98\n",
      "weighted avg       0.54      0.53      0.53        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6224489795918368 and f1 score is: 0.6107353730542135\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.61      0.54        36\n",
      "           1       0.74      0.63      0.68        62\n",
      "\n",
      "    accuracy                           0.62        98\n",
      "   macro avg       0.61      0.62      0.61        98\n",
      "weighted avg       0.65      0.62      0.63        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5510204081632653 and f1 score is: 0.5493311036789297\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.67      0.52        36\n",
      "           1       0.71      0.48      0.58        62\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.57      0.58      0.55        98\n",
      "weighted avg       0.61      0.55      0.56        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.40816326530612246 and f1 score is: 0.4019360269360269\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.42      0.34        36\n",
      "           1       0.54      0.40      0.46        62\n",
      "\n",
      "    accuracy                           0.41        98\n",
      "   macro avg       0.42      0.41      0.40        98\n",
      "weighted avg       0.45      0.41      0.42        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6428571428571429 and f1 score is: 0.6342893698688559\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.67      0.58        36\n",
      "           1       0.76      0.63      0.69        62\n",
      "\n",
      "    accuracy                           0.64        98\n",
      "   macro avg       0.64      0.65      0.63        98\n",
      "weighted avg       0.67      0.64      0.65        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6020408163265306 and f1 score is: 0.5271557590003711\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.28      0.34        36\n",
      "           1       0.65      0.79      0.72        62\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.54      0.53      0.53        98\n",
      "weighted avg       0.57      0.60      0.58        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1933.csv ---\n",
      "[18:40:08] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5714285714285714 and f1 score is: 0.5528031290743155\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46        36\n",
      "           1       0.68      0.61      0.64        62\n",
      "\n",
      "    accuracy                           0.57        98\n",
      "   macro avg       0.55      0.56      0.55        98\n",
      "weighted avg       0.59      0.57      0.58        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5918367346938775 and f1 score is: 0.5806589644843817\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.58      0.51        36\n",
      "           1       0.71      0.60      0.65        62\n",
      "\n",
      "    accuracy                           0.59        98\n",
      "   macro avg       0.58      0.59      0.58        98\n",
      "weighted avg       0.62      0.59      0.60        98\n",
      "\n",
      "----- Running Modality Combination EDA_EEG_GAZE\n",
      "Saved Directory: 2022_08_11_18_41\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5576923076923077 and f1 score is: 0.4025227925565131\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.05      0.10        95\n",
      "           1       0.55      0.98      0.71       113\n",
      "\n",
      "    accuracy                           0.56       208\n",
      "   macro avg       0.63      0.52      0.40       208\n",
      "weighted avg       0.63      0.56      0.43       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.4855769230769231 and f1 score is: 0.449857866765542\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.25      0.31        95\n",
      "           1       0.52      0.68      0.59       113\n",
      "\n",
      "    accuracy                           0.49       208\n",
      "   macro avg       0.46      0.47      0.45       208\n",
      "weighted avg       0.47      0.49      0.46       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5336538461538461 and f1 score is: 0.5327791028877105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.54      0.51        95\n",
      "           1       0.58      0.53      0.55       113\n",
      "\n",
      "    accuracy                           0.53       208\n",
      "   macro avg       0.53      0.53      0.53       208\n",
      "weighted avg       0.54      0.53      0.53       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5625 and f1 score is: 0.5367936764310012\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.36      0.43        95\n",
      "           1       0.58      0.73      0.65       113\n",
      "\n",
      "    accuracy                           0.56       208\n",
      "   macro avg       0.55      0.55      0.54       208\n",
      "weighted avg       0.56      0.56      0.55       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.49038461538461536 and f1 score is: 0.46872289156626507\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.32      0.36        95\n",
      "           1       0.53      0.64      0.58       113\n",
      "\n",
      "    accuracy                           0.49       208\n",
      "   macro avg       0.47      0.48      0.47       208\n",
      "weighted avg       0.48      0.49      0.48       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.47596153846153844 and f1 score is: 0.4451704475931772\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.78      0.58        95\n",
      "           1       0.54      0.22      0.31       113\n",
      "\n",
      "    accuracy                           0.48       208\n",
      "   macro avg       0.50      0.50      0.45       208\n",
      "weighted avg       0.50      0.48      0.43       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1105.csv ---\n",
      "[18:42:22] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.5817307692307693 and f1 score is: 0.5364635364635365\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.29      0.39        95\n",
      "           1       0.58      0.82      0.68       113\n",
      "\n",
      "    accuracy                           0.58       208\n",
      "   macro avg       0.58      0.56      0.54       208\n",
      "weighted avg       0.58      0.58      0.55       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1105.csv ---\n",
      "Test Subject: 1105.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1105.csv is: 0.6057692307692307 and f1 score is: 0.5973940137852894\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.51      0.54        95\n",
      "           1       0.62      0.69      0.66       113\n",
      "\n",
      "    accuracy                           0.61       208\n",
      "   macro avg       0.60      0.60      0.60       208\n",
      "weighted avg       0.60      0.61      0.60       208\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8843537414965986 and f1 score is: 0.6284014869888476\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.25      0.32        16\n",
      "           1       0.91      0.96      0.94       131\n",
      "\n",
      "    accuracy                           0.88       147\n",
      "   macro avg       0.68      0.61      0.63       147\n",
      "weighted avg       0.86      0.88      0.87       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8775510204081632 and f1 score is: 0.6659090909090909\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.38      0.40        16\n",
      "           1       0.92      0.94      0.93       131\n",
      "\n",
      "    accuracy                           0.88       147\n",
      "   macro avg       0.68      0.66      0.67       147\n",
      "weighted avg       0.87      0.88      0.87       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8231292517006803 and f1 score is: 0.5885012919896642\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.31      0.28        16\n",
      "           1       0.91      0.89      0.90       131\n",
      "\n",
      "    accuracy                           0.82       147\n",
      "   macro avg       0.58      0.60      0.59       147\n",
      "weighted avg       0.84      0.82      0.83       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8367346938775511 and f1 score is: 0.6201550387596899\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.38      0.33        16\n",
      "           1       0.92      0.89      0.91       131\n",
      "\n",
      "    accuracy                           0.84       147\n",
      "   macro avg       0.61      0.63      0.62       147\n",
      "weighted avg       0.85      0.84      0.84       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8843537414965986 and f1 score is: 0.6533499791926758\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.31      0.37        16\n",
      "           1       0.92      0.95      0.94       131\n",
      "\n",
      "    accuracy                           0.88       147\n",
      "   macro avg       0.69      0.63      0.65       147\n",
      "weighted avg       0.87      0.88      0.87       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8231292517006803 and f1 score is: 0.6238188976377953\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.44      0.35        16\n",
      "           1       0.93      0.87      0.90       131\n",
      "\n",
      "    accuracy                           0.82       147\n",
      "   macro avg       0.61      0.65      0.62       147\n",
      "weighted avg       0.86      0.82      0.84       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1106.csv ---\n",
      "[18:44:37] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8503401360544217 and f1 score is: 0.5916666666666667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.25      0.27        16\n",
      "           1       0.91      0.92      0.92       131\n",
      "\n",
      "    accuracy                           0.85       147\n",
      "   macro avg       0.60      0.59      0.59       147\n",
      "weighted avg       0.84      0.85      0.85       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1106.csv ---\n",
      "Test Subject: 1106.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1106.csv is: 0.8503401360544217 and f1 score is: 0.6142652671755725\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.31      0.31        16\n",
      "           1       0.92      0.92      0.92       131\n",
      "\n",
      "    accuracy                           0.85       147\n",
      "   macro avg       0.61      0.61      0.61       147\n",
      "weighted avg       0.85      0.85      0.85       147\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.536723163841808 and f1 score is: 0.3799555707450444\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.04      0.07        84\n",
      "           1       0.53      0.99      0.69        93\n",
      "\n",
      "    accuracy                           0.54       177\n",
      "   macro avg       0.64      0.51      0.38       177\n",
      "weighted avg       0.64      0.54      0.40       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5819209039548022 and f1 score is: 0.4904295051353874\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.17      0.27        84\n",
      "           1       0.56      0.96      0.71        93\n",
      "\n",
      "    accuracy                           0.58       177\n",
      "   macro avg       0.67      0.56      0.49       177\n",
      "weighted avg       0.66      0.58      0.50       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5480225988700564 and f1 score is: 0.49152542372881347\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.23      0.32        84\n",
      "           1       0.55      0.84      0.66        93\n",
      "\n",
      "    accuracy                           0.55       177\n",
      "   macro avg       0.55      0.53      0.49       177\n",
      "weighted avg       0.55      0.55      0.50       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.6101694915254238 and f1 score is: 0.5792248062015504\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.36      0.47        84\n",
      "           1       0.59      0.84      0.69        93\n",
      "\n",
      "    accuracy                           0.61       177\n",
      "   macro avg       0.63      0.60      0.58       177\n",
      "weighted avg       0.63      0.61      0.59       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5988700564971752 and f1 score is: 0.5193344807802639\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.20      0.32        84\n",
      "           1       0.57      0.96      0.71        93\n",
      "\n",
      "    accuracy                           0.60       177\n",
      "   macro avg       0.69      0.58      0.52       177\n",
      "weighted avg       0.68      0.60      0.53       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5310734463276836 and f1 score is: 0.37710409158363367\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.04      0.07        84\n",
      "           1       0.53      0.98      0.69        93\n",
      "\n",
      "    accuracy                           0.53       177\n",
      "   macro avg       0.56      0.51      0.38       177\n",
      "weighted avg       0.56      0.53      0.39       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1175.csv ---\n",
      "[18:46:51] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.519774011299435 and f1 score is: 0.5035472694274872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.36      0.41        84\n",
      "           1       0.53      0.67      0.59        93\n",
      "\n",
      "    accuracy                           0.52       177\n",
      "   macro avg       0.51      0.51      0.50       177\n",
      "weighted avg       0.51      0.52      0.51       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1175.csv ---\n",
      "Test Subject: 1175.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1175.csv is: 0.5875706214689266 and f1 score is: 0.5717694627647234\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.42      0.49        84\n",
      "           1       0.58      0.74      0.65        93\n",
      "\n",
      "    accuracy                           0.59       177\n",
      "   macro avg       0.59      0.58      0.57       177\n",
      "weighted avg       0.59      0.59      0.58       177\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5231481481481481 and f1 score is: 0.4256357299599845\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.11      0.19       113\n",
      "           1       0.50      0.98      0.66       103\n",
      "\n",
      "    accuracy                           0.52       216\n",
      "   macro avg       0.68      0.54      0.43       216\n",
      "weighted avg       0.69      0.52      0.41       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6064814814814815 and f1 score is: 0.6062705067444405\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60       113\n",
      "           1       0.58      0.66      0.62       103\n",
      "\n",
      "    accuracy                           0.61       216\n",
      "   macro avg       0.61      0.61      0.61       216\n",
      "weighted avg       0.61      0.61      0.61       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6111111111111112 and f1 score is: 0.5785953177257525\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.32      0.46       113\n",
      "           1       0.55      0.93      0.70       103\n",
      "\n",
      "    accuracy                           0.61       216\n",
      "   macro avg       0.70      0.63      0.58       216\n",
      "weighted avg       0.70      0.61      0.57       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5787037037037037 and f1 score is: 0.5659681586327202\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.39      0.49       113\n",
      "           1       0.54      0.79      0.64       103\n",
      "\n",
      "    accuracy                           0.58       216\n",
      "   macro avg       0.60      0.59      0.57       216\n",
      "weighted avg       0.61      0.58      0.56       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6157407407407407 and f1 score is: 0.6105233429645238\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.48      0.57       113\n",
      "           1       0.57      0.77      0.66       103\n",
      "\n",
      "    accuracy                           0.62       216\n",
      "   macro avg       0.63      0.62      0.61       216\n",
      "weighted avg       0.64      0.62      0.61       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.47685185185185186 and f1 score is: 0.4735911316237842\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.38      0.43       113\n",
      "           1       0.46      0.58      0.52       103\n",
      "\n",
      "    accuracy                           0.48       216\n",
      "   macro avg       0.48      0.48      0.47       216\n",
      "weighted avg       0.48      0.48      0.47       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1337.csv ---\n",
      "[18:49:03] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.5972222222222222 and f1 score is: 0.575370014687606\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.35      0.48       113\n",
      "           1       0.55      0.86      0.67       103\n",
      "\n",
      "    accuracy                           0.60       216\n",
      "   macro avg       0.65      0.61      0.58       216\n",
      "weighted avg       0.65      0.60      0.57       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1337.csv ---\n",
      "Test Subject: 1337.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1337.csv is: 0.6018518518518519 and f1 score is: 0.5773571168547507\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.35      0.48       113\n",
      "           1       0.55      0.88      0.68       103\n",
      "\n",
      "    accuracy                           0.60       216\n",
      "   macro avg       0.66      0.61      0.58       216\n",
      "weighted avg       0.66      0.60      0.57       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.568075117370892 and f1 score is: 0.49505256648113793\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.21      0.30        95\n",
      "           1       0.57      0.86      0.69       118\n",
      "\n",
      "    accuracy                           0.57       213\n",
      "   macro avg       0.56      0.53      0.50       213\n",
      "weighted avg       0.56      0.57      0.52       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.47417840375586856 and f1 score is: 0.4164383561643836\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.88      0.60        95\n",
      "           1       0.61      0.14      0.23       118\n",
      "\n",
      "    accuracy                           0.47       213\n",
      "   macro avg       0.53      0.51      0.42       213\n",
      "weighted avg       0.54      0.47      0.40       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5164319248826291 and f1 score is: 0.4777050351148673\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.88      0.62        95\n",
      "           1       0.70      0.22      0.34       118\n",
      "\n",
      "    accuracy                           0.52       213\n",
      "   macro avg       0.59      0.55      0.48       213\n",
      "weighted avg       0.60      0.52      0.46       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.5211267605633803 and f1 score is: 0.4685420743639922\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.64        95\n",
      "           1       0.79      0.19      0.30       118\n",
      "\n",
      "    accuracy                           0.52       213\n",
      "   macro avg       0.63      0.56      0.47       213\n",
      "weighted avg       0.65      0.52      0.45       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.49765258215962443 and f1 score is: 0.4406430236838875\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.92      0.62        95\n",
      "           1       0.70      0.16      0.26       118\n",
      "\n",
      "    accuracy                           0.50       213\n",
      "   macro avg       0.59      0.54      0.44       213\n",
      "weighted avg       0.60      0.50      0.42       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.4694835680751174 and f1 score is: 0.3823552054196926\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.95      0.61        95\n",
      "           1       0.67      0.08      0.15       118\n",
      "\n",
      "    accuracy                           0.47       213\n",
      "   macro avg       0.56      0.52      0.38       213\n",
      "weighted avg       0.57      0.47      0.36       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1390.csv ---\n",
      "[18:51:15] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.596244131455399 and f1 score is: 0.5695958646616541\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.39      0.46        95\n",
      "           1       0.61      0.76      0.68       118\n",
      "\n",
      "    accuracy                           0.60       213\n",
      "   macro avg       0.59      0.58      0.57       213\n",
      "weighted avg       0.59      0.60      0.58       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1390.csv ---\n",
      "Test Subject: 1390.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1390.csv is: 0.568075117370892 and f1 score is: 0.5664601769911505\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.57      0.54        95\n",
      "           1       0.62      0.57      0.59       118\n",
      "\n",
      "    accuracy                           0.57       213\n",
      "   macro avg       0.57      0.57      0.57       213\n",
      "weighted avg       0.57      0.57      0.57       213\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6476190476190476 and f1 score is: 0.4393130321835763\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78       136\n",
      "           1       0.50      0.05      0.10        74\n",
      "\n",
      "    accuracy                           0.65       210\n",
      "   macro avg       0.58      0.51      0.44       210\n",
      "weighted avg       0.60      0.65      0.54       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6238095238095238 and f1 score is: 0.5688109161793373\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72       136\n",
      "           1       0.46      0.38      0.41        74\n",
      "\n",
      "    accuracy                           0.62       210\n",
      "   macro avg       0.58      0.57      0.57       210\n",
      "weighted avg       0.61      0.62      0.61       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6666666666666666 and f1 score is: 0.6411483253588517\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74       136\n",
      "           1       0.53      0.57      0.55        74\n",
      "\n",
      "    accuracy                           0.67       210\n",
      "   macro avg       0.64      0.64      0.64       210\n",
      "weighted avg       0.67      0.67      0.67       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6047619047619047 and f1 score is: 0.4268521258755056\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.90      0.75       136\n",
      "           1       0.26      0.07      0.11        74\n",
      "\n",
      "    accuracy                           0.60       210\n",
      "   macro avg       0.45      0.48      0.43       210\n",
      "weighted avg       0.51      0.60      0.52       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6428571428571429 and f1 score is: 0.5873830918760317\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74       136\n",
      "           1       0.49      0.39      0.44        74\n",
      "\n",
      "    accuracy                           0.64       210\n",
      "   macro avg       0.60      0.59      0.59       210\n",
      "weighted avg       0.63      0.64      0.63       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6285714285714286 and f1 score is: 0.6115169338772413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.69       136\n",
      "           1       0.48      0.59      0.53        74\n",
      "\n",
      "    accuracy                           0.63       210\n",
      "   macro avg       0.61      0.62      0.61       210\n",
      "weighted avg       0.65      0.63      0.64       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1400.csv ---\n",
      "[18:53:27] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.680952380952381 and f1 score is: 0.6515515490725377\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75       136\n",
      "           1       0.55      0.55      0.55        74\n",
      "\n",
      "    accuracy                           0.68       210\n",
      "   macro avg       0.65      0.65      0.65       210\n",
      "weighted avg       0.68      0.68      0.68       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1400.csv ---\n",
      "Test Subject: 1400.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1400.csv is: 0.6761904761904762 and f1 score is: 0.6072175156782924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77       136\n",
      "           1       0.56      0.36      0.44        74\n",
      "\n",
      "    accuracy                           0.68       210\n",
      "   macro avg       0.64      0.61      0.61       210\n",
      "weighted avg       0.66      0.68      0.66       210\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.48130841121495327 and f1 score is: 0.4771871904919116\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.64      0.52        95\n",
      "           1       0.55      0.35      0.43       119\n",
      "\n",
      "    accuracy                           0.48       214\n",
      "   macro avg       0.50      0.50      0.48       214\n",
      "weighted avg       0.50      0.48      0.47       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5373831775700935 and f1 score is: 0.48710872249255577\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.96      0.65        95\n",
      "           1       0.86      0.20      0.33       119\n",
      "\n",
      "    accuracy                           0.54       214\n",
      "   macro avg       0.67      0.58      0.49       214\n",
      "weighted avg       0.69      0.54      0.47       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.4766355140186916 and f1 score is: 0.4720239668693277\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.64      0.52        95\n",
      "           1       0.55      0.34      0.42       119\n",
      "\n",
      "    accuracy                           0.48       214\n",
      "   macro avg       0.49      0.49      0.47       214\n",
      "weighted avg       0.50      0.48      0.47       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5420560747663551 and f1 score is: 0.5362229102167183\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.74      0.59        95\n",
      "           1       0.65      0.39      0.48       119\n",
      "\n",
      "    accuracy                           0.54       214\n",
      "   macro avg       0.57      0.56      0.54       214\n",
      "weighted avg       0.58      0.54      0.53       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5046728971962616 and f1 score is: 0.4624134989098493\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.88      0.61        95\n",
      "           1       0.69      0.20      0.31       119\n",
      "\n",
      "    accuracy                           0.50       214\n",
      "   macro avg       0.58      0.54      0.46       214\n",
      "weighted avg       0.59      0.50      0.45       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5654205607476636 and f1 score is: 0.559407584512187\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.51      0.51        95\n",
      "           1       0.61      0.61      0.61       119\n",
      "\n",
      "    accuracy                           0.57       214\n",
      "   macro avg       0.56      0.56      0.56       214\n",
      "weighted avg       0.56      0.57      0.57       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1419.csv ---\n",
      "[18:55:38] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5514018691588785 and f1 score is: 0.5512450851900393\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.54        95\n",
      "           1       0.62      0.51      0.56       119\n",
      "\n",
      "    accuracy                           0.55       214\n",
      "   macro avg       0.56      0.56      0.55       214\n",
      "weighted avg       0.56      0.55      0.55       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1419.csv ---\n",
      "Test Subject: 1419.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1419.csv is: 0.5327102803738317 and f1 score is: 0.5285928275618997\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.71      0.57        95\n",
      "           1       0.63      0.39      0.48       119\n",
      "\n",
      "    accuracy                           0.53       214\n",
      "   macro avg       0.55      0.55      0.53       214\n",
      "weighted avg       0.56      0.53      0.52       214\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.43209876543209874 and f1 score is: 0.4320121951219512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.28      0.42       122\n",
      "           1       0.29      0.90      0.44        40\n",
      "\n",
      "    accuracy                           0.43       162\n",
      "   macro avg       0.59      0.59      0.43       162\n",
      "weighted avg       0.75      0.43      0.43       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.4691358024691358 and f1 score is: 0.4671052631578947\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.35      0.50       122\n",
      "           1       0.29      0.82      0.43        40\n",
      "\n",
      "    accuracy                           0.47       162\n",
      "   macro avg       0.58      0.59      0.47       162\n",
      "weighted avg       0.72      0.47      0.48       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.4444444444444444 and f1 score is: 0.44308632543926657\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.33      0.47       122\n",
      "           1       0.28      0.80      0.42        40\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.56      0.56      0.44       162\n",
      "weighted avg       0.70      0.44      0.46       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5925925925925926 and f1 score is: 0.49230769230769234\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       122\n",
      "           1       0.24      0.30      0.27        40\n",
      "\n",
      "    accuracy                           0.59       162\n",
      "   macro avg       0.49      0.49      0.49       162\n",
      "weighted avg       0.62      0.59      0.61       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5 and f1 score is: 0.49443267193219037\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.40      0.55       122\n",
      "           1       0.30      0.80      0.44        40\n",
      "\n",
      "    accuracy                           0.50       162\n",
      "   macro avg       0.58      0.60      0.49       162\n",
      "weighted avg       0.72      0.50      0.52       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.47530864197530864 and f1 score is: 0.4719079578139981\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.37      0.51       122\n",
      "           1       0.29      0.80      0.43        40\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.57      0.58      0.47       162\n",
      "weighted avg       0.71      0.48      0.49       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1517.csv ---\n",
      "[18:57:53] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5185185185185185 and f1 score is: 0.4963329081632653\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.48      0.60       122\n",
      "           1       0.28      0.62      0.39        40\n",
      "\n",
      "    accuracy                           0.52       162\n",
      "   macro avg       0.54      0.55      0.50       162\n",
      "weighted avg       0.67      0.52      0.55       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1517.csv ---\n",
      "Test Subject: 1517.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1517.csv is: 0.5061728395061729 and f1 score is: 0.4586466165413533\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.53      0.62       122\n",
      "           1       0.23      0.42      0.30        40\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.48      0.48      0.46       162\n",
      "weighted avg       0.61      0.51      0.54       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.5652173913043478 and f1 score is: 0.4866071428571429\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.40      0.29        10\n",
      "           1       0.79      0.61      0.69        36\n",
      "\n",
      "    accuracy                           0.57        46\n",
      "   macro avg       0.50      0.51      0.49        46\n",
      "weighted avg       0.66      0.57      0.60        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.7391304347826086 and f1 score is: 0.425\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.77      0.94      0.85        36\n",
      "\n",
      "    accuracy                           0.74        46\n",
      "   macro avg       0.39      0.47      0.42        46\n",
      "weighted avg       0.60      0.74      0.67        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.5652173913043478 and f1 score is: 0.5053763440860215\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.50      0.33        10\n",
      "           1       0.81      0.58      0.68        36\n",
      "\n",
      "    accuracy                           0.57        46\n",
      "   macro avg       0.53      0.54      0.51        46\n",
      "weighted avg       0.69      0.57      0.60        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.782608695652174 and f1 score is: 0.4390243902439025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        10\n",
      "           1       0.78      1.00      0.88        36\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.89      0.50      0.44        46\n",
      "weighted avg       0.83      0.78      0.69        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1544.csv ---\n",
      "[19:00:11] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.6956521739130435 and f1 score is: 0.5527777777777778\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.30      0.30        10\n",
      "           1       0.81      0.81      0.81        36\n",
      "\n",
      "    accuracy                           0.70        46\n",
      "   macro avg       0.55      0.55      0.55        46\n",
      "weighted avg       0.70      0.70      0.70        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1544.csv ---\n",
      "Test Subject: 1544.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1544.csv is: 0.5434782608695652 and f1 score is: 0.42328358208955225\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.20      0.16        10\n",
      "           1       0.74      0.64      0.69        36\n",
      "\n",
      "    accuracy                           0.54        46\n",
      "   macro avg       0.44      0.42      0.42        46\n",
      "weighted avg       0.61      0.54      0.57        46\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.6226415094339622 and f1 score is: 0.6114369501466277\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.49      0.55        73\n",
      "           1       0.63      0.73      0.68        86\n",
      "\n",
      "    accuracy                           0.62       159\n",
      "   macro avg       0.62      0.61      0.61       159\n",
      "weighted avg       0.62      0.62      0.62       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5660377358490566 and f1 score is: 0.49398090493980906\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.21      0.30        73\n",
      "           1       0.56      0.87      0.68        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.57      0.54      0.49       159\n",
      "weighted avg       0.57      0.57      0.51       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5974842767295597 and f1 score is: 0.5855327468230694\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.47      0.52        73\n",
      "           1       0.61      0.71      0.66        86\n",
      "\n",
      "    accuracy                           0.60       159\n",
      "   macro avg       0.59      0.59      0.59       159\n",
      "weighted avg       0.59      0.60      0.59       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5220125786163522 and f1 score is: 0.36533613445378155\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.03      0.05        73\n",
      "           1       0.53      0.94      0.68        86\n",
      "\n",
      "    accuracy                           0.52       159\n",
      "   macro avg       0.41      0.48      0.37       159\n",
      "weighted avg       0.42      0.52      0.39       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5471698113207547 and f1 score is: 0.4748623853211009\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.19      0.28        73\n",
      "           1       0.55      0.85      0.67        86\n",
      "\n",
      "    accuracy                           0.55       159\n",
      "   macro avg       0.54      0.52      0.47       159\n",
      "weighted avg       0.54      0.55      0.49       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5345911949685535 and f1 score is: 0.4412044072948328\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.14      0.21        73\n",
      "           1       0.54      0.87      0.67        86\n",
      "\n",
      "    accuracy                           0.53       159\n",
      "   macro avg       0.51      0.50      0.44       159\n",
      "weighted avg       0.51      0.53      0.46       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1624.csv ---\n",
      "[19:02:31] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5660377358490566 and f1 score is: 0.5654188948306595\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.55        73\n",
      "           1       0.61      0.56      0.58        86\n",
      "\n",
      "    accuracy                           0.57       159\n",
      "   macro avg       0.57      0.57      0.57       159\n",
      "weighted avg       0.57      0.57      0.57       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1624.csv ---\n",
      "Test Subject: 1624.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1624.csv is: 0.5031446540880503 and f1 score is: 0.5018836499187056\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.60      0.53        73\n",
      "           1       0.55      0.42      0.48        86\n",
      "\n",
      "    accuracy                           0.50       159\n",
      "   macro avg       0.51      0.51      0.50       159\n",
      "weighted avg       0.51      0.50      0.50       159\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6685082872928176 and f1 score is: 0.40066225165562913\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        60\n",
      "           1       0.67      1.00      0.80       121\n",
      "\n",
      "    accuracy                           0.67       181\n",
      "   macro avg       0.83      0.50      0.40       181\n",
      "weighted avg       0.78      0.67      0.54       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5966850828729282 and f1 score is: 0.4790853538340232\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.18      0.23        60\n",
      "           1       0.66      0.80      0.73       121\n",
      "\n",
      "    accuracy                           0.60       181\n",
      "   macro avg       0.49      0.49      0.48       181\n",
      "weighted avg       0.55      0.60      0.56       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6243093922651933 and f1 score is: 0.49722222222222223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.18      0.24        60\n",
      "           1       0.68      0.84      0.75       121\n",
      "\n",
      "    accuracy                           0.62       181\n",
      "   macro avg       0.52      0.51      0.50       181\n",
      "weighted avg       0.57      0.62      0.58       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6519337016574586 and f1 score is: 0.43596972844635706\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.05      0.09        60\n",
      "           1       0.67      0.95      0.78       121\n",
      "\n",
      "    accuracy                           0.65       181\n",
      "   macro avg       0.50      0.50      0.44       181\n",
      "weighted avg       0.56      0.65      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5580110497237569 and f1 score is: 0.47763347763347763\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.25      0.27        60\n",
      "           1       0.66      0.71      0.68       121\n",
      "\n",
      "    accuracy                           0.56       181\n",
      "   macro avg       0.48      0.48      0.48       181\n",
      "weighted avg       0.54      0.56      0.55       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5193370165745856 and f1 score is: 0.4643330952137973\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.30      0.29        60\n",
      "           1       0.64      0.63      0.64       121\n",
      "\n",
      "    accuracy                           0.52       181\n",
      "   macro avg       0.46      0.46      0.46       181\n",
      "weighted avg       0.53      0.52      0.52       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1688.csv ---\n",
      "[19:04:45] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.6574585635359116 and f1 score is: 0.4837136547662864\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.12      0.18        60\n",
      "           1       0.68      0.93      0.78       121\n",
      "\n",
      "    accuracy                           0.66       181\n",
      "   macro avg       0.56      0.52      0.48       181\n",
      "weighted avg       0.60      0.66      0.58       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1688.csv ---\n",
      "Test Subject: 1688.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1688.csv is: 0.5966850828729282 and f1 score is: 0.4477324973876698\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.12      0.16        60\n",
      "           1       0.66      0.83      0.73       121\n",
      "\n",
      "    accuracy                           0.60       181\n",
      "   macro avg       0.46      0.48      0.45       181\n",
      "weighted avg       0.52      0.60      0.54       181\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.7129629629629629 and f1 score is: 0.4944889023101314\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.16        34\n",
      "           1       0.70      1.00      0.83        74\n",
      "\n",
      "    accuracy                           0.71       108\n",
      "   macro avg       0.85      0.54      0.49       108\n",
      "weighted avg       0.80      0.71      0.62       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.3888888888888889 and f1 score is: 0.3880494505494505\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.68      0.41        34\n",
      "           1       0.63      0.26      0.37        74\n",
      "\n",
      "    accuracy                           0.39       108\n",
      "   macro avg       0.46      0.47      0.39       108\n",
      "weighted avg       0.53      0.39      0.38       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6944444444444444 and f1 score is: 0.5764705882352942\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.26      0.35        34\n",
      "           1       0.73      0.89      0.80        74\n",
      "\n",
      "    accuracy                           0.69       108\n",
      "   macro avg       0.63      0.58      0.58       108\n",
      "weighted avg       0.66      0.69      0.66       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.5092592592592593 and f1 score is: 0.49679120879120886\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.56      0.42        34\n",
      "           1       0.71      0.49      0.58        74\n",
      "\n",
      "    accuracy                           0.51       108\n",
      "   macro avg       0.52      0.52      0.50       108\n",
      "weighted avg       0.59      0.51      0.53       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.3888888888888889 and f1 score is: 0.3888888888888889\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.62      0.39        34\n",
      "           1       0.62      0.28      0.39        74\n",
      "\n",
      "    accuracy                           0.39       108\n",
      "   macro avg       0.45      0.45      0.39       108\n",
      "weighted avg       0.51      0.39      0.39       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6759259259259259 and f1 score is: 0.654320987654321\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.68      0.57        34\n",
      "           1       0.82      0.68      0.74        74\n",
      "\n",
      "    accuracy                           0.68       108\n",
      "   macro avg       0.65      0.68      0.65       108\n",
      "weighted avg       0.72      0.68      0.69       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1717.csv ---\n",
      "[19:07:01] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.7129629629629629 and f1 score is: 0.5649122807017544\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.21      0.31        34\n",
      "           1       0.72      0.95      0.82        74\n",
      "\n",
      "    accuracy                           0.71       108\n",
      "   macro avg       0.68      0.58      0.56       108\n",
      "weighted avg       0.69      0.71      0.66       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1717.csv ---\n",
      "Test Subject: 1717.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1717.csv is: 0.6759259259259259 and f1 score is: 0.562449357564533\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.26      0.34        34\n",
      "           1       0.72      0.86      0.79        74\n",
      "\n",
      "    accuracy                           0.68       108\n",
      "   macro avg       0.60      0.56      0.56       108\n",
      "weighted avg       0.64      0.68      0.64       108\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.5123456790123457 and f1 score is: 0.46752652381943\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.21      0.31        86\n",
      "           1       0.49      0.86      0.62        76\n",
      "\n",
      "    accuracy                           0.51       162\n",
      "   macro avg       0.55      0.53      0.47       162\n",
      "weighted avg       0.56      0.51      0.46       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.46296296296296297 and f1 score is: 0.3929971144321461\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.12      0.19        86\n",
      "           1       0.46      0.86      0.60        76\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.47      0.49      0.39       162\n",
      "weighted avg       0.47      0.46      0.38       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4382716049382716 and f1 score is: 0.3998290111142776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.17      0.25        86\n",
      "           1       0.44      0.74      0.55        76\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.43      0.46      0.40       162\n",
      "weighted avg       0.43      0.44      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4506172839506173 and f1 score is: 0.44958961633899597\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.38      0.43        86\n",
      "           1       0.43      0.53      0.47        76\n",
      "\n",
      "    accuracy                           0.45       162\n",
      "   macro avg       0.45      0.46      0.45       162\n",
      "weighted avg       0.46      0.45      0.45       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.46296296296296297 and f1 score is: 0.403882755995432\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.14      0.22        86\n",
      "           1       0.46      0.83      0.59        76\n",
      "\n",
      "    accuracy                           0.46       162\n",
      "   macro avg       0.47      0.48      0.40       162\n",
      "weighted avg       0.47      0.46      0.39       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4074074074074074 and f1 score is: 0.3647058823529412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.14      0.20        86\n",
      "           1       0.42      0.71      0.53        76\n",
      "\n",
      "    accuracy                           0.41       162\n",
      "   macro avg       0.39      0.43      0.36       162\n",
      "weighted avg       0.39      0.41      0.35       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1765.csv ---\n",
      "[19:09:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.4382716049382716 and f1 score is: 0.41395348837209295\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.22      0.29        86\n",
      "           1       0.44      0.68      0.53        76\n",
      "\n",
      "    accuracy                           0.44       162\n",
      "   macro avg       0.44      0.45      0.41       162\n",
      "weighted avg       0.44      0.44      0.41       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1765.csv ---\n",
      "Test Subject: 1765.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1765.csv is: 0.48148148148148145 and f1 score is: 0.45129032258064516\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.23      0.32        86\n",
      "           1       0.47      0.76      0.58        76\n",
      "\n",
      "    accuracy                           0.48       162\n",
      "   macro avg       0.50      0.50      0.45       162\n",
      "weighted avg       0.50      0.48      0.44       162\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7735849056603774 and f1 score is: 0.5340659340659342\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.38      0.20        16\n",
      "           1       0.94      0.81      0.87       196\n",
      "\n",
      "    accuracy                           0.77       212\n",
      "   macro avg       0.54      0.59      0.53       212\n",
      "weighted avg       0.88      0.77      0.82       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8726415094339622 and f1 score is: 0.5003055434308162\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.06      0.07        16\n",
      "           1       0.92      0.94      0.93       196\n",
      "\n",
      "    accuracy                           0.87       212\n",
      "   macro avg       0.50      0.50      0.50       212\n",
      "weighted avg       0.86      0.87      0.87       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.7264150943396226 and f1 score is: 0.5252509652509653\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.50      0.22        16\n",
      "           1       0.95      0.74      0.83       196\n",
      "\n",
      "    accuracy                           0.73       212\n",
      "   macro avg       0.54      0.62      0.53       212\n",
      "weighted avg       0.89      0.73      0.79       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.660377358490566 and f1 score is: 0.4557124518613607\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.31      0.12        16\n",
      "           1       0.92      0.69      0.79       196\n",
      "\n",
      "    accuracy                           0.66       212\n",
      "   macro avg       0.50      0.50      0.46       212\n",
      "weighted avg       0.86      0.66      0.74       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.8773584905660378 and f1 score is: 0.5843137254901961\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.25      0.24        16\n",
      "           1       0.94      0.93      0.93       196\n",
      "\n",
      "    accuracy                           0.88       212\n",
      "   macro avg       0.58      0.59      0.58       212\n",
      "weighted avg       0.88      0.88      0.88       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.4858490566037736 and f1 score is: 0.3873644582305999\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.56      0.14        16\n",
      "           1       0.93      0.48      0.63       196\n",
      "\n",
      "    accuracy                           0.49       212\n",
      "   macro avg       0.51      0.52      0.39       212\n",
      "weighted avg       0.87      0.49      0.60       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1818.csv ---\n",
      "[19:11:31] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.6415094339622641 and f1 score is: 0.4724986904138292\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.50      0.17        16\n",
      "           1       0.94      0.65      0.77       196\n",
      "\n",
      "    accuracy                           0.64       212\n",
      "   macro avg       0.52      0.58      0.47       212\n",
      "weighted avg       0.88      0.64      0.73       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1818.csv ---\n",
      "Test Subject: 1818.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1818.csv is: 0.5471698113207547 and f1 score is: 0.41758241758241765\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.50      0.14        16\n",
      "           1       0.93      0.55      0.69       196\n",
      "\n",
      "    accuracy                           0.55       212\n",
      "   macro avg       0.51      0.53      0.42       212\n",
      "weighted avg       0.87      0.55      0.65       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.49537037037037035 and f1 score is: 0.4630419412958697\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.49      0.59       162\n",
      "           1       0.25      0.50      0.33        54\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.50      0.50      0.46       216\n",
      "weighted avg       0.62      0.50      0.53       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.49537037037037035 and f1 score is: 0.4745463878411855\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.46      0.58       162\n",
      "           1       0.27      0.59      0.37        54\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.52      0.53      0.47       216\n",
      "weighted avg       0.65      0.50      0.53       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5046296296296297 and f1 score is: 0.4777539261100441\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.49      0.60       162\n",
      "           1       0.27      0.56      0.36        54\n",
      "\n",
      "    accuracy                           0.50       216\n",
      "   macro avg       0.52      0.52      0.48       216\n",
      "weighted avg       0.64      0.50      0.54       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5787037037037037 and f1 score is: 0.5015089650275164\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.65      0.70       162\n",
      "           1       0.26      0.37      0.31        54\n",
      "\n",
      "    accuracy                           0.58       216\n",
      "   macro avg       0.51      0.51      0.50       216\n",
      "weighted avg       0.63      0.58      0.60       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.4675925925925926 and f1 score is: 0.45149822244794313\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.43      0.55       162\n",
      "           1       0.26      0.59      0.36        54\n",
      "\n",
      "    accuracy                           0.47       216\n",
      "   macro avg       0.51      0.51      0.45       216\n",
      "weighted avg       0.63      0.47      0.50       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.39351851851851855 and f1 score is: 0.3919415493714409\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.30      0.42       162\n",
      "           1       0.25      0.69      0.36        54\n",
      "\n",
      "    accuracy                           0.39       216\n",
      "   macro avg       0.49      0.49      0.39       216\n",
      "weighted avg       0.62      0.39      0.41       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1892.csv ---\n",
      "[19:13:43] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5324074074074074 and f1 score is: 0.4999885402580733\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.52      0.63       162\n",
      "           1       0.28      0.56      0.37        54\n",
      "\n",
      "    accuracy                           0.53       216\n",
      "   macro avg       0.53      0.54      0.50       216\n",
      "weighted avg       0.65      0.53      0.56       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1892.csv ---\n",
      "Test Subject: 1892.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1892.csv is: 0.5879629629629629 and f1 score is: 0.5205387205387205\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.64      0.70       162\n",
      "           1       0.28      0.43      0.34        54\n",
      "\n",
      "    accuracy                           0.59       216\n",
      "   macro avg       0.53      0.53      0.52       216\n",
      "weighted avg       0.65      0.59      0.61       216\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5283018867924528 and f1 score is: 0.5005183300348695\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.48      0.38        65\n",
      "           1       0.70      0.55      0.62       147\n",
      "\n",
      "    accuracy                           0.53       212\n",
      "   macro avg       0.51      0.51      0.50       212\n",
      "weighted avg       0.59      0.53      0.55       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5707547169811321 and f1 score is: 0.5093466263129784\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.35      0.34        65\n",
      "           1       0.70      0.67      0.68       147\n",
      "\n",
      "    accuracy                           0.57       212\n",
      "   macro avg       0.51      0.51      0.51       212\n",
      "weighted avg       0.58      0.57      0.58       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.4858490566037736 and f1 score is: 0.4807541064647327\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.63      0.43        65\n",
      "           1       0.72      0.42      0.53       147\n",
      "\n",
      "    accuracy                           0.49       212\n",
      "   macro avg       0.52      0.53      0.48       212\n",
      "weighted avg       0.60      0.49      0.50       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5330188679245284 and f1 score is: 0.48120133481646277\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.35      0.32        65\n",
      "           1       0.68      0.61      0.65       147\n",
      "\n",
      "    accuracy                           0.53       212\n",
      "   macro avg       0.48      0.48      0.48       212\n",
      "weighted avg       0.56      0.53      0.54       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.5707547169811321 and f1 score is: 0.4973816533361124\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.31      0.31        65\n",
      "           1       0.69      0.69      0.69       147\n",
      "\n",
      "    accuracy                           0.57       212\n",
      "   macro avg       0.50      0.50      0.50       212\n",
      "weighted avg       0.57      0.57      0.57       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.45754716981132076 and f1 score is: 0.4531547899423547\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.60      0.40        65\n",
      "           1       0.69      0.39      0.50       147\n",
      "\n",
      "    accuracy                           0.46       212\n",
      "   macro avg       0.50      0.50      0.45       212\n",
      "weighted avg       0.57      0.46      0.47       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1929.csv ---\n",
      "[19:15:55] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.4858490566037736 and f1 score is: 0.48168584438014495\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.65      0.44        65\n",
      "           1       0.73      0.41      0.53       147\n",
      "\n",
      "    accuracy                           0.49       212\n",
      "   macro avg       0.53      0.53      0.48       212\n",
      "weighted avg       0.60      0.49      0.50       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1929.csv ---\n",
      "Test Subject: 1929.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1929.csv is: 0.4669811320754717 and f1 score is: 0.4635315194267159\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.63      0.42        65\n",
      "           1       0.71      0.39      0.51       147\n",
      "\n",
      "    accuracy                           0.47       212\n",
      "   macro avg       0.51      0.51      0.46       212\n",
      "weighted avg       0.59      0.47      0.48       212\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5306122448979592 and f1 score is: 0.5006645990252548\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.39      0.38        36\n",
      "           1       0.63      0.61      0.62        62\n",
      "\n",
      "    accuracy                           0.53        98\n",
      "   macro avg       0.50      0.50      0.50        98\n",
      "weighted avg       0.54      0.53      0.53        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6224489795918368 and f1 score is: 0.6107353730542135\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.61      0.54        36\n",
      "           1       0.74      0.63      0.68        62\n",
      "\n",
      "    accuracy                           0.62        98\n",
      "   macro avg       0.61      0.62      0.61        98\n",
      "weighted avg       0.65      0.62      0.63        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5510204081632653 and f1 score is: 0.5493311036789297\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.67      0.52        36\n",
      "           1       0.71      0.48      0.58        62\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.57      0.58      0.55        98\n",
      "weighted avg       0.61      0.55      0.56        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5510204081632653 and f1 score is: 0.5510204081632653\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.75      0.55        36\n",
      "           1       0.75      0.44      0.55        62\n",
      "\n",
      "    accuracy                           0.55        98\n",
      "   macro avg       0.59      0.59      0.55        98\n",
      "weighted avg       0.63      0.55      0.55        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6428571428571429 and f1 score is: 0.6342893698688559\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.67      0.58        36\n",
      "           1       0.76      0.63      0.69        62\n",
      "\n",
      "    accuracy                           0.64        98\n",
      "   macro avg       0.64      0.65      0.63        98\n",
      "weighted avg       0.67      0.64      0.65        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.6020408163265306 and f1 score is: 0.5271557590003711\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.28      0.34        36\n",
      "           1       0.65      0.79      0.72        62\n",
      "\n",
      "    accuracy                           0.60        98\n",
      "   macro avg       0.54      0.53      0.53        98\n",
      "weighted avg       0.57      0.60      0.58        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for subject: 1933.csv ---\n",
      "[19:18:12] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5714285714285714 and f1 score is: 0.5528031290743155\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46        36\n",
      "           1       0.68      0.61      0.64        62\n",
      "\n",
      "    accuracy                           0.57        98\n",
      "   macro avg       0.55      0.56      0.55        98\n",
      "weighted avg       0.59      0.57      0.58        98\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for subject: 1933.csv ---\n",
      "Test Subject: 1933.csv\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1933.csv is: 0.5918367346938775 and f1 score is: 0.5806589644843817\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.58      0.51        36\n",
      "           1       0.71      0.60      0.65        62\n",
      "\n",
      "    accuracy                           0.59        98\n",
      "   macro avg       0.58      0.59      0.58        98\n",
      "weighted avg       0.62      0.59      0.60        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, mods in cols_run.items():\n",
    "    print(f\"----- Running Modality Combination {name}\")\n",
    "    losoValidation1('MatbII', 'ECG_EDA_Features_Combined_scld', 'ECG_EDA_Base2_Features_Combined', mods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG_EEG\n",
      "ECG_GAZE\n",
      "EDA_EEG\n",
      "EDA_GAZE\n",
      "EEG_GAZE\n",
      "ECG_EDA_EEG\n",
      "ECG_EDA_GAZE\n",
      "ECG_EEG_GAZE\n",
      "EDA_EEG_GAZE\n"
     ]
    }
   ],
   "source": [
    "for key, value in cols_run.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_kfold_data(dr_feat_path):\n",
    "    subjects = os.listdir(dr_feat_path)\n",
    "    xtrainDriv = pd.DataFrame()\n",
    "\n",
    "    for subTrain in subjects:\n",
    "        # if subTrain != sdriv:\n",
    "        train = pd.read_csv(os.path.join(dr_feat_path, '{}'.format(subTrain)))\n",
    "\n",
    "        train[['scrAmpDF_min','scrRecoveryTime_min', 'scrRiseTime_min']].fillna(0)\n",
    "        if np.isinf(train).values.sum():\n",
    "            cinf = np.isinf(train).values.sum()\n",
    "            print(\"Train Dataframe contains {} values\".format(cinf))\n",
    "        train.replace([np.inf], 9999, inplace=True)        \n",
    "        train.replace([-np.inf], -9999, inplace=True)        \n",
    "\n",
    "        train['scrNumPeaks'] = train['scrNumPeaks'].values.astype(int)\n",
    "        train['scrNumPeaks'] = train['scrNumPeaks'].values.clip(min=0) # converting negatives to zero\n",
    "\n",
    "        train.dropna(inplace=True)\n",
    "        xtrainDriv = xtrainDriv.append(train)\n",
    "        xtrainDriv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return xtrainDriv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldValidation1(dataset, folder, basefolder, paramsSELECTCOLS):\n",
    "    dr_feat_path = r'X:\\All Modes\\All\\{}\\Combine'.format(dataset) # ECG_EDA_Features_Combined_scld\n",
    "    bs_feat_path = r'X:\\All Modes\\All\\{}\\Combine'.format(dataset) # ECG_EDA_Base2_Features_Combined\n",
    "    date_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "    print(\"Saved Directory: {}\".format(date_time))\n",
    "    savePath_0 = f\"X:/All Modes/Data Files/{date_time}\"\n",
    "    utils.mk_dirs(savePath_0)\n",
    "    savePath1 = os.path.join(savePath_0, f'{dataset}')\n",
    "    utils.mk_dirs(savePath1)\n",
    "    savePath = os.path.join(savePath1, 'ECG EDA')\n",
    "    utils.mk_dirs(savePath)\n",
    "\n",
    "    mycls = {}\n",
    "\n",
    "    if dataset == 'MatbII':\n",
    "        parameter_list = funcs_for_matbii\n",
    "\n",
    "    results_df = pd.DataFrame(columns=['dataset', 'method', 'test_subject', 'test_acc', 'test_f1', 'wgt_test_f1'])\n",
    "    XtrainDriv = mk_kfold_data(dr_feat_path)\n",
    "    XtrainDriv = XtrainDriv[paramsSELECTCOLS].copy()\n",
    "    ytrainDriv = list(XtrainDriv['scaled label'].copy())\n",
    "\n",
    "    XtrainDriv.drop(columns=['label', 'complexity', 'scaled label'], inplace=True)\n",
    "    ytrain = ytrainDriv #+ ytrainBase\n",
    "\n",
    "    X = XtrainDriv.values\n",
    "    X, ytrain = shuffle(X, ytrain, random_state=42)\n",
    "\n",
    "    for idx, val in enumerate(ytrain):\n",
    "        if val <= 4:\n",
    "            ytrain[idx] = 0\n",
    "        else: ytrain[idx] = 1\n",
    "\n",
    "\n",
    "    tenFoldSplit = KFold(n_splits=10)\n",
    "    counter = 1\n",
    "\n",
    "    for train_index, test_index in tenFoldSplit.split(X):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = np.asarray(ytrain)[train_index], np.asarray(ytrain)[test_index]\n",
    "        print(counter)\n",
    "\n",
    "        # training different classifier for all subjects and saving them in different dictionnaries\n",
    "        mycls = {}\n",
    "        for cls_modl, cls_parameters in parameter_list:\n",
    "            print(\"--------------------------------------------\")\n",
    "            print(f\"---- Training classifier {cls_modl.__name__} for fold: {counter} ---\")\n",
    "\n",
    "            classifier_save_path = os.path.join(savePath, str(counter), cls_modl.__name__)\n",
    "            utils.mk_dirs(classifier_save_path)\n",
    "\n",
    "            classifier_report = os.path.join(classifier_save_path, 'report')\n",
    "            classifier_sav = os.path.join(classifier_save_path, 'classifier')\n",
    "            utils.mk_dirs(classifier_report)\n",
    "            utils.mk_dirs(classifier_sav)\n",
    "\n",
    "            if cls_modl.__name__ in ['LogisticRegression', 'SVC', 'LGBMClassifier', 'XGBClassifier']:\n",
    "                scaler = StandardScaler()\n",
    "                X_train = scaler.fit_transform(X_train)\n",
    "                X_test = scaler.transform(X_test)\n",
    "            clf = cls_modl(**cls_parameters)\n",
    "            hist = clf.fit(X_train, y_train)\n",
    "\n",
    "            yPred = hist.predict(X_test)\n",
    "\n",
    "            test_accuray = accuracy_score(y_test, yPred)\n",
    "            test_f1 = f1_score(y_test, yPred, average='macro')\n",
    "            wgt_test_f1 = f1_score(y_test, yPred, average='weighted')\n",
    "\n",
    "            results_df = results_df.append({'dataset': folder,\n",
    "                                            'method':cls_modl.__name__,\n",
    "                                            'test_subject': counter,\n",
    "                                            'test_acc': test_accuray,\n",
    "                                            'test_f1':test_f1, 'wgt_test_f1': wgt_test_f1}, ignore_index=True)\n",
    "            print('Test Subject: {}'.format(counter))\n",
    "\n",
    "            mycls[counter] = classification_report(y_test, yPred, zero_division=1, output_dict=True)\n",
    "            print(\"----- Classification Report ------\")\n",
    "            print(f\"Test accuracy for {counter} is: {test_accuray} and f1 score is: {test_f1}\\n\")\n",
    "\n",
    "            print(classification_report(y_test, yPred, zero_division=1))\n",
    "            with open(os.path.join(classifier_report, 'Test_fold_{}_report.pickle'.format(counter)), 'wb') as handle:\n",
    "                pickle.dump(mycls, handle, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            with open(os.path.join(classifier_sav, 'Test_fold_{}_report.sav'.format(counter)), 'wb') as handle:\n",
    "                pickle.dump(hist, handle, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        counter += 1\n",
    "    results_df.to_csv(os.path.join(savePath, 'results.csv'), index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_run_ALL = {\"ECG\": config2.SELECTECG, \"EDA\": config2.SELECTEDA, \"EEG\": config2.SELECTEEG, \"GAZE\": config2.SELECTGAZE,\n",
    "            \"ECG_EEG\": config2.SELECT_ECG_EEG, \"ECG_GAZE\": config2.SELECT_ECG_GAZE,\n",
    "            \"EDA_EEG\": config2.SELECT_EDA_EEG, \"EDA_GAZE\": config2.SELECT_EDA_GAZE,\n",
    "            \"EEG_GAZE\": config2.SELECT_EEG_GAZE,\n",
    "            \"ECG_EDA_EEG\": config2.SELECT_ECG_EDA_EEG, \"ECG_EDA_GAZE\": config2.SELECT_ECG_EDA_GAZE,\n",
    "            \"ECG_EEG_GAZE\": config2.SELECT_ECG_EEG_GAZE, \"EDA_EEG_GAZE\": config2.SELECT_EDA_EEG_GAZE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Running Modality Combination ECG\n",
      "Saved Directory: 2022_08_12_00_03\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6949152542372882 and f1 score is: 0.68890607424072\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65       131\n",
      "           1       0.72      0.75      0.73       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.69      0.69      0.69       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6203389830508474 and f1 score is: 0.6009661835748792\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.45      0.51       131\n",
      "           1       0.63      0.76      0.69       164\n",
      "\n",
      "    accuracy                           0.62       295\n",
      "   macro avg       0.61      0.60      0.60       295\n",
      "weighted avg       0.62      0.62      0.61       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.688135593220339 and f1 score is: 0.6813656429041044\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63       131\n",
      "           1       0.71      0.75      0.73       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.68      0.68      0.68       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6271186440677966 and f1 score is: 0.623968665986836\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59       131\n",
      "           1       0.67      0.65      0.66       164\n",
      "\n",
      "    accuracy                           0.63       295\n",
      "   macro avg       0.62      0.62      0.62       295\n",
      "weighted avg       0.63      0.63      0.63       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6067796610169491 and f1 score is: 0.5892154038221453\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.45      0.50       131\n",
      "           1       0.62      0.73      0.67       164\n",
      "\n",
      "    accuracy                           0.61       295\n",
      "   macro avg       0.60      0.59      0.59       295\n",
      "weighted avg       0.60      0.61      0.60       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6474576271186441 and f1 score is: 0.6456620160768733\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62       131\n",
      "           1       0.70      0.65      0.67       164\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.65      0.65      0.65       295\n",
      "weighted avg       0.65      0.65      0.65       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[00:04:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6711864406779661 and f1 score is: 0.6614611061816031\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60       131\n",
      "           1       0.69      0.76      0.72       164\n",
      "\n",
      "    accuracy                           0.67       295\n",
      "   macro avg       0.67      0.66      0.66       295\n",
      "weighted avg       0.67      0.67      0.67       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6610169491525424 and f1 score is: 0.659887474635676\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       131\n",
      "           1       0.72      0.65      0.68       164\n",
      "\n",
      "    accuracy                           0.66       295\n",
      "   macro avg       0.66      0.66      0.66       295\n",
      "weighted avg       0.67      0.66      0.66       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7040816326530612 and f1 score is: 0.7019263264616424\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68       141\n",
      "           1       0.70      0.76      0.73       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6054421768707483 and f1 score is: 0.5870786516853933\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.41      0.50       141\n",
      "           1       0.59      0.78      0.67       153\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.61      0.60      0.59       294\n",
      "weighted avg       0.61      0.61      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6564625850340136 and f1 score is: 0.6535405509468304\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.59      0.62       141\n",
      "           1       0.65      0.72      0.69       153\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6224489795918368 and f1 score is: 0.6220948410630536\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61       141\n",
      "           1       0.64      0.63      0.63       153\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.62      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.608843537414966 and f1 score is: 0.5900178253119429\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.41      0.50       141\n",
      "           1       0.59      0.79      0.68       153\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.62      0.60      0.59       294\n",
      "weighted avg       0.62      0.61      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6700680272108843 and f1 score is: 0.6697585548028487\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       141\n",
      "           1       0.69      0.67      0.68       153\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[00:04:51] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6598639455782312 and f1 score is: 0.6540850903614457\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.55      0.61       141\n",
      "           1       0.65      0.76      0.70       153\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6598639455782312 and f1 score is: 0.6598009719972229\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.66       141\n",
      "           1       0.68      0.65      0.66       153\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7006802721088435 and f1 score is: 0.6867493219682295\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.56      0.62       128\n",
      "           1       0.71      0.81      0.75       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.68      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6428571428571429 and f1 score is: 0.6085815360036517\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.40      0.49       128\n",
      "           1       0.64      0.83      0.72       166\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.61      0.61       294\n",
      "weighted avg       0.64      0.64      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6768707482993197 and f1 score is: 0.6651520782630589\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60       128\n",
      "           1       0.69      0.77      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.66      0.67       294\n",
      "weighted avg       0.67      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6326530612244898 and f1 score is: 0.6234345351043643\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.56       128\n",
      "           1       0.67      0.70      0.68       166\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6360544217687075 and f1 score is: 0.6061596244131455\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.41      0.50       128\n",
      "           1       0.64      0.81      0.71       166\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.61      0.61       294\n",
      "weighted avg       0.63      0.64      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6700680272108843 and f1 score is: 0.6658582023972723\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       128\n",
      "           1       0.71      0.69      0.70       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[00:05:25] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6598639455782312 and f1 score is: 0.6381627529168512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.48      0.55       128\n",
      "           1       0.67      0.80      0.73       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.64      0.64       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6802721088435374 and f1 score is: 0.671516188846099\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.62       128\n",
      "           1       0.70      0.75      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6564625850340136 and f1 score is: 0.6440037884691467\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.55      0.58       126\n",
      "           1       0.69      0.74      0.71       168\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.608843537414966 and f1 score is: 0.5816163641088465\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.41      0.47       126\n",
      "           1       0.63      0.76      0.69       168\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.58      0.58       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6564625850340136 and f1 score is: 0.6430451873489849\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57       126\n",
      "           1       0.68      0.74      0.71       168\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.608843537414966 and f1 score is: 0.5846182197923705\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.43      0.48       126\n",
      "           1       0.63      0.74      0.68       168\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.59      0.58       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.608843537414966 and f1 score is: 0.5831432552060858\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.42      0.48       126\n",
      "           1       0.63      0.75      0.69       168\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.59      0.58       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6258503401360545 and f1 score is: 0.6207786116322702\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.60      0.58       126\n",
      "           1       0.68      0.65      0.66       168\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[00:05:59] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6700680272108843 and f1 score is: 0.6496344984335647\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.50      0.57       126\n",
      "           1       0.68      0.80      0.73       168\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.67      0.67      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6598639455782312 and f1 score is: 0.6546863988724454\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.61       126\n",
      "           1       0.71      0.68      0.70       168\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.66      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6462585034013606 and f1 score is: 0.6430205949656751\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       137\n",
      "           1       0.66      0.69      0.68       157\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.5884353741496599 and f1 score is: 0.5613942076516207\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.36      0.45       137\n",
      "           1       0.59      0.78      0.67       157\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.59      0.57      0.56       294\n",
      "weighted avg       0.59      0.59      0.57       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6530612244897959 and f1 score is: 0.645112426035503\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.54      0.59       137\n",
      "           1       0.65      0.75      0.70       157\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6054421768707483 and f1 score is: 0.601290684624018\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56       137\n",
      "           1       0.62      0.66      0.64       157\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.5850340136054422 and f1 score is: 0.5569664031620554\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.36      0.45       137\n",
      "           1       0.58      0.78      0.67       157\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.59      0.57      0.56       294\n",
      "weighted avg       0.59      0.59      0.56       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6122448979591837 and f1 score is: 0.6113636363636363\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.59       137\n",
      "           1       0.64      0.62      0.63       157\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.61      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[00:06:32] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6564625850340136 and f1 score is: 0.6482212033976615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.54      0.59       137\n",
      "           1       0.65      0.76      0.70       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6530612244897959 and f1 score is: 0.651448230973081\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       137\n",
      "           1       0.68      0.68      0.68       157\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6972789115646258 and f1 score is: 0.6906616856018064\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65       128\n",
      "           1       0.73      0.75      0.74       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.5918367346938775 and f1 score is: 0.5701754385964912\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.42      0.47       128\n",
      "           1       0.62      0.72      0.67       166\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.58      0.57      0.57       294\n",
      "weighted avg       0.58      0.59      0.58       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6632653061224489 and f1 score is: 0.6481170283503597\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.52      0.58       128\n",
      "           1       0.68      0.77      0.72       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.5918367346938775 and f1 score is: 0.5786557110782018\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.48      0.50       128\n",
      "           1       0.63      0.68      0.65       166\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.58      0.58      0.58       294\n",
      "weighted avg       0.59      0.59      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6122448979591837 and f1 score is: 0.5976470588235294\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.48      0.52       128\n",
      "           1       0.64      0.71      0.67       166\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.61      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6156462585034014 and f1 score is: 0.6113249488154432\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.59      0.57       128\n",
      "           1       0.67      0.64      0.65       166\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.62      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[00:07:08] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6598639455782312 and f1 score is: 0.6440333204184424\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.52      0.57       128\n",
      "           1       0.67      0.77      0.72       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6598639455782312 and f1 score is: 0.6552532833020638\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.62      0.62       128\n",
      "           1       0.70      0.69      0.70       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6938775510204082 and f1 score is: 0.6719563600297546\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.58      0.59       111\n",
      "           1       0.75      0.77      0.76       183\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6258503401360545 and f1 score is: 0.5723353610156043\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.36      0.42       111\n",
      "           1       0.67      0.79      0.72       183\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.59      0.57      0.57       294\n",
      "weighted avg       0.61      0.63      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6972789115646258 and f1 score is: 0.6773891279421012\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.60       111\n",
      "           1       0.76      0.76      0.76       183\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6190476190476191 and f1 score is: 0.5885851366884902\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.46      0.48       111\n",
      "           1       0.69      0.72      0.70       183\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.59      0.59      0.59       294\n",
      "weighted avg       0.61      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6224489795918368 and f1 score is: 0.5719289040466977\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.37      0.42       111\n",
      "           1       0.67      0.78      0.72       183\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.58      0.57      0.57       294\n",
      "weighted avg       0.61      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6666666666666666 and f1 score is: 0.6521802115022455\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.61      0.58       111\n",
      "           1       0.75      0.70      0.72       183\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.65      0.66      0.65       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[00:07:44] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7244897959183674 and f1 score is: 0.6980486134885313\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.57      0.61       111\n",
      "           1       0.76      0.82      0.79       183\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.69      0.70       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6768707482993197 and f1 score is: 0.6633114339099512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.63      0.60       111\n",
      "           1       0.76      0.70      0.73       183\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.66      0.67      0.66       294\n",
      "weighted avg       0.69      0.68      0.68       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6666666666666666 and f1 score is: 0.6541176470588236\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.59       127\n",
      "           1       0.69      0.75      0.72       167\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.67      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.5816326530612245 and f1 score is: 0.541481227889992\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.33      0.41       127\n",
      "           1       0.60      0.77      0.68       167\n",
      "\n",
      "    accuracy                           0.58       294\n",
      "   macro avg       0.56      0.55      0.54       294\n",
      "weighted avg       0.57      0.58      0.56       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6462585034013606 and f1 score is: 0.6319337442218799\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.52      0.56       127\n",
      "           1       0.67      0.74      0.70       167\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6326530612244898 and f1 score is: 0.6315618472963564\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.67      0.61       127\n",
      "           1       0.71      0.60      0.65       167\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.64      0.63       294\n",
      "weighted avg       0.64      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6054421768707483 and f1 score is: 0.5771881973716837\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.40      0.47       127\n",
      "           1       0.63      0.76      0.69       167\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.59      0.58      0.58       294\n",
      "weighted avg       0.60      0.61      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6564625850340136 and f1 score is: 0.6530872130381447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62       127\n",
      "           1       0.71      0.66      0.69       167\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.66      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[00:08:18] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6326530612244898 and f1 score is: 0.6177773497688752\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.54       127\n",
      "           1       0.66      0.73      0.69       167\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6700680272108843 and f1 score is: 0.6653248993674525\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63       127\n",
      "           1       0.72      0.69      0.71       167\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6904761904761905 and f1 score is: 0.6837102628063414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.61      0.64       131\n",
      "           1       0.71      0.75      0.73       163\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.5578231292517006 and f1 score is: 0.5279150197628458\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.34      0.41       131\n",
      "           1       0.58      0.73      0.65       163\n",
      "\n",
      "    accuracy                           0.56       294\n",
      "   macro avg       0.54      0.54      0.53       294\n",
      "weighted avg       0.55      0.56      0.54       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6632653061224489 and f1 score is: 0.6544338513778243\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60       131\n",
      "           1       0.68      0.74      0.71       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6292517006802721 and f1 score is: 0.603445075546646\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.42      0.50       131\n",
      "           1       0.63      0.80      0.70       163\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.61      0.60       294\n",
      "weighted avg       0.63      0.63      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.5612244897959183 and f1 score is: 0.5356473829201102\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.37      0.43       131\n",
      "           1       0.58      0.72      0.64       163\n",
      "\n",
      "    accuracy                           0.56       294\n",
      "   macro avg       0.55      0.54      0.54       294\n",
      "weighted avg       0.55      0.56      0.55       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6326530612244898 and f1 score is: 0.6309451857362034\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.61       131\n",
      "           1       0.68      0.63      0.66       163\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.64      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[00:08:52] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6836734693877551 and f1 score is: 0.6713188358757979\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.55      0.61       131\n",
      "           1       0.69      0.79      0.74       163\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6870748299319728 and f1 score is: 0.6846082089552239\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.66       131\n",
      "           1       0.73      0.70      0.71       163\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.69      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6768707482993197 and f1 score is: 0.6732377888271425\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.61      0.64       138\n",
      "           1       0.68      0.74      0.71       156\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6258503401360545 and f1 score is: 0.610699152542373\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.46      0.53       138\n",
      "           1       0.62      0.78      0.69       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.62      0.61       294\n",
      "weighted avg       0.63      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6564625850340136 and f1 score is: 0.6489531488290163\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.54      0.60       138\n",
      "           1       0.65      0.76      0.70       156\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6496598639455783 and f1 score is: 0.6496558107248221\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.70      0.65       138\n",
      "           1       0.69      0.61      0.65       156\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6258503401360545 and f1 score is: 0.6127873563218391\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.54       138\n",
      "           1       0.62      0.76      0.68       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.62      0.61       294\n",
      "weighted avg       0.63      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6224489795918368 and f1 score is: 0.6224446115578179\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.67      0.62       138\n",
      "           1       0.66      0.58      0.62       156\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.63      0.62      0.62       294\n",
      "weighted avg       0.63      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[00:09:27] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6496598639455783 and f1 score is: 0.6433845610316198\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.55      0.60       138\n",
      "           1       0.65      0.74      0.69       156\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6632653061224489 and f1 score is: 0.6615384615384615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64       138\n",
      "           1       0.68      0.69      0.69       156\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "----- Running Modality Combination EDA\n",
      "Saved Directory: 2022_08_12_00_09\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7084745762711865 and f1 score is: 0.6971686401833461\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.58      0.64       131\n",
      "           1       0.71      0.81      0.76       164\n",
      "\n",
      "    accuracy                           0.71       295\n",
      "   macro avg       0.71      0.70      0.70       295\n",
      "weighted avg       0.71      0.71      0.70       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6508474576271186 and f1 score is: 0.6312544750670501\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.47      0.55       131\n",
      "           1       0.65      0.79      0.72       164\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.65      0.63      0.63       295\n",
      "weighted avg       0.65      0.65      0.64       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6711864406779661 and f1 score is: 0.6622443077867353\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61       131\n",
      "           1       0.69      0.75      0.72       164\n",
      "\n",
      "    accuracy                           0.67       295\n",
      "   macro avg       0.67      0.66      0.66       295\n",
      "weighted avg       0.67      0.67      0.67       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6 and f1 score is: 0.5960967232897059\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.56      0.56       131\n",
      "           1       0.64      0.63      0.64       164\n",
      "\n",
      "    accuracy                           0.60       295\n",
      "   macro avg       0.60      0.60      0.60       295\n",
      "weighted avg       0.60      0.60      0.60       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6576271186440678 and f1 score is: 0.6384145823473016\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.48      0.56       131\n",
      "           1       0.66      0.80      0.72       164\n",
      "\n",
      "    accuracy                           0.66       295\n",
      "   macro avg       0.66      0.64      0.64       295\n",
      "weighted avg       0.66      0.66      0.65       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6474576271186441 and f1 score is: 0.6429901321913982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       131\n",
      "           1       0.68      0.68      0.68       164\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.64      0.64      0.64       295\n",
      "weighted avg       0.65      0.65      0.65       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[00:10:03] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6813559322033899 and f1 score is: 0.6689982811306341\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.55      0.61       131\n",
      "           1       0.69      0.79      0.73       164\n",
      "\n",
      "    accuracy                           0.68       295\n",
      "   macro avg       0.68      0.67      0.67       295\n",
      "weighted avg       0.68      0.68      0.68       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6847457627118644 and f1 score is: 0.6814513788098694\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65       131\n",
      "           1       0.72      0.71      0.71       164\n",
      "\n",
      "    accuracy                           0.68       295\n",
      "   macro avg       0.68      0.68      0.68       295\n",
      "weighted avg       0.69      0.68      0.69       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7482993197278912 and f1 score is: 0.7430555555555556\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.63      0.71       141\n",
      "           1       0.72      0.86      0.78       153\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.76      0.74      0.74       294\n",
      "weighted avg       0.76      0.75      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6122448979591837 and f1 score is: 0.5976470588235294\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.44      0.52       141\n",
      "           1       0.60      0.77      0.67       153\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.62      0.61      0.60       294\n",
      "weighted avg       0.62      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.717687074829932 and f1 score is: 0.714084853597666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68       141\n",
      "           1       0.70      0.80      0.75       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6122448979591837 and f1 score is: 0.6063424947145879\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.51      0.56       141\n",
      "           1       0.61      0.71      0.65       153\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.61      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6122448979591837 and f1 score is: 0.5976470588235294\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.44      0.52       141\n",
      "           1       0.60      0.77      0.67       153\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.62      0.61      0.60       294\n",
      "weighted avg       0.62      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7006802721088435 and f1 score is: 0.6995540691192865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68       141\n",
      "           1       0.70      0.73      0.72       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[00:10:38] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6938775510204082 and f1 score is: 0.686863905325444\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.57      0.64       141\n",
      "           1       0.67      0.81      0.73       153\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7006802721088435 and f1 score is: 0.6989947877885332\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.68       141\n",
      "           1       0.70      0.75      0.72       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7244897959183674 and f1 score is: 0.7137293086660175\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.61      0.66       128\n",
      "           1       0.73      0.81      0.77       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6258503401360545 and f1 score is: 0.5990577733697\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.42      0.50       128\n",
      "           1       0.64      0.78      0.70       166\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.60      0.60       294\n",
      "weighted avg       0.62      0.63      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.673469387755102 and f1 score is: 0.6572261355355843\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.52      0.58       128\n",
      "           1       0.68      0.79      0.73       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.5816326530612245 and f1 score is: 0.5706602395906302\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.48      0.50       128\n",
      "           1       0.62      0.66      0.64       166\n",
      "\n",
      "    accuracy                           0.58       294\n",
      "   macro avg       0.57      0.57      0.57       294\n",
      "weighted avg       0.58      0.58      0.58       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6258503401360545 and f1 score is: 0.5990577733697\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.42      0.50       128\n",
      "           1       0.64      0.78      0.70       166\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.60      0.60       294\n",
      "weighted avg       0.62      0.63      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6054421768707483 and f1 score is: 0.5980008486963082\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.54       128\n",
      "           1       0.65      0.66      0.65       166\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.60      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[00:11:13] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6632653061224489 and f1 score is: 0.6424104674734321\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.48      0.56       128\n",
      "           1       0.67      0.80      0.73       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.64      0.64       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6836734693877551 and f1 score is: 0.6760848704552724\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.63       128\n",
      "           1       0.71      0.74      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7278911564625851 and f1 score is: 0.7160654787773433\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66       126\n",
      "           1       0.74      0.82      0.77       168\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.72      0.71      0.72       294\n",
      "weighted avg       0.73      0.73      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.5986394557823129 and f1 score is: 0.5786737915958222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.44      0.49       126\n",
      "           1       0.63      0.71      0.67       168\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.59      0.58      0.58       294\n",
      "weighted avg       0.59      0.60      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6768707482993197 and f1 score is: 0.6691189536908697\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62       126\n",
      "           1       0.71      0.73      0.72       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.5680272108843537 and f1 score is: 0.5594596189015397\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50       126\n",
      "           1       0.62      0.62      0.62       168\n",
      "\n",
      "    accuracy                           0.57       294\n",
      "   macro avg       0.56      0.56      0.56       294\n",
      "weighted avg       0.57      0.57      0.57       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.608843537414966 and f1 score is: 0.5887411660240114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.45      0.50       126\n",
      "           1       0.64      0.73      0.68       168\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.59      0.59       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6632653061224489 and f1 score is: 0.6501135994806881\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.58       126\n",
      "           1       0.69      0.75      0.72       168\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[00:11:48] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6802721088435374 and f1 score is: 0.668235294117647\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.61       126\n",
      "           1       0.70      0.76      0.73       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7346938775510204 and f1 score is: 0.7301863704819278\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.70       126\n",
      "           1       0.77      0.76      0.77       168\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.73      0.74       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.717687074829932 and f1 score is: 0.7145130155016086\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68       137\n",
      "           1       0.72      0.77      0.74       157\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6496598639455783 and f1 score is: 0.6387904813025587\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.51      0.58       137\n",
      "           1       0.64      0.77      0.70       157\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6598639455782312 and f1 score is: 0.6571828358208955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.63       137\n",
      "           1       0.67      0.70      0.69       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.5578231292517006 and f1 score is: 0.5531705948372614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.71      0.60       137\n",
      "           1       0.63      0.43      0.51       157\n",
      "\n",
      "    accuracy                           0.56       294\n",
      "   macro avg       0.57      0.57      0.55       294\n",
      "weighted avg       0.58      0.56      0.55       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6496598639455783 and f1 score is: 0.6369543585378428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57       137\n",
      "           1       0.64      0.78      0.70       157\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6666666666666666 and f1 score is: 0.6651169277976661\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       137\n",
      "           1       0.69      0.69      0.69       157\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[00:12:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6904761904761905 and f1 score is: 0.6849319908143439\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64       137\n",
      "           1       0.69      0.77      0.73       157\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6870748299319728 and f1 score is: 0.6853127326880118\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66       137\n",
      "           1       0.70      0.71      0.71       157\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6768707482993197 and f1 score is: 0.6683961200090233\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.62       128\n",
      "           1       0.70      0.74      0.72       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6122448979591837 and f1 score is: 0.5889423076923077\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.43      0.49       128\n",
      "           1       0.63      0.75      0.69       166\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.59      0.59       294\n",
      "weighted avg       0.61      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6768707482993197 and f1 score is: 0.6660169562461884\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61       128\n",
      "           1       0.70      0.76      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.66      0.67       294\n",
      "weighted avg       0.67      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.5612244897959183 and f1 score is: 0.48196309297783124\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.20      0.28       128\n",
      "           1       0.58      0.84      0.68       166\n",
      "\n",
      "    accuracy                           0.56       294\n",
      "   macro avg       0.53      0.52      0.48       294\n",
      "weighted avg       0.54      0.56      0.51       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.608843537414966 and f1 score is: 0.5846182197923706\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.42      0.48       128\n",
      "           1       0.63      0.75      0.68       166\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.59      0.58       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6292517006802721 and f1 score is: 0.621898413072975\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57       128\n",
      "           1       0.67      0.68      0.67       166\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[00:12:58] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6802721088435374 and f1 score is: 0.6663769375633783\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60       128\n",
      "           1       0.69      0.78      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6768707482993197 and f1 score is: 0.6727477239973285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.64       128\n",
      "           1       0.72      0.70      0.71       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7380952380952381 and f1 score is: 0.7103448275862069\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.57      0.62       111\n",
      "           1       0.76      0.84      0.80       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.72      0.70      0.71       294\n",
      "weighted avg       0.73      0.74      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6428571428571429 and f1 score is: 0.6150632832470853\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.50      0.51       111\n",
      "           1       0.71      0.73      0.72       183\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.62      0.61      0.62       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7040816326530612 and f1 score is: 0.6770903031144664\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.58       111\n",
      "           1       0.74      0.80      0.77       183\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.68      0.67      0.68       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.5884353741496599 and f1 score is: 0.5735094891561066\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.53      0.49       111\n",
      "           1       0.69      0.62      0.65       183\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.57      0.58      0.57       294\n",
      "weighted avg       0.60      0.59      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6428571428571429 and f1 score is: 0.6150632832470853\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.50      0.51       111\n",
      "           1       0.71      0.73      0.72       183\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.62      0.61      0.62       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6564625850340136 and f1 score is: 0.6430451873489849\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.61      0.57       111\n",
      "           1       0.74      0.68      0.71       183\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.64      0.65      0.64       294\n",
      "weighted avg       0.67      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[00:13:33] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7040816326530612 and f1 score is: 0.6742278545500859\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.53      0.58       111\n",
      "           1       0.74      0.81      0.77       183\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7108843537414966 and f1 score is: 0.6907599212978432\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61       111\n",
      "           1       0.76      0.78      0.77       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.717687074829932 and f1 score is: 0.7031784067825473\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.57      0.64       127\n",
      "           1       0.72      0.83      0.77       167\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.70      0.70       294\n",
      "weighted avg       0.72      0.72      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.673469387755102 and f1 score is: 0.6561403508771929\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58       127\n",
      "           1       0.68      0.79      0.73       167\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6870748299319728 and f1 score is: 0.6769693784932881\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62       127\n",
      "           1       0.71      0.76      0.73       167\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6836734693877551 and f1 score is: 0.6773995634475842\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       127\n",
      "           1       0.72      0.72      0.72       167\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6666666666666666 and f1 score is: 0.6466346153846154\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.50      0.56       127\n",
      "           1       0.68      0.80      0.73       167\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.67      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.673469387755102 and f1 score is: 0.6666666666666666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.62       127\n",
      "           1       0.71      0.72      0.71       167\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[00:14:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.717687074829932 and f1 score is: 0.7031784067825473\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.57      0.64       127\n",
      "           1       0.72      0.83      0.77       167\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.70      0.70       294\n",
      "weighted avg       0.72      0.72      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7312925170068028 and f1 score is: 0.7254187995791315\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.69       127\n",
      "           1       0.76      0.77      0.77       167\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.717687074829932 and f1 score is: 0.7126302773361597\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67       131\n",
      "           1       0.74      0.77      0.75       163\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6564625850340136 and f1 score is: 0.6420468928937376\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.51      0.57       131\n",
      "           1       0.66      0.77      0.71       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6904761904761905 and f1 score is: 0.6849319908143436\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64       131\n",
      "           1       0.71      0.74      0.73       163\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6598639455782312 and f1 score is: 0.6440333204184425\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.50      0.57       131\n",
      "           1       0.66      0.79      0.72       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.64      0.64       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6564625850340136 and f1 score is: 0.6410082814483467\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.50      0.57       131\n",
      "           1       0.66      0.78      0.72       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6530612244897959 and f1 score is: 0.6517558528428093\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.63       131\n",
      "           1       0.70      0.64      0.67       163\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[00:14:42] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7040816326530612 and f1 score is: 0.6956268221574344\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64       131\n",
      "           1       0.71      0.79      0.75       163\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7278911564625851 and f1 score is: 0.7257462686567164\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70       131\n",
      "           1       0.76      0.74      0.75       163\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7210884353741497 and f1 score is: 0.7140891840607211\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67       138\n",
      "           1       0.70      0.83      0.76       156\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.73      0.71      0.71       294\n",
      "weighted avg       0.73      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6292517006802721 and f1 score is: 0.6177491501162999\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.49      0.55       138\n",
      "           1       0.62      0.76      0.68       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6768707482993197 and f1 score is: 0.6741223003955336\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64       138\n",
      "           1       0.68      0.72      0.70       156\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6428571428571429 and f1 score is: 0.6402559112468099\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       138\n",
      "           1       0.66      0.69      0.67       156\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6190476190476191 and f1 score is: 0.6047058823529412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.46      0.53       138\n",
      "           1       0.61      0.76      0.68       156\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.62      0.61      0.60       294\n",
      "weighted avg       0.62      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6632653061224489 and f1 score is: 0.6604011340963982\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63       138\n",
      "           1       0.67      0.71      0.69       156\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[00:15:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.717687074829932 and f1 score is: 0.7152857992929399\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       138\n",
      "           1       0.72      0.76      0.74       156\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6802721088435374 and f1 score is: 0.6777518656716417\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65       138\n",
      "           1       0.69      0.72      0.71       156\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "----- Running Modality Combination EEG\n",
      "Saved Directory: 2022_08_12_00_15\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7423728813559322 and f1 score is: 0.7382553469692725\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.71       131\n",
      "           1       0.76      0.78      0.77       164\n",
      "\n",
      "    accuracy                           0.74       295\n",
      "   macro avg       0.74      0.74      0.74       295\n",
      "weighted avg       0.74      0.74      0.74       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6372881355932203 and f1 score is: 0.6274241333317596\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.57       131\n",
      "           1       0.66      0.72      0.69       164\n",
      "\n",
      "    accuracy                           0.64       295\n",
      "   macro avg       0.63      0.63      0.63       295\n",
      "weighted avg       0.63      0.64      0.63       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7016949152542373 and f1 score is: 0.6939256744010565\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.65       131\n",
      "           1       0.71      0.77      0.74       164\n",
      "\n",
      "    accuracy                           0.70       295\n",
      "   macro avg       0.70      0.69      0.69       295\n",
      "weighted avg       0.70      0.70      0.70       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6033898305084746 and f1 score is: 0.6002848903866866\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.58      0.57       131\n",
      "           1       0.65      0.62      0.64       164\n",
      "\n",
      "    accuracy                           0.60       295\n",
      "   macro avg       0.60      0.60      0.60       295\n",
      "weighted avg       0.61      0.60      0.60       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6508474576271186 and f1 score is: 0.6449562402869795\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.59      0.60       131\n",
      "           1       0.68      0.70      0.69       164\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.65      0.64      0.64       295\n",
      "weighted avg       0.65      0.65      0.65       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6847457627118644 and f1 score is: 0.6818798483319999\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65       131\n",
      "           1       0.72      0.70      0.71       164\n",
      "\n",
      "    accuracy                           0.68       295\n",
      "   macro avg       0.68      0.68      0.68       295\n",
      "weighted avg       0.69      0.68      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[00:16:31] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7322033898305085 and f1 score is: 0.7285982135578613\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.70       131\n",
      "           1       0.76      0.76      0.76       164\n",
      "\n",
      "    accuracy                           0.73       295\n",
      "   macro avg       0.73      0.73      0.73       295\n",
      "weighted avg       0.73      0.73      0.73       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7050847457627119 and f1 score is: 0.7031197584703119\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68       131\n",
      "           1       0.75      0.71      0.73       164\n",
      "\n",
      "    accuracy                           0.71       295\n",
      "   macro avg       0.70      0.70      0.70       295\n",
      "weighted avg       0.71      0.71      0.71       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6972789115646258 and f1 score is: 0.6924071614139444\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.60      0.65       141\n",
      "           1       0.68      0.79      0.73       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6122448979591837 and f1 score is: 0.6063424947145879\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.51      0.56       141\n",
      "           1       0.61      0.71      0.65       153\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.61      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6904761904761905 and f1 score is: 0.6849319908143436\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.58      0.64       141\n",
      "           1       0.67      0.79      0.73       153\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.70      0.69      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6530612244897959 and f1 score is: 0.6529166666666667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66       141\n",
      "           1       0.69      0.61      0.65       153\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6190476190476191 and f1 score is: 0.6118628883964354\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.50      0.56       141\n",
      "           1       0.61      0.73      0.66       153\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.62      0.61      0.61       294\n",
      "weighted avg       0.62      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6904761904761905 and f1 score is: 0.6885701980048191\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66       141\n",
      "           1       0.69      0.74      0.71       153\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[00:18:14] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6802721088435374 and f1 score is: 0.6742420670470084\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.57      0.63       141\n",
      "           1       0.66      0.78      0.72       153\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.69      0.68      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7074829931972789 and f1 score is: 0.7066140635878393\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69       141\n",
      "           1       0.71      0.73      0.72       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7006802721088435 and f1 score is: 0.6885593220338984\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.58      0.63       128\n",
      "           1       0.71      0.80      0.75       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6326530612244898 and f1 score is: 0.6118906761844229\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.46      0.52       128\n",
      "           1       0.65      0.77      0.70       166\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.61      0.61       294\n",
      "weighted avg       0.63      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6836734693877551 and f1 score is: 0.6730481782199529\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.58      0.61       128\n",
      "           1       0.70      0.77      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6428571428571429 and f1 score is: 0.6278705322162619\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.51      0.55       128\n",
      "           1       0.66      0.75      0.70       166\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6666666666666666 and f1 score is: 0.6427969253657326\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.47      0.55       128\n",
      "           1       0.67      0.82      0.74       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.64      0.64       294\n",
      "weighted avg       0.67      0.67      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7108843537414966 and f1 score is: 0.7051501386348888\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66       128\n",
      "           1       0.74      0.75      0.75       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[00:19:55] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6870748299319728 and f1 score is: 0.6752941176470589\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.57      0.61       128\n",
      "           1       0.70      0.78      0.74       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.67      0.68       294\n",
      "weighted avg       0.68      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6836734693877551 and f1 score is: 0.6760848704552724\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.63       128\n",
      "           1       0.71      0.74      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7006802721088435 and f1 score is: 0.6867493219682292\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.57      0.62       126\n",
      "           1       0.71      0.80      0.75       168\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.68      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.608843537414966 and f1 score is: 0.5912470531342562\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.47      0.51       126\n",
      "           1       0.64      0.71      0.68       168\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.59      0.59       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6836734693877551 and f1 score is: 0.6684491978609625\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60       126\n",
      "           1       0.70      0.79      0.74       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6054421768707483 and f1 score is: 0.6054239170677527\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.70      0.60       126\n",
      "           1       0.70      0.54      0.61       168\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.62      0.62      0.61       294\n",
      "weighted avg       0.63      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6224489795918368 and f1 score is: 0.6066059912000481\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.49      0.53       126\n",
      "           1       0.65      0.72      0.69       168\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.62      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6666666666666666 and f1 score is: 0.6621482176360225\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62       126\n",
      "           1       0.72      0.68      0.70       168\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[00:21:38] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6972789115646258 and f1 score is: 0.6836607628604243\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62       126\n",
      "           1       0.71      0.79      0.75       168\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.70      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6870748299319728 and f1 score is: 0.6777544796035074\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62       126\n",
      "           1       0.72      0.75      0.73       168\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7040816326530612 and f1 score is: 0.7019263264616424\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.68       137\n",
      "           1       0.72      0.74      0.73       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6292517006802721 and f1 score is: 0.6239217941345601\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.55      0.58       137\n",
      "           1       0.64      0.70      0.67       157\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7108843537414966 and f1 score is: 0.7084252161433722\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68       137\n",
      "           1       0.72      0.75      0.74       157\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6360544217687075 and f1 score is: 0.6359491268472763\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.63       137\n",
      "           1       0.68      0.61      0.64       157\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.608843537414966 and f1 score is: 0.6059945694607918\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57       137\n",
      "           1       0.63      0.65      0.64       157\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.61      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7312925170068028 and f1 score is: 0.7312645353882467\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.73       137\n",
      "           1       0.78      0.69      0.73       157\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[00:23:19] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6564625850340136 and f1 score is: 0.6526001754899093\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.62       137\n",
      "           1       0.67      0.71      0.69       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6972789115646258 and f1 score is: 0.6964888471308766\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68       137\n",
      "           1       0.72      0.70      0.71       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7210884353741497 and f1 score is: 0.7127811666031263\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66       128\n",
      "           1       0.74      0.79      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6598639455782312 and f1 score is: 0.6460901386748844\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.53      0.58       128\n",
      "           1       0.68      0.76      0.72       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6666666666666666 and f1 score is: 0.6575381543289118\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.58      0.60       128\n",
      "           1       0.69      0.73      0.71       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.67      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6190476190476191 and f1 score is: 0.6155606407322654\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.60      0.58       128\n",
      "           1       0.67      0.63      0.65       166\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.62      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6326530612244898 and f1 score is: 0.6198275862068965\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.52      0.55       128\n",
      "           1       0.66      0.72      0.69       166\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7006802721088435 and f1 score is: 0.6979405034324944\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67       128\n",
      "           1       0.75      0.70      0.73       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[00:25:01] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7244897959183674 and f1 score is: 0.7184673767836666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.68       128\n",
      "           1       0.75      0.77      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7210884353741497 and f1 score is: 0.7173076923076922\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.68       128\n",
      "           1       0.76      0.74      0.75       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7448979591836735 and f1 score is: 0.7271411070275087\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       111\n",
      "           1       0.79      0.80      0.80       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7142857142857143 and f1 score is: 0.6971153846153846\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.62       111\n",
      "           1       0.77      0.77      0.77       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7312925170068028 and f1 score is: 0.7136375405328763\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64       111\n",
      "           1       0.78      0.79      0.78       183\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6802721088435374 and f1 score is: 0.656063321385902\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.56       111\n",
      "           1       0.74      0.76      0.75       183\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.66      0.65      0.66       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7244897959183674 and f1 score is: 0.7063878580147213\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63       111\n",
      "           1       0.78      0.78      0.78       183\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7278911564625851 and f1 score is: 0.7125116119884614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.65       111\n",
      "           1       0.79      0.77      0.78       183\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[00:26:42] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7380952380952381 and f1 score is: 0.7154135291085774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.64       111\n",
      "           1       0.77      0.82      0.80       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.72      0.71      0.72       294\n",
      "weighted avg       0.73      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7006802721088435 and f1 score is: 0.6837627731873075\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61       111\n",
      "           1       0.77      0.75      0.76       183\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.68      0.69      0.68       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7414965986394558 and f1 score is: 0.7350094876660342\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69       127\n",
      "           1       0.76      0.79      0.78       167\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6870748299319728 and f1 score is: 0.6761494252873563\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.58      0.62       127\n",
      "           1       0.71      0.77      0.74       167\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.67      0.68       294\n",
      "weighted avg       0.68      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7074829931972789 and f1 score is: 0.7001423149905123\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65       127\n",
      "           1       0.73      0.76      0.75       167\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6632653061224489 and f1 score is: 0.6599567731760032\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.63       127\n",
      "           1       0.72      0.67      0.69       167\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.67      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7074829931972789 and f1 score is: 0.6956375192604005\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.64       127\n",
      "           1       0.72      0.80      0.76       167\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.69      0.70       294\n",
      "weighted avg       0.71      0.71      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7006802721088435 and f1 score is: 0.6983208955223881\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.71      0.67       127\n",
      "           1       0.76      0.69      0.72       167\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[00:28:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7210884353741497 and f1 score is: 0.7127811666031261\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66       127\n",
      "           1       0.74      0.78      0.76       167\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7346938775510204 and f1 score is: 0.7301863704819277\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70       127\n",
      "           1       0.77      0.76      0.77       167\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.73      0.73       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7278911564625851 and f1 score is: 0.7227592059974538\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.69       131\n",
      "           1       0.74      0.78      0.76       163\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6700680272108843 and f1 score is: 0.6598318124888174\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60       131\n",
      "           1       0.68      0.76      0.72       163\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6972789115646258 and f1 score is: 0.6924071614139442\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65       131\n",
      "           1       0.72      0.74      0.73       163\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.5782312925170068 and f1 score is: 0.5762703984378632\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.57      0.55       131\n",
      "           1       0.63      0.58      0.61       163\n",
      "\n",
      "    accuracy                           0.58       294\n",
      "   macro avg       0.58      0.58      0.58       294\n",
      "weighted avg       0.58      0.58      0.58       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6666666666666666 and f1 score is: 0.6559021640471983\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.55      0.60       131\n",
      "           1       0.68      0.76      0.72       163\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.67      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6700680272108843 and f1 score is: 0.6663585843813981\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       131\n",
      "           1       0.70      0.70      0.70       163\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[00:30:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7210884353741497 and f1 score is: 0.7158281861473903\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68       131\n",
      "           1       0.74      0.77      0.75       163\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7006802721088435 and f1 score is: 0.6975308641975309\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.67       131\n",
      "           1       0.73      0.72      0.73       163\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7040816326530612 and f1 score is: 0.6963206572714213\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.58      0.65       138\n",
      "           1       0.69      0.81      0.74       156\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.5782312925170068 and f1 score is: 0.5623529411764706\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.41      0.48       138\n",
      "           1       0.58      0.72      0.65       156\n",
      "\n",
      "    accuracy                           0.58       294\n",
      "   macro avg       0.58      0.57      0.56       294\n",
      "weighted avg       0.58      0.58      0.57       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6462585034013606 and f1 score is: 0.6434701492537314\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       138\n",
      "           1       0.66      0.69      0.68       156\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.5714285714285714 and f1 score is: 0.5633457494459899\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.46      0.50       138\n",
      "           1       0.58      0.67      0.62       156\n",
      "\n",
      "    accuracy                           0.57       294\n",
      "   macro avg       0.57      0.57      0.56       294\n",
      "weighted avg       0.57      0.57      0.57       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.5850340136054422 and f1 score is: 0.5716333062628386\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.43      0.50       138\n",
      "           1       0.59      0.72      0.65       156\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.58      0.58      0.57       294\n",
      "weighted avg       0.58      0.59      0.58       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6258503401360545 and f1 score is: 0.6224256292906178\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59       138\n",
      "           1       0.64      0.68      0.66       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.62      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[00:31:47] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6326530612244898 and f1 score is: 0.6234345351043644\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.51      0.56       138\n",
      "           1       0.63      0.74      0.68       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.63      0.62       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6564625850340136 and f1 score is: 0.6535405509468305\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62       138\n",
      "           1       0.67      0.71      0.69       156\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "----- Running Modality Combination GAZE\n",
      "Saved Directory: 2022_08_12_00_32\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6915254237288135 and f1 score is: 0.6838379912612327\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63       131\n",
      "           1       0.71      0.76      0.73       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.69      0.68      0.68       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6101694915254238 and f1 score is: 0.582456399463378\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.40      0.47       131\n",
      "           1       0.62      0.78      0.69       164\n",
      "\n",
      "    accuracy                           0.61       295\n",
      "   macro avg       0.60      0.59      0.58       295\n",
      "weighted avg       0.61      0.61      0.59       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6915254237288135 and f1 score is: 0.6838379912612327\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63       131\n",
      "           1       0.71      0.76      0.73       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.69      0.68      0.68       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.5966101694915255 and f1 score is: 0.5739736168250386\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.41      0.48       131\n",
      "           1       0.61      0.74      0.67       164\n",
      "\n",
      "    accuracy                           0.60       295\n",
      "   macro avg       0.59      0.58      0.57       295\n",
      "weighted avg       0.59      0.60      0.58       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6237288135593221 and f1 score is: 0.5984622742155024\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.42      0.50       131\n",
      "           1       0.63      0.79      0.70       164\n",
      "\n",
      "    accuracy                           0.62       295\n",
      "   macro avg       0.62      0.60      0.60       295\n",
      "weighted avg       0.62      0.62      0.61       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6677966101694915 and f1 score is: 0.6657648908620053\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64       131\n",
      "           1       0.71      0.67      0.69       164\n",
      "\n",
      "    accuracy                           0.67       295\n",
      "   macro avg       0.67      0.67      0.67       295\n",
      "weighted avg       0.67      0.67      0.67       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[00:32:46] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6915254237288135 and f1 score is: 0.6816332823377331\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.58      0.63       131\n",
      "           1       0.70      0.78      0.74       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.69      0.68      0.68       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.688135593220339 and f1 score is: 0.6846532812790482\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65       131\n",
      "           1       0.72      0.71      0.72       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.68      0.68      0.68       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7244897959183674 and f1 score is: 0.7209743751977222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69       141\n",
      "           1       0.71      0.80      0.75       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6156462585034014 and f1 score is: 0.5983558000362692\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.43      0.52       141\n",
      "           1       0.60      0.79      0.68       153\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.63      0.61      0.60       294\n",
      "weighted avg       0.62      0.62      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6428571428571429 and f1 score is: 0.6377228292121909\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.55      0.59       141\n",
      "           1       0.64      0.73      0.68       153\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6156462585034014 and f1 score is: 0.6113249488154431\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.53      0.57       141\n",
      "           1       0.62      0.69      0.65       153\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.62      0.61      0.61       294\n",
      "weighted avg       0.62      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.608843537414966 and f1 score is: 0.5912470531342562\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.42      0.51       141\n",
      "           1       0.59      0.78      0.68       153\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.62      0.60      0.59       294\n",
      "weighted avg       0.62      0.61      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6768707482993197 and f1 score is: 0.6768670098918261\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.68       141\n",
      "           1       0.70      0.65      0.68       153\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[00:33:12] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6938775510204082 and f1 score is: 0.6906565656565657\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66       141\n",
      "           1       0.68      0.76      0.72       153\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7074829931972789 and f1 score is: 0.7068181818181818\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69       141\n",
      "           1       0.72      0.73      0.72       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6938775510204082 and f1 score is: 0.6765755634870191\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.53      0.60       128\n",
      "           1       0.69      0.82      0.75       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6156462585034014 and f1 score is: 0.5857347714944822\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.40      0.47       128\n",
      "           1       0.63      0.78      0.70       166\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.59      0.59       294\n",
      "weighted avg       0.61      0.62      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6870748299319728 and f1 score is: 0.6744029275808937\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61       128\n",
      "           1       0.70      0.78      0.74       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6156462585034014 and f1 score is: 0.6006347145587652\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.48      0.52       128\n",
      "           1       0.64      0.72      0.68       166\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.60      0.60       294\n",
      "weighted avg       0.61      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.608843537414966 and f1 score is: 0.5800365185636032\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.40      0.47       128\n",
      "           1       0.62      0.77      0.69       166\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.58      0.58       294\n",
      "weighted avg       0.60      0.61      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6462585034013606 and f1 score is: 0.6388888888888888\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.58      0.59       128\n",
      "           1       0.68      0.70      0.69       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[00:33:37] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6802721088435374 and f1 score is: 0.6673247303543914\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60       128\n",
      "           1       0.69      0.78      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.673469387755102 and f1 score is: 0.6629245688625615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60       128\n",
      "           1       0.69      0.75      0.72       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6938775510204082 and f1 score is: 0.6854942233632864\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63       126\n",
      "           1       0.72      0.75      0.74       168\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6462585034013606 and f1 score is: 0.6236892630335253\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.47      0.53       126\n",
      "           1       0.66      0.78      0.72       168\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.62      0.62       294\n",
      "weighted avg       0.64      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6870748299319728 and f1 score is: 0.6785052061046927\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.63       126\n",
      "           1       0.72      0.74      0.73       168\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6394557823129252 and f1 score is: 0.6021752450980393\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.39      0.48       126\n",
      "           1       0.64      0.83      0.72       168\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.61      0.60       294\n",
      "weighted avg       0.64      0.64      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6462585034013606 and f1 score is: 0.625\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.48      0.54       126\n",
      "           1       0.66      0.77      0.71       168\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.62      0.62       294\n",
      "weighted avg       0.64      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6768707482993197 and f1 score is: 0.6732377888271425\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.67      0.64       126\n",
      "           1       0.73      0.68      0.71       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.68      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[00:34:03] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6666666666666666 and f1 score is: 0.6500850133592422\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.52      0.57       126\n",
      "           1       0.68      0.77      0.73       168\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.67      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6836734693877551 and f1 score is: 0.6780074191838898\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64       126\n",
      "           1       0.73      0.71      0.72       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6496598639455783 and f1 score is: 0.6457209710441649\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.58      0.61       137\n",
      "           1       0.66      0.71      0.68       157\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.5952380952380952 and f1 score is: 0.581642292561015\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.45      0.51       137\n",
      "           1       0.60      0.73      0.66       157\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.59      0.59      0.58       294\n",
      "weighted avg       0.59      0.60      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6360544217687075 and f1 score is: 0.6329588014981273\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60       137\n",
      "           1       0.65      0.68      0.67       157\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6156462585034014 and f1 score is: 0.609460777975008\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.56       137\n",
      "           1       0.63      0.69      0.66       157\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.61      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.5952380952380952 and f1 score is: 0.5805589190874105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.44      0.50       137\n",
      "           1       0.60      0.73      0.66       157\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.59      0.59      0.58       294\n",
      "weighted avg       0.59      0.60      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6394557823129252 and f1 score is: 0.6393890303170562\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.67      0.63       137\n",
      "           1       0.68      0.61      0.64       157\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[00:34:31] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6632653061224489 and f1 score is: 0.658424381828637\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62       137\n",
      "           1       0.67      0.73      0.70       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6632653061224489 and f1 score is: 0.6627932572554016\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65       137\n",
      "           1       0.70      0.66      0.68       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.67      0.66      0.66       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7278911564625851 and f1 score is: 0.7176470588235295\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.66       128\n",
      "           1       0.73      0.81      0.77       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6598639455782312 and f1 score is: 0.6368577075098815\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.47      0.55       128\n",
      "           1       0.66      0.81      0.73       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.64      0.64       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6938775510204082 and f1 score is: 0.6861954459203037\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64       128\n",
      "           1       0.72      0.75      0.74       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6292517006802721 and f1 score is: 0.6147715388221717\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.54       128\n",
      "           1       0.65      0.73      0.69       166\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.61      0.61       294\n",
      "weighted avg       0.62      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6530612244897959 and f1 score is: 0.6322115384615384\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.48      0.54       128\n",
      "           1       0.66      0.79      0.72       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.63      0.63       294\n",
      "weighted avg       0.65      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6938775510204082 and f1 score is: 0.6924543214468362\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.72      0.67       128\n",
      "           1       0.76      0.67      0.71       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.70      0.69       294\n",
      "weighted avg       0.70      0.69      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[00:34:57] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7074829931972789 and f1 score is: 0.7001423149905124\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65       128\n",
      "           1       0.73      0.77      0.75       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6972789115646258 and f1 score is: 0.6924071614139443\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65       128\n",
      "           1       0.73      0.73      0.73       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.717687074829932 and f1 score is: 0.7002027151544934\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63       111\n",
      "           1       0.77      0.77      0.77       183\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6496598639455783 and f1 score is: 0.6223954111852359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.50      0.52       111\n",
      "           1       0.71      0.74      0.72       183\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6802721088435374 and f1 score is: 0.6653913211933359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.59       111\n",
      "           1       0.76      0.72      0.74       183\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.66      0.67      0.67       294\n",
      "weighted avg       0.69      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6530612244897959 and f1 score is: 0.6322115384615385\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.55      0.54       111\n",
      "           1       0.72      0.72      0.72       183\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6530612244897959 and f1 score is: 0.6282172080337218\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53       111\n",
      "           1       0.72      0.73      0.72       183\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.673469387755102 and f1 score is: 0.6611764705882353\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.64      0.60       111\n",
      "           1       0.76      0.69      0.73       183\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.67      0.66       294\n",
      "weighted avg       0.68      0.67      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[00:35:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7108843537414966 and f1 score is: 0.6950467985405202\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63       111\n",
      "           1       0.78      0.75      0.76       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.69      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.717687074829932 and f1 score is: 0.7049870035664632\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       111\n",
      "           1       0.79      0.74      0.77       183\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.70      0.71      0.70       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7108843537414966 and f1 score is: 0.6950467985405201\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.56      0.63       127\n",
      "           1       0.71      0.83      0.76       167\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.69      0.70       294\n",
      "weighted avg       0.71      0.71      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6190476190476191 and f1 score is: 0.5815584811670818\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.37      0.46       127\n",
      "           1       0.63      0.81      0.71       167\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.59      0.58       294\n",
      "weighted avg       0.61      0.62      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6598639455782312 and f1 score is: 0.650549137070318\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59       127\n",
      "           1       0.69      0.72      0.71       167\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.5986394557823129 and f1 score is: 0.5823863636363636\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.46      0.50       127\n",
      "           1       0.63      0.70      0.66       167\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.59      0.58      0.58       294\n",
      "weighted avg       0.59      0.60      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6360544217687075 and f1 score is: 0.602858188887907\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.40      0.49       127\n",
      "           1       0.64      0.81      0.72       167\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.61      0.60       294\n",
      "weighted avg       0.63      0.64      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6156462585034014 and f1 score is: 0.6113249488154431\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.59      0.57       127\n",
      "           1       0.67      0.63      0.65       167\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.62      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[00:35:49] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6598639455782312 and f1 score is: 0.6406395149855767\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.50      0.56       127\n",
      "           1       0.67      0.78      0.72       167\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.673469387755102 and f1 score is: 0.6673110471969447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       127\n",
      "           1       0.71      0.71      0.71       167\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6904761904761905 and f1 score is: 0.6765520159584114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.54      0.61       131\n",
      "           1       0.69      0.81      0.74       163\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6190476190476191 and f1 score is: 0.6024916702882804\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.47      0.52       131\n",
      "           1       0.63      0.74      0.68       163\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.60      0.60       294\n",
      "weighted avg       0.62      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6530612244897959 and f1 score is: 0.6427277926038886\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.54      0.58       131\n",
      "           1       0.67      0.74      0.70       163\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.5986394557823129 and f1 score is: 0.562962962962963\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.35      0.44       131\n",
      "           1       0.60      0.80      0.69       163\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.59      0.57      0.56       294\n",
      "weighted avg       0.59      0.60      0.58       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.608843537414966 and f1 score is: 0.5924296305225725\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.46      0.51       131\n",
      "           1       0.63      0.73      0.67       163\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.59      0.59       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6360544217687075 and f1 score is: 0.6353414399480681\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.66      0.62       131\n",
      "           1       0.69      0.61      0.65       163\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[00:36:15] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6496598639455783 and f1 score is: 0.6387904813025587\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.58       131\n",
      "           1       0.66      0.74      0.70       163\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6598639455782312 and f1 score is: 0.6552532833020638\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.62       131\n",
      "           1       0.69      0.70      0.70       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6700680272108843 and f1 score is: 0.6635242758539318\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.57      0.62       138\n",
      "           1       0.66      0.76      0.71       156\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.608843537414966 and f1 score is: 0.5957047365085439\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.46      0.52       138\n",
      "           1       0.61      0.74      0.67       156\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.61      0.60      0.60       294\n",
      "weighted avg       0.61      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6530612244897959 and f1 score is: 0.6483583489681051\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61       138\n",
      "           1       0.66      0.72      0.69       156\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.5918367346938775 and f1 score is: 0.5715326694194801\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.40      0.48       138\n",
      "           1       0.59      0.76      0.66       156\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.59      0.58      0.57       294\n",
      "weighted avg       0.59      0.59      0.58       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6156462585034014 and f1 score is: 0.6037215959921275\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.47      0.53       138\n",
      "           1       0.61      0.74      0.67       156\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.62      0.61      0.60       294\n",
      "weighted avg       0.62      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6564625850340136 and f1 score is: 0.6564268110659863\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66       138\n",
      "           1       0.70      0.61      0.65       156\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[00:36:41] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6564625850340136 and f1 score is: 0.6489531488290163\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.54      0.60       138\n",
      "           1       0.65      0.76      0.70       156\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6326530612244898 and f1 score is: 0.6297574626865672\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60       138\n",
      "           1       0.65      0.68      0.66       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "----- Running Modality Combination ECG_EEG\n",
      "Saved Directory: 2022_08_12_00_36\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7559322033898305 and f1 score is: 0.7520313813393108\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72       131\n",
      "           1       0.77      0.79      0.78       164\n",
      "\n",
      "    accuracy                           0.76       295\n",
      "   macro avg       0.75      0.75      0.75       295\n",
      "weighted avg       0.76      0.76      0.76       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6440677966101694 and f1 score is: 0.6359693967492861\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.56      0.58       131\n",
      "           1       0.67      0.71      0.69       164\n",
      "\n",
      "    accuracy                           0.64       295\n",
      "   macro avg       0.64      0.64      0.64       295\n",
      "weighted avg       0.64      0.64      0.64       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.752542372881356 and f1 score is: 0.7495959349309893\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.72       131\n",
      "           1       0.78      0.77      0.78       164\n",
      "\n",
      "    accuracy                           0.75       295\n",
      "   macro avg       0.75      0.75      0.75       295\n",
      "weighted avg       0.75      0.75      0.75       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6101694915254238 and f1 score is: 0.6100978059740947\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.60       131\n",
      "           1       0.68      0.56      0.62       164\n",
      "\n",
      "    accuracy                           0.61       295\n",
      "   macro avg       0.62      0.62      0.61       295\n",
      "weighted avg       0.62      0.61      0.61       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6677966101694915 and f1 score is: 0.661253280839895\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61       131\n",
      "           1       0.69      0.73      0.71       164\n",
      "\n",
      "    accuracy                           0.67       295\n",
      "   macro avg       0.66      0.66      0.66       295\n",
      "weighted avg       0.67      0.67      0.67       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6949152542372882 and f1 score is: 0.6930493895671477\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67       131\n",
      "           1       0.74      0.70      0.72       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.69      0.69      0.69       295\n",
      "weighted avg       0.70      0.69      0.70       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[00:38:02] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.711864406779661 and f1 score is: 0.7070027225669249\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67       131\n",
      "           1       0.73      0.76      0.74       164\n",
      "\n",
      "    accuracy                           0.71       295\n",
      "   macro avg       0.71      0.71      0.71       295\n",
      "weighted avg       0.71      0.71      0.71       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7288135593220338 and f1 score is: 0.7265226661722444\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70       131\n",
      "           1       0.77      0.74      0.75       164\n",
      "\n",
      "    accuracy                           0.73       295\n",
      "   macro avg       0.73      0.73      0.73       295\n",
      "weighted avg       0.73      0.73      0.73       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7108843537414966 and f1 score is: 0.7051501386348888\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.66       141\n",
      "           1       0.69      0.82      0.75       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6530612244897959 and f1 score is: 0.6477801268498942\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.55      0.60       141\n",
      "           1       0.64      0.75      0.69       153\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7142857142857143 and f1 score is: 0.7126768428890544\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       141\n",
      "           1       0.71      0.76      0.73       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6530612244897959 and f1 score is: 0.6511075949367089\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.62       141\n",
      "           1       0.66      0.70      0.68       153\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6632653061224489 and f1 score is: 0.6599567731760032\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.63       141\n",
      "           1       0.66      0.73      0.69       153\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6598639455782312 and f1 score is: 0.6582825793853736\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.64       141\n",
      "           1       0.66      0.70      0.68       153\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[00:40:02] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6836734693877551 and f1 score is: 0.6773995634475842\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.57      0.63       141\n",
      "           1       0.66      0.79      0.72       153\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7040816326530612 and f1 score is: 0.7025641025641026\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68       141\n",
      "           1       0.70      0.75      0.72       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7312925170068028 and f1 score is: 0.7215475177134911\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67       128\n",
      "           1       0.74      0.81      0.77       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6530612244897959 and f1 score is: 0.6390119414483821\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.52      0.57       128\n",
      "           1       0.67      0.75      0.71       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7040816326530612 and f1 score is: 0.6907695097624373\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.57      0.63       128\n",
      "           1       0.71      0.81      0.75       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6632653061224489 and f1 score is: 0.6370596670615376\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.45      0.54       128\n",
      "           1       0.66      0.83      0.73       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.64      0.64       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6768707482993197 and f1 score is: 0.6623345221543855\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.54      0.59       128\n",
      "           1       0.69      0.78      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7108843537414966 and f1 score is: 0.7045645311927364\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       128\n",
      "           1       0.74      0.76      0.75       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[00:42:03] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6768707482993197 and f1 score is: 0.6642504237440947\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.55      0.60       128\n",
      "           1       0.69      0.77      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7040816326530612 and f1 score is: 0.6976131083972715\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65       128\n",
      "           1       0.73      0.75      0.74       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7244897959183674 and f1 score is: 0.7137293086660176\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66       126\n",
      "           1       0.74      0.80      0.77       168\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6394557823129252 and f1 score is: 0.6268678160919541\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56       126\n",
      "           1       0.67      0.72      0.70       168\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6870748299319728 and f1 score is: 0.6785052061046927\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.63       126\n",
      "           1       0.72      0.74      0.73       168\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6360544217687075 and f1 score is: 0.6324785326245692\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.63      0.60       126\n",
      "           1       0.70      0.64      0.67       168\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6530612244897959 and f1 score is: 0.6418573544164716\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58       126\n",
      "           1       0.69      0.73      0.71       168\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6802721088435374 and f1 score is: 0.6773455377574371\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.65       126\n",
      "           1       0.74      0.68      0.71       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.69      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[00:44:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6870748299319728 and f1 score is: 0.6744029275808936\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61       126\n",
      "           1       0.71      0.77      0.74       168\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6870748299319728 and f1 score is: 0.679905325443787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63       126\n",
      "           1       0.72      0.73      0.73       168\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7006802721088435 and f1 score is: 0.6986722571628232\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67       137\n",
      "           1       0.71      0.73      0.72       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6292517006802721 and f1 score is: 0.622610846140258\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57       137\n",
      "           1       0.64      0.71      0.67       157\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6870748299319728 and f1 score is: 0.6856199730345436\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       137\n",
      "           1       0.71      0.71      0.71       157\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6054421768707483 and f1 score is: 0.5972222222222222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.54       137\n",
      "           1       0.61      0.70      0.65       157\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6224489795918368 and f1 score is: 0.6182041532611875\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.55      0.58       137\n",
      "           1       0.64      0.68      0.66       157\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.62      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7006802721088435 and f1 score is: 0.7004584819154356\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.72      0.69       137\n",
      "           1       0.74      0.68      0.71       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[00:46:05] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6598639455782312 and f1 score is: 0.6552532833020637\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.58      0.62       137\n",
      "           1       0.67      0.73      0.70       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6700680272108843 and f1 score is: 0.6696055146845855\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66       137\n",
      "           1       0.70      0.66      0.68       157\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7142857142857143 and f1 score is: 0.7083333333333333\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67       128\n",
      "           1       0.74      0.76      0.75       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6564625850340136 and f1 score is: 0.6430451873489849\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57       128\n",
      "           1       0.68      0.75      0.71       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7040816326530612 and f1 score is: 0.6963206572714213\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65       128\n",
      "           1       0.73      0.77      0.74       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6394557823129252 and f1 score is: 0.6339675828047922\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.59      0.59       128\n",
      "           1       0.68      0.67      0.68       166\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6496598639455783 and f1 score is: 0.6404715827466252\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.56      0.58       128\n",
      "           1       0.68      0.72      0.70       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6904761904761905 and f1 score is: 0.6869961977186312\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.65       128\n",
      "           1       0.74      0.70      0.72       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[00:48:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7006802721088435 and f1 score is: 0.6931688804554079\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65       128\n",
      "           1       0.72      0.76      0.74       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6836734693877551 and f1 score is: 0.6780074191838897\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64       128\n",
      "           1       0.72      0.72      0.72       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7380952380952381 and f1 score is: 0.7177130743811958\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64       111\n",
      "           1       0.78      0.81      0.79       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7108843537414966 and f1 score is: 0.6960260792351389\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63       111\n",
      "           1       0.78      0.75      0.76       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.69      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7380952380952381 and f1 score is: 0.7177130743811958\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64       111\n",
      "           1       0.78      0.81      0.79       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6054421768707483 and f1 score is: 0.5927005207089285\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.57      0.52       111\n",
      "           1       0.71      0.63      0.66       183\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.59      0.60      0.59       294\n",
      "weighted avg       0.62      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7040816326530612 and f1 score is: 0.685754653234228\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       111\n",
      "           1       0.76      0.76      0.76       183\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7074829931972789 and f1 score is: 0.6919590643274854\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62       111\n",
      "           1       0.77      0.75      0.76       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[00:50:09] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6870748299319728 and f1 score is: 0.6592592592592592\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.56       111\n",
      "           1       0.73      0.78      0.76       183\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.68      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7108843537414966 and f1 score is: 0.6950467985405202\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63       111\n",
      "           1       0.78      0.75      0.76       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.69      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7448979591836735 and f1 score is: 0.7387781213348971\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       127\n",
      "           1       0.77      0.79      0.78       167\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6768707482993197 and f1 score is: 0.661319073083779\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.54      0.59       127\n",
      "           1       0.69      0.78      0.73       167\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7142857142857143 and f1 score is: 0.7027157164869029\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.60      0.64       127\n",
      "           1       0.72      0.80      0.76       167\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6462585034013606 and f1 score is: 0.6430205949656751\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.64      0.61       127\n",
      "           1       0.70      0.65      0.68       167\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.65      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6768707482993197 and f1 score is: 0.6623345221543856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.54      0.59       127\n",
      "           1       0.69      0.78      0.73       167\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6836734693877551 and f1 score is: 0.6805654535895788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65       127\n",
      "           1       0.74      0.69      0.71       167\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.69      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[00:52:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7244897959183674 and f1 score is: 0.714498087782187\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66       127\n",
      "           1       0.74      0.80      0.77       167\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6904761904761905 and f1 score is: 0.6849319908143437\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64       127\n",
      "           1       0.73      0.72      0.73       167\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.69      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7142857142857143 and f1 score is: 0.7077396449704142\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66       131\n",
      "           1       0.73      0.78      0.75       163\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6972789115646258 and f1 score is: 0.6886297376093296\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64       131\n",
      "           1       0.71      0.78      0.74       163\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7040816326530612 and f1 score is: 0.6987811340752517\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66       131\n",
      "           1       0.72      0.75      0.74       163\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6462585034013606 and f1 score is: 0.6420175151032641\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       131\n",
      "           1       0.68      0.68      0.68       163\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6870748299319728 and f1 score is: 0.6785052061046926\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.63       131\n",
      "           1       0.70      0.77      0.73       163\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7108843537414966 and f1 score is: 0.7051501386348888\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66       131\n",
      "           1       0.73      0.77      0.75       163\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[00:54:11] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.717687074829932 and f1 score is: 0.7120877824317149\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67       131\n",
      "           1       0.73      0.77      0.75       163\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7414965986394558 and f1 score is: 0.738776655443322\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71       131\n",
      "           1       0.77      0.76      0.77       163\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.717687074829932 and f1 score is: 0.7131437572736784\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.68       138\n",
      "           1       0.71      0.79      0.75       156\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6054421768707483 and f1 score is: 0.5980008486963082\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.54       138\n",
      "           1       0.61      0.70      0.65       156\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6700680272108843 and f1 score is: 0.6658582023972723\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.63       138\n",
      "           1       0.67      0.74      0.70       156\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6326530612244898 and f1 score is: 0.6166883963494132\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.46      0.54       138\n",
      "           1       0.62      0.79      0.69       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.64      0.62      0.62       294\n",
      "weighted avg       0.64      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.5918367346938775 and f1 score is: 0.5849021084337349\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.49      0.53       138\n",
      "           1       0.60      0.68      0.64       156\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.59      0.59      0.58       294\n",
      "weighted avg       0.59      0.59      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6360544217687075 and f1 score is: 0.6351045690225146\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.62      0.62       138\n",
      "           1       0.66      0.65      0.65       156\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[00:56:12] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6802721088435374 and f1 score is: 0.6742420670470084\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.58      0.63       138\n",
      "           1       0.67      0.77      0.72       156\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6972789115646258 and f1 score is: 0.6943045738652959\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66       138\n",
      "           1       0.70      0.75      0.72       156\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "----- Running Modality Combination ECG_GAZE\n",
      "Saved Directory: 2022_08_12_00_57\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7220338983050848 and f1 score is: 0.7165588676415449\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68       131\n",
      "           1       0.74      0.77      0.76       164\n",
      "\n",
      "    accuracy                           0.72       295\n",
      "   macro avg       0.72      0.72      0.72       295\n",
      "weighted avg       0.72      0.72      0.72       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6237288135593221 and f1 score is: 0.6116625751592131\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.54       131\n",
      "           1       0.64      0.72      0.68       164\n",
      "\n",
      "    accuracy                           0.62       295\n",
      "   macro avg       0.62      0.61      0.61       295\n",
      "weighted avg       0.62      0.62      0.62       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6677966101694915 and f1 score is: 0.6618871631736527\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.62       131\n",
      "           1       0.69      0.72      0.71       164\n",
      "\n",
      "    accuracy                           0.67       295\n",
      "   macro avg       0.66      0.66      0.66       295\n",
      "weighted avg       0.67      0.67      0.67       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6 and f1 score is: 0.5739081472777126\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.40      0.47       131\n",
      "           1       0.61      0.76      0.68       164\n",
      "\n",
      "    accuracy                           0.60       295\n",
      "   macro avg       0.59      0.58      0.57       295\n",
      "weighted avg       0.59      0.60      0.59       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6440677966101694 and f1 score is: 0.632653787312769\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57       131\n",
      "           1       0.66      0.74      0.70       164\n",
      "\n",
      "    accuracy                           0.64       295\n",
      "   macro avg       0.64      0.63      0.63       295\n",
      "weighted avg       0.64      0.64      0.64       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6915254237288135 and f1 score is: 0.6868620886747774\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65       131\n",
      "           1       0.72      0.73      0.73       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.69      0.69      0.69       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[00:57:31] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6983050847457627 and f1 score is: 0.6914407267684424\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       131\n",
      "           1       0.71      0.76      0.74       164\n",
      "\n",
      "    accuracy                           0.70       295\n",
      "   macro avg       0.69      0.69      0.69       295\n",
      "weighted avg       0.70      0.70      0.70       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6983050847457627 and f1 score is: 0.6937442405720351\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66       131\n",
      "           1       0.72      0.74      0.73       164\n",
      "\n",
      "    accuracy                           0.70       295\n",
      "   macro avg       0.69      0.69      0.69       295\n",
      "weighted avg       0.70      0.70      0.70       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7108843537414966 and f1 score is: 0.7076338110558643\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.68       141\n",
      "           1       0.70      0.78      0.74       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6530612244897959 and f1 score is: 0.6435601198117245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.51      0.59       141\n",
      "           1       0.63      0.78      0.70       153\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.66      0.65      0.64       294\n",
      "weighted avg       0.66      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7040816326530612 and f1 score is: 0.7011741340031543\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67       141\n",
      "           1       0.69      0.77      0.73       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6530612244897959 and f1 score is: 0.64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.48      0.57       141\n",
      "           1       0.63      0.81      0.71       153\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.67      0.65      0.64       294\n",
      "weighted avg       0.66      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6530612244897959 and f1 score is: 0.6435601198117245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.51      0.59       141\n",
      "           1       0.63      0.78      0.70       153\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.66      0.65      0.64       294\n",
      "weighted avg       0.66      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6904761904761905 and f1 score is: 0.6898698227595721\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.68       141\n",
      "           1       0.70      0.71      0.70       153\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[00:58:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.717687074829932 and f1 score is: 0.716503049665989\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70       141\n",
      "           1       0.72      0.75      0.73       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7210884353741497 and f1 score is: 0.7204545454545455\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71       141\n",
      "           1       0.73      0.74      0.73       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7108843537414966 and f1 score is: 0.6950467985405201\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.55      0.63       128\n",
      "           1       0.71      0.83      0.76       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.69      0.70       294\n",
      "weighted avg       0.71      0.71      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6428571428571429 and f1 score is: 0.6245028037610538\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.48      0.54       128\n",
      "           1       0.66      0.77      0.71       166\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.62      0.62       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7210884353741497 and f1 score is: 0.7097939137134053\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65       128\n",
      "           1       0.73      0.81      0.77       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.673469387755102 and f1 score is: 0.656140350877193\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.52      0.58       128\n",
      "           1       0.68      0.80      0.73       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6462585034013606 and f1 score is: 0.6297946532351801\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.55       128\n",
      "           1       0.66      0.76      0.71       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.673469387755102 and f1 score is: 0.6679216867469879\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       128\n",
      "           1       0.71      0.71      0.71       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[00:59:05] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7040816326530612 and f1 score is: 0.6907695097624373\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.57      0.63       128\n",
      "           1       0.71      0.81      0.75       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7210884353741497 and f1 score is: 0.7158281861473903\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.68       128\n",
      "           1       0.75      0.76      0.75       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7040816326530612 and f1 score is: 0.6925240722709077\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.63       126\n",
      "           1       0.72      0.79      0.75       168\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6530612244897959 and f1 score is: 0.6369139868268113\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.52      0.56       126\n",
      "           1       0.68      0.76      0.71       168\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6972789115646258 and f1 score is: 0.6871106221674819\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63       126\n",
      "           1       0.72      0.77      0.74       168\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.608843537414966 and f1 score is: 0.608621667612025\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.68      0.60       126\n",
      "           1       0.70      0.55      0.62       168\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.62      0.62      0.61       294\n",
      "weighted avg       0.63      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6462585034013606 and f1 score is: 0.6297946532351801\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55       126\n",
      "           1       0.67      0.75      0.71       168\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6530612244897959 and f1 score is: 0.6435601198117245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.57      0.59       126\n",
      "           1       0.69      0.71      0.70       168\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[00:59:51] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6938775510204082 and f1 score is: 0.681481124807396\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62       126\n",
      "           1       0.71      0.78      0.74       168\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7006802721088435 and f1 score is: 0.6931688804554079\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65       126\n",
      "           1       0.73      0.75      0.74       168\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7040816326530612 and f1 score is: 0.7011741340031543\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67       137\n",
      "           1       0.71      0.75      0.73       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6428571428571429 and f1 score is: 0.6364599894011658\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.55      0.59       137\n",
      "           1       0.65      0.73      0.68       157\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6700680272108843 and f1 score is: 0.6680363649062359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64       137\n",
      "           1       0.69      0.70      0.69       157\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6326530612244898 and f1 score is: 0.6264118975903614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58       137\n",
      "           1       0.64      0.71      0.67       157\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6326530612244898 and f1 score is: 0.6257249280965628\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57       137\n",
      "           1       0.64      0.72      0.68       157\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6972789115646258 and f1 score is: 0.6968545444013208\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.69       137\n",
      "           1       0.73      0.69      0.71       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[01:00:38] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6938775510204082 and f1 score is: 0.6918238993710691\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67       137\n",
      "           1       0.71      0.73      0.72       157\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7142857142857143 and f1 score is: 0.7126768428890543\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69       137\n",
      "           1       0.73      0.74      0.73       157\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7278911564625851 and f1 score is: 0.7176470588235295\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.66       128\n",
      "           1       0.73      0.81      0.77       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6530612244897959 and f1 score is: 0.6435601198117245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.56      0.59       128\n",
      "           1       0.68      0.72      0.70       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7074829931972789 and f1 score is: 0.6938686555598605\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.57      0.63       128\n",
      "           1       0.71      0.81      0.76       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.69      0.69       294\n",
      "weighted avg       0.71      0.71      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6598639455782312 and f1 score is: 0.6497331300038125\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59       128\n",
      "           1       0.69      0.73      0.71       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6462585034013606 and f1 score is: 0.6365711025531308\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.55      0.58       128\n",
      "           1       0.68      0.72      0.70       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.64      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.673469387755102 and f1 score is: 0.6708955223880597\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.67      0.64       128\n",
      "           1       0.73      0.67      0.70       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[01:01:25] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7108843537414966 and f1 score is: 0.7033017915870208\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.66       128\n",
      "           1       0.73      0.77      0.75       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7210884353741497 and f1 score is: 0.7173076923076922\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.68       128\n",
      "           1       0.76      0.74      0.75       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7517006802721088 and f1 score is: 0.7344173441734417\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67       111\n",
      "           1       0.80      0.81      0.80       183\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6564625850340136 and f1 score is: 0.6376438429716768\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.57      0.56       111\n",
      "           1       0.73      0.71      0.72       183\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.717687074829932 and f1 score is: 0.7012304866850322\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       111\n",
      "           1       0.78      0.77      0.77       183\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6972789115646258 and f1 score is: 0.6636198850707702\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.56       111\n",
      "           1       0.73      0.81      0.77       183\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.68      0.66      0.66       294\n",
      "weighted avg       0.69      0.70      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.673469387755102 and f1 score is: 0.6550139343861536\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.59      0.58       111\n",
      "           1       0.74      0.73      0.73       183\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.65      0.66      0.66       294\n",
      "weighted avg       0.68      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6972789115646258 and f1 score is: 0.6845759749261648\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.66      0.62       111\n",
      "           1       0.78      0.72      0.75       183\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.68      0.69      0.68       294\n",
      "weighted avg       0.71      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[01:02:12] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7380952380952381 and f1 score is: 0.7188070602556299\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65       111\n",
      "           1       0.78      0.80      0.79       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7142857142857143 and f1 score is: 0.7043103448275861\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.70      0.65       111\n",
      "           1       0.80      0.72      0.76       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.71      0.70       294\n",
      "weighted avg       0.73      0.71      0.72       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6632653061224489 and f1 score is: 0.6510532184004507\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.59       127\n",
      "           1       0.69      0.75      0.72       167\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6360544217687075 and f1 score is: 0.620782351877524\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.54       127\n",
      "           1       0.66      0.74      0.70       167\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.62      0.62       294\n",
      "weighted avg       0.63      0.64      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6666666666666666 and f1 score is: 0.6575381543289117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60       127\n",
      "           1       0.70      0.73      0.71       167\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6326530612244898 and f1 score is: 0.6297574626865672\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.63      0.60       127\n",
      "           1       0.69      0.63      0.66       167\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.64      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6258503401360545 and f1 score is: 0.6095900333188469\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.49      0.53       127\n",
      "           1       0.65      0.73      0.69       167\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.61      0.61       294\n",
      "weighted avg       0.62      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6632653061224489 and f1 score is: 0.6594793799356538\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.62       127\n",
      "           1       0.72      0.68      0.70       167\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.67      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[01:02:58] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6870748299319728 and f1 score is: 0.6734753005939447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.61       127\n",
      "           1       0.70      0.78      0.74       167\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6802721088435374 and f1 score is: 0.6742420670470083\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       127\n",
      "           1       0.72      0.72      0.72       167\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7210884353741497 and f1 score is: 0.7097939137134053\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.59      0.65       131\n",
      "           1       0.71      0.83      0.77       163\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.5918367346938775 and f1 score is: 0.5806589644843817\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.48      0.51       131\n",
      "           1       0.62      0.68      0.65       163\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.58      0.58      0.58       294\n",
      "weighted avg       0.59      0.59      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6836734693877551 and f1 score is: 0.6746355685131196\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.58      0.62       131\n",
      "           1       0.69      0.77      0.73       163\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6122448979591837 and f1 score is: 0.6041666666666666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.53      0.55       131\n",
      "           1       0.64      0.68      0.66       163\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.61      0.60      0.60       294\n",
      "weighted avg       0.61      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6054421768707483 and f1 score is: 0.5955407969639469\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.50      0.53       131\n",
      "           1       0.63      0.69      0.66       163\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6598639455782312 and f1 score is: 0.6546863988724454\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61       131\n",
      "           1       0.69      0.71      0.70       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[01:03:49] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7278911564625851 and f1 score is: 0.7191038073854679\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.62      0.67       131\n",
      "           1       0.73      0.82      0.77       163\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6972789115646258 and f1 score is: 0.6906616856018064\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       131\n",
      "           1       0.71      0.76      0.74       163\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6836734693877551 and f1 score is: 0.6805654535895788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       138\n",
      "           1       0.69      0.74      0.71       156\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6428571428571429 and f1 score is: 0.6350503032380862\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.53      0.58       138\n",
      "           1       0.64      0.74      0.69       156\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6598639455782312 and f1 score is: 0.6552532833020638\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62       138\n",
      "           1       0.66      0.73      0.70       156\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6156462585034014 and f1 score is: 0.6151074552511151\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.60       138\n",
      "           1       0.64      0.62      0.63       156\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.62      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6394557823129252 and f1 score is: 0.6333301957831325\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.59       138\n",
      "           1       0.64      0.72      0.68       156\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6802721088435374 and f1 score is: 0.6787856246222512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66       138\n",
      "           1       0.70      0.71      0.70       156\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[01:04:36] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6870748299319728 and f1 score is: 0.6842105263157894\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65       138\n",
      "           1       0.69      0.74      0.71       156\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6700680272108843 and f1 score is: 0.6696055146845854\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.66       138\n",
      "           1       0.70      0.67      0.68       156\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "----- Running Modality Combination EDA_EEG\n",
      "Saved Directory: 2022_08_12_01_04\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7593220338983051 and f1 score is: 0.7538459730399935\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       131\n",
      "           1       0.77      0.82      0.79       164\n",
      "\n",
      "    accuracy                           0.76       295\n",
      "   macro avg       0.76      0.75      0.75       295\n",
      "weighted avg       0.76      0.76      0.76       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6474576271186441 and f1 score is: 0.6382757970194304\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.58       131\n",
      "           1       0.67      0.73      0.70       164\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.64      0.64      0.64       295\n",
      "weighted avg       0.64      0.65      0.64       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7220338983050848 and f1 score is: 0.7165588676415449\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68       131\n",
      "           1       0.74      0.77      0.76       164\n",
      "\n",
      "    accuracy                           0.72       295\n",
      "   macro avg       0.72      0.72      0.72       295\n",
      "weighted avg       0.72      0.72      0.72       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6474576271186441 and f1 score is: 0.6365962285605989\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57       131\n",
      "           1       0.66      0.74      0.70       164\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.64      0.64      0.64       295\n",
      "weighted avg       0.64      0.65      0.64       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6474576271186441 and f1 score is: 0.641186377245509\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59       131\n",
      "           1       0.68      0.70      0.69       164\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.64      0.64      0.64       295\n",
      "weighted avg       0.65      0.65      0.65       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6576271186440678 and f1 score is: 0.6535505401099988\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.62      0.62       131\n",
      "           1       0.69      0.69      0.69       164\n",
      "\n",
      "    accuracy                           0.66       295\n",
      "   macro avg       0.65      0.65      0.65       295\n",
      "weighted avg       0.66      0.66      0.66       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[01:06:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7491525423728813 and f1 score is: 0.7442116610423697\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71       131\n",
      "           1       0.76      0.80      0.78       164\n",
      "\n",
      "    accuracy                           0.75       295\n",
      "   macro avg       0.75      0.74      0.74       295\n",
      "weighted avg       0.75      0.75      0.75       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.688135593220339 and f1 score is: 0.6865471680680033\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66       131\n",
      "           1       0.74      0.68      0.71       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.69      0.69      0.69       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.717687074829932 and f1 score is: 0.7126302773361597\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67       141\n",
      "           1       0.69      0.82      0.75       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.673469387755102 and f1 score is: 0.6673110471969447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62       141\n",
      "           1       0.66      0.78      0.71       153\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7108843537414966 and f1 score is: 0.7084252161433722\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68       141\n",
      "           1       0.70      0.77      0.74       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6190476190476191 and f1 score is: 0.6118628883964354\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.50      0.56       141\n",
      "           1       0.61      0.73      0.66       153\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.62      0.61      0.61       294\n",
      "weighted avg       0.62      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6632653061224489 and f1 score is: 0.6572337042925278\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.55      0.61       141\n",
      "           1       0.65      0.76      0.70       153\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7142857142857143 and f1 score is: 0.7132107023411371\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.70       141\n",
      "           1       0.72      0.75      0.73       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[01:08:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6972789115646258 and f1 score is: 0.6938754021643756\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66       141\n",
      "           1       0.69      0.77      0.73       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6904761904761905 and f1 score is: 0.6869961977186312\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.65       141\n",
      "           1       0.68      0.76      0.72       153\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7108843537414966 and f1 score is: 0.699592484402611\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.59      0.64       128\n",
      "           1       0.72      0.80      0.76       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6496598639455783 and f1 score is: 0.6279624055531667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.47      0.54       128\n",
      "           1       0.66      0.79      0.72       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.65      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7210884353741497 and f1 score is: 0.7089671157467767\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.59      0.65       128\n",
      "           1       0.72      0.82      0.77       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.5986394557823129 and f1 score is: 0.5745192307692308\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.41      0.47       128\n",
      "           1       0.62      0.74      0.68       166\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.59      0.58      0.57       294\n",
      "weighted avg       0.59      0.60      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6564625850340136 and f1 score is: 0.63643709825528\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.48      0.55       128\n",
      "           1       0.66      0.79      0.72       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7006802721088435 and f1 score is: 0.6931688804554079\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65       128\n",
      "           1       0.72      0.76      0.74       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[01:10:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7108843537414966 and f1 score is: 0.6978782566644501\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64       128\n",
      "           1       0.71      0.81      0.76       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7040816326530612 and f1 score is: 0.6949006977992485\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.64       128\n",
      "           1       0.72      0.78      0.75       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7448979591836735 and f1 score is: 0.7356463775760991\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69       126\n",
      "           1       0.76      0.82      0.79       168\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6054421768707483 and f1 score is: 0.5955407969639468\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53       126\n",
      "           1       0.65      0.67      0.66       168\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7244897959183674 and f1 score is: 0.7129286962811163\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66       126\n",
      "           1       0.74      0.81      0.77       168\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6020408163265306 and f1 score is: 0.593341766465296\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.53       126\n",
      "           1       0.65      0.65      0.65       168\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.59      0.59      0.59       294\n",
      "weighted avg       0.60      0.60      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6258503401360545 and f1 score is: 0.61646110056926\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.55      0.56       126\n",
      "           1       0.67      0.68      0.68       168\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.62      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6700680272108843 and f1 score is: 0.6672617172459658\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.67      0.64       126\n",
      "           1       0.73      0.67      0.70       168\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[01:12:05] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7482993197278912 and f1 score is: 0.7373605678690425\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68       126\n",
      "           1       0.75      0.83      0.79       168\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.73      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7414965986394558 and f1 score is: 0.7355739644970414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.70       126\n",
      "           1       0.77      0.78      0.78       168\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7414965986394558 and f1 score is: 0.7387766554433222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       137\n",
      "           1       0.74      0.79      0.77       157\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6360544217687075 and f1 score is: 0.6308223116733755\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.59       137\n",
      "           1       0.65      0.71      0.67       157\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.63      0.64      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7006802721088435 and f1 score is: 0.6979405034324944\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67       137\n",
      "           1       0.71      0.75      0.73       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.5986394557823129 and f1 score is: 0.593827565213319\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.53      0.55       137\n",
      "           1       0.62      0.66      0.64       157\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.60      0.59      0.59       294\n",
      "weighted avg       0.60      0.60      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6292517006802721 and f1 score is: 0.6256089724867107\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59       137\n",
      "           1       0.64      0.68      0.66       157\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7074829931972789 and f1 score is: 0.7066140635878393\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69       137\n",
      "           1       0.73      0.71      0.72       157\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[01:14:05] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6938775510204082 and f1 score is: 0.6886765813253013\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.65       137\n",
      "           1       0.69      0.77      0.73       157\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7142857142857143 and f1 score is: 0.7138089278264497\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70       137\n",
      "           1       0.74      0.71      0.73       157\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7278911564625851 and f1 score is: 0.7222222222222223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68       128\n",
      "           1       0.75      0.77      0.76       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6428571428571429 and f1 score is: 0.6289083630855783\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.52      0.56       128\n",
      "           1       0.66      0.74      0.70       166\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7074829931972789 and f1 score is: 0.701388888888889\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       128\n",
      "           1       0.74      0.75      0.74       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.54421768707483 and f1 score is: 0.5168269230769231\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.35      0.40       128\n",
      "           1       0.58      0.69      0.63       166\n",
      "\n",
      "    accuracy                           0.54       294\n",
      "   macro avg       0.52      0.52      0.52       294\n",
      "weighted avg       0.53      0.54      0.53       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6258503401360545 and f1 score is: 0.6127873563218391\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.51      0.54       128\n",
      "           1       0.65      0.72      0.68       166\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.61      0.61       294\n",
      "weighted avg       0.62      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6462585034013606 and f1 score is: 0.6414634146341464\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60       128\n",
      "           1       0.69      0.67      0.68       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[01:16:06] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6972789115646258 and f1 score is: 0.6878869207371623\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63       128\n",
      "           1       0.72      0.77      0.74       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7312925170068028 and f1 score is: 0.7269681545135012\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69       128\n",
      "           1       0.76      0.76      0.76       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7482993197278912 and f1 score is: 0.729241338112306\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66       111\n",
      "           1       0.79      0.81      0.80       183\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6972789115646258 and f1 score is: 0.6785306222740954\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       111\n",
      "           1       0.76      0.75      0.76       183\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7244897959183674 and f1 score is: 0.7018591549295775\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62       111\n",
      "           1       0.77      0.80      0.78       183\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6326530612244898 and f1 score is: 0.6131578947368421\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.54      0.53       111\n",
      "           1       0.71      0.69      0.70       183\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.64      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7040816326530612 and f1 score is: 0.682288496652465\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.59      0.60       111\n",
      "           1       0.76      0.78      0.77       183\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7619047619047619 and f1 score is: 0.7475961538461539\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.69       111\n",
      "           1       0.81      0.80      0.81       183\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[01:18:06] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7517006802721088 and f1 score is: 0.7344173441734417\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67       111\n",
      "           1       0.80      0.81      0.80       183\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7482993197278912 and f1 score is: 0.7349415204678363\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.69      0.68       111\n",
      "           1       0.81      0.78      0.79       183\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.73      0.74      0.73       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7789115646258503 and f1 score is: 0.7720522454821972\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73       127\n",
      "           1       0.79      0.84      0.81       167\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.78      0.77      0.77       294\n",
      "weighted avg       0.78      0.78      0.78       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7040816326530612 and f1 score is: 0.6907695097624373\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.57      0.63       127\n",
      "           1       0.71      0.80      0.75       167\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7517006802721088 and f1 score is: 0.7439971372338523\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       127\n",
      "           1       0.76      0.81      0.79       167\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6326530612244898 and f1 score is: 0.6177773497688752\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.54       127\n",
      "           1       0.66      0.73      0.69       167\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7108843537414966 and f1 score is: 0.7019144748613348\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       127\n",
      "           1       0.73      0.78      0.75       167\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7074829931972789 and f1 score is: 0.701966146447263\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       127\n",
      "           1       0.74      0.74      0.74       167\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[01:20:06] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7482993197278912 and f1 score is: 0.7401710218315578\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69       127\n",
      "           1       0.76      0.81      0.79       167\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7517006802721088 and f1 score is: 0.7467760014158458\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       127\n",
      "           1       0.78      0.78      0.78       167\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.717687074829932 and f1 score is: 0.7136285221391604\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68       131\n",
      "           1       0.74      0.75      0.75       163\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6666666666666666 and f1 score is: 0.6603800273468811\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61       131\n",
      "           1       0.69      0.72      0.71       163\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7210884353741497 and f1 score is: 0.7152777777777777\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67       131\n",
      "           1       0.73      0.78      0.76       163\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6258503401360545 and f1 score is: 0.6137677351550184\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.55       131\n",
      "           1       0.64      0.72      0.68       163\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.61      0.61       294\n",
      "weighted avg       0.62      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6632653061224489 and f1 score is: 0.6551871201620642\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60       131\n",
      "           1       0.68      0.74      0.71       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6768707482993197 and f1 score is: 0.6736958934517203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64       131\n",
      "           1       0.71      0.70      0.71       163\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[01:22:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7278911564625851 and f1 score is: 0.7222222222222222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68       131\n",
      "           1       0.74      0.79      0.76       163\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7142857142857143 and f1 score is: 0.7123689727463312\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69       131\n",
      "           1       0.75      0.72      0.74       163\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7142857142857143 and f1 score is: 0.7071157495256166\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66       138\n",
      "           1       0.70      0.82      0.75       156\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6122448979591837 and f1 score is: 0.6025142314990513\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.49      0.54       138\n",
      "           1       0.61      0.72      0.66       156\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.61      0.60      0.60       294\n",
      "weighted avg       0.61      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7346938775510204 and f1 score is: 0.7315131363274481\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70       138\n",
      "           1       0.73      0.79      0.76       156\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.5952380952380952 and f1 score is: 0.5457956301037298\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.28      0.40       138\n",
      "           1       0.58      0.87      0.70       156\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.62      0.58      0.55       294\n",
      "weighted avg       0.62      0.60      0.55       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6020408163265306 and f1 score is: 0.5924938692824395\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.48      0.53       138\n",
      "           1       0.61      0.71      0.65       156\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.60      0.59      0.59       294\n",
      "weighted avg       0.60      0.60      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6428571428571429 and f1 score is: 0.6416590246903549\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       138\n",
      "           1       0.66      0.66      0.66       156\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[01:24:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7244897959183674 and f1 score is: 0.7184673767836665\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68       138\n",
      "           1       0.71      0.82      0.76       156\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7244897959183674 and f1 score is: 0.7239500620167618\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       138\n",
      "           1       0.75      0.72      0.74       156\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.73      0.72      0.72       294\n",
      "\n",
      "----- Running Modality Combination EDA_GAZE\n",
      "Saved Directory: 2022_08_12_01_24\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7491525423728813 and f1 score is: 0.7420353564000755\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.70       131\n",
      "           1       0.75      0.82      0.78       164\n",
      "\n",
      "    accuracy                           0.75       295\n",
      "   macro avg       0.75      0.74      0.74       295\n",
      "weighted avg       0.75      0.75      0.75       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6813559322033899 and f1 score is: 0.666128876902331\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.53      0.59       131\n",
      "           1       0.68      0.80      0.74       164\n",
      "\n",
      "    accuracy                           0.68       295\n",
      "   macro avg       0.68      0.67      0.67       295\n",
      "weighted avg       0.68      0.68      0.67       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.711864406779661 and f1 score is: 0.7046838379912613\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66       131\n",
      "           1       0.72      0.78      0.75       164\n",
      "\n",
      "    accuracy                           0.71       295\n",
      "   macro avg       0.71      0.70      0.70       295\n",
      "weighted avg       0.71      0.71      0.71       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6101694915254238 and f1 score is: 0.5995679937677789\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.50      0.53       131\n",
      "           1       0.64      0.70      0.66       164\n",
      "\n",
      "    accuracy                           0.61       295\n",
      "   macro avg       0.60      0.60      0.60       295\n",
      "weighted avg       0.61      0.61      0.61       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6813559322033899 and f1 score is: 0.6640253949791606\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.51      0.59       131\n",
      "           1       0.68      0.82      0.74       164\n",
      "\n",
      "    accuracy                           0.68       295\n",
      "   macro avg       0.68      0.66      0.66       295\n",
      "weighted avg       0.68      0.68      0.67       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.688135593220339 and f1 score is: 0.680705882352941\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63       131\n",
      "           1       0.70      0.76      0.73       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.68      0.68      0.68       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[01:25:30] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7084745762711865 and f1 score is: 0.7002032520325202\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.65       131\n",
      "           1       0.72      0.79      0.75       164\n",
      "\n",
      "    accuracy                           0.71       295\n",
      "   macro avg       0.71      0.70      0.70       295\n",
      "weighted avg       0.71      0.71      0.71       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7254237288135593 and f1 score is: 0.7202809482001755\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68       131\n",
      "           1       0.74      0.77      0.76       164\n",
      "\n",
      "    accuracy                           0.73       295\n",
      "   macro avg       0.72      0.72      0.72       295\n",
      "weighted avg       0.72      0.73      0.72       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7585034013605442 and f1 score is: 0.7546169489931467\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.66      0.72       141\n",
      "           1       0.73      0.85      0.79       153\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.77      0.75      0.75       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6530612244897959 and f1 score is: 0.6418573544164716\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.50      0.58       141\n",
      "           1       0.63      0.80      0.71       153\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.66      0.65      0.64       294\n",
      "weighted avg       0.66      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7312925170068028 and f1 score is: 0.7286523745545885\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.70       141\n",
      "           1       0.72      0.80      0.76       153\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6156462585034014 and f1 score is: 0.6154282473057289\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61       141\n",
      "           1       0.64      0.61      0.62       153\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.62      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6496598639455783 and f1 score is: 0.6387904813025587\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.50      0.58       141\n",
      "           1       0.63      0.79      0.70       153\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.66      0.64      0.64       294\n",
      "weighted avg       0.66      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.717687074829932 and f1 score is: 0.7172913166888721\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.71       141\n",
      "           1       0.73      0.73      0.73       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[01:26:20] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7414965986394558 and f1 score is: 0.7391304347826086\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       141\n",
      "           1       0.73      0.80      0.76       153\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7244897959183674 and f1 score is: 0.7235655333325595\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71       141\n",
      "           1       0.73      0.75      0.74       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7414965986394558 and f1 score is: 0.7294653235180163\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67       128\n",
      "           1       0.74      0.84      0.79       166\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6496598639455783 and f1 score is: 0.6316551313084624\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.49      0.55       128\n",
      "           1       0.66      0.77      0.71       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.65      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7244897959183674 and f1 score is: 0.7172640602182199\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67       128\n",
      "           1       0.74      0.78      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.5748299319727891 and f1 score is: 0.5252612677784811\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.29      0.37       128\n",
      "           1       0.59      0.80      0.68       166\n",
      "\n",
      "    accuracy                           0.57       294\n",
      "   macro avg       0.56      0.54      0.53       294\n",
      "weighted avg       0.56      0.57      0.55       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6632653061224489 and f1 score is: 0.6481170283503597\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.52      0.58       128\n",
      "           1       0.68      0.77      0.72       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6700680272108843 and f1 score is: 0.6614149856934237\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       128\n",
      "           1       0.70      0.73      0.72       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[01:27:11] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7517006802721088 and f1 score is: 0.7433603979575975\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70       128\n",
      "           1       0.76      0.83      0.79       166\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7278911564625851 and f1 score is: 0.7222222222222223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68       128\n",
      "           1       0.75      0.77      0.76       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7312925170068028 and f1 score is: 0.721547517713491\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67       126\n",
      "           1       0.75      0.80      0.77       168\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6632653061224489 and f1 score is: 0.6491350732324754\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58       126\n",
      "           1       0.69      0.76      0.72       168\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7074829931972789 and f1 score is: 0.6987704918032787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65       126\n",
      "           1       0.73      0.77      0.75       168\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.5544217687074829 and f1 score is: 0.36356275303643726\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.01      0.02       126\n",
      "           1       0.56      0.96      0.71       168\n",
      "\n",
      "    accuracy                           0.55       294\n",
      "   macro avg       0.35      0.49      0.36       294\n",
      "weighted avg       0.38      0.55      0.41       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6666666666666666 and f1 score is: 0.6531683359013868\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.58       126\n",
      "           1       0.69      0.76      0.72       168\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.67      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6836734693877551 and f1 score is: 0.6753772543246228\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.62       126\n",
      "           1       0.72      0.74      0.73       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[01:28:02] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7108843537414966 and f1 score is: 0.7045645311927364\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       126\n",
      "           1       0.75      0.75      0.75       168\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7142857142857143 and f1 score is: 0.7077396449704141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66       126\n",
      "           1       0.75      0.76      0.75       168\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7653061224489796 and f1 score is: 0.7645187876536617\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       137\n",
      "           1       0.79      0.77      0.78       157\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.76      0.76      0.76       294\n",
      "weighted avg       0.77      0.77      0.77       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6462585034013606 and f1 score is: 0.6339080459770116\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.50      0.57       137\n",
      "           1       0.64      0.78      0.70       157\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.63       294\n",
      "weighted avg       0.65      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7142857142857143 and f1 score is: 0.7136363636363636\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70       137\n",
      "           1       0.74      0.71      0.73       157\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.5306122448979592 and f1 score is: 0.5087659821774506\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.34      0.41       137\n",
      "           1       0.55      0.69      0.61       157\n",
      "\n",
      "    accuracy                           0.53       294\n",
      "   macro avg       0.52      0.52      0.51       294\n",
      "weighted avg       0.52      0.53      0.52       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6428571428571429 and f1 score is: 0.6317767042404723\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.50      0.57       137\n",
      "           1       0.64      0.76      0.70       157\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6938775510204082 and f1 score is: 0.6931818181818181\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.69      0.68       137\n",
      "           1       0.72      0.69      0.71       157\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[01:28:53] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7312925170068028 and f1 score is: 0.7305912238577443\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72       137\n",
      "           1       0.76      0.73      0.74       157\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7142857142857143 and f1 score is: 0.7142724916697518\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.71       137\n",
      "           1       0.76      0.68      0.72       157\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.72      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7210884353741497 and f1 score is: 0.7152777777777777\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67       128\n",
      "           1       0.75      0.77      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6428571428571429 and f1 score is: 0.6299049286065387\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.52      0.56       128\n",
      "           1       0.67      0.73      0.70       166\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7074829931972789 and f1 score is: 0.6994722578804735\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       128\n",
      "           1       0.73      0.77      0.75       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.564625850340136 and f1 score is: 0.517365208023393\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.29      0.37       128\n",
      "           1       0.59      0.78      0.67       166\n",
      "\n",
      "    accuracy                           0.56       294\n",
      "   macro avg       0.54      0.53      0.52       294\n",
      "weighted avg       0.55      0.56      0.54       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6496598639455783 and f1 score is: 0.6369543585378428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.53      0.57       128\n",
      "           1       0.67      0.74      0.70       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6598639455782312 and f1 score is: 0.6540850903614458\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       128\n",
      "           1       0.70      0.70      0.70       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[01:29:44] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7108843537414966 and f1 score is: 0.7011730661150107\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.61      0.65       128\n",
      "           1       0.72      0.79      0.76       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7312925170068028 and f1 score is: 0.7282714243930974\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70       128\n",
      "           1       0.77      0.74      0.76       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7482993197278912 and f1 score is: 0.729241338112306\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66       111\n",
      "           1       0.79      0.81      0.80       183\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6598639455782312 and f1 score is: 0.6406395149855766\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.57      0.56       111\n",
      "           1       0.73      0.72      0.72       183\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7108843537414966 and f1 score is: 0.689592209373098\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.61       111\n",
      "           1       0.76      0.78      0.77       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.5918367346938775 and f1 score is: 0.5796797560045749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.56      0.51       111\n",
      "           1       0.70      0.61      0.65       183\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.58      0.59      0.58       294\n",
      "weighted avg       0.61      0.59      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6700680272108843 and f1 score is: 0.6496344984335647\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.57      0.57       111\n",
      "           1       0.74      0.73      0.73       183\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7142857142857143 and f1 score is: 0.7018687527162104\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       111\n",
      "           1       0.79      0.74      0.76       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.71      0.70       294\n",
      "weighted avg       0.72      0.71      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[01:30:35] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7414965986394558 and f1 score is: 0.7173076923076923\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.59      0.63       111\n",
      "           1       0.77      0.83      0.80       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.71      0.72       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7380952380952381 and f1 score is: 0.7228282828282828\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       111\n",
      "           1       0.79      0.78      0.79       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7414965986394558 and f1 score is: 0.7337971788028974\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69       127\n",
      "           1       0.76      0.80      0.78       167\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6666666666666666 and f1 score is: 0.6567384674037362\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.60       127\n",
      "           1       0.69      0.74      0.72       167\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.67      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7210884353741497 and f1 score is: 0.7163497740963856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68       127\n",
      "           1       0.76      0.75      0.75       167\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.5680272108843537 and f1 score is: 0.5546251565575238\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.46      0.48       127\n",
      "           1       0.61      0.65      0.63       167\n",
      "\n",
      "    accuracy                           0.57       294\n",
      "   macro avg       0.56      0.55      0.55       294\n",
      "weighted avg       0.56      0.57      0.57       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6700680272108843 and f1 score is: 0.6614149856934237\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.61       127\n",
      "           1       0.70      0.73      0.72       167\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6870748299319728 and f1 score is: 0.6817582831325301\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64       127\n",
      "           1       0.73      0.72      0.72       167\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[01:31:26] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7346938775510204 and f1 score is: 0.7261262122008312\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68       127\n",
      "           1       0.75      0.80      0.77       167\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7346938775510204 and f1 score is: 0.7310975609756096\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70       127\n",
      "           1       0.78      0.75      0.76       167\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.73      0.74       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7619047619047619 and f1 score is: 0.7553843959492226\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72       131\n",
      "           1       0.76      0.83      0.80       163\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.76      0.75      0.76       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6564625850340136 and f1 score is: 0.6474527170622246\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59       131\n",
      "           1       0.67      0.74      0.70       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6938775510204082 and f1 score is: 0.6875\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64       131\n",
      "           1       0.71      0.75      0.73       163\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.5782312925170068 and f1 score is: 0.5781532052765564\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.63      0.57       131\n",
      "           1       0.64      0.53      0.58       163\n",
      "\n",
      "    accuracy                           0.58       294\n",
      "   macro avg       0.58      0.58      0.58       294\n",
      "weighted avg       0.59      0.58      0.58       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6530612244897959 and f1 score is: 0.6427277926038886\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.54      0.58       131\n",
      "           1       0.67      0.74      0.70       163\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6938775510204082 and f1 score is: 0.6921537602382726\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67       131\n",
      "           1       0.74      0.69      0.72       163\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[01:32:18] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7244897959183674 and f1 score is: 0.7172640602182198\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67       131\n",
      "           1       0.73      0.80      0.76       163\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7414965986394558 and f1 score is: 0.7371046686746988\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.70       131\n",
      "           1       0.76      0.79      0.77       163\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7210884353741497 and f1 score is: 0.7188899253731343\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       138\n",
      "           1       0.73      0.76      0.74       156\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6258503401360545 and f1 score is: 0.6147064430041937\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.49      0.55       138\n",
      "           1       0.62      0.75      0.68       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.62      0.61       294\n",
      "weighted avg       0.63      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7108843537414966 and f1 score is: 0.7071953319976098\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.67       138\n",
      "           1       0.71      0.78      0.74       156\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.5782312925170068 and f1 score is: 0.5710655120481927\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.75      0.63       138\n",
      "           1       0.66      0.42      0.52       156\n",
      "\n",
      "    accuracy                           0.58       294\n",
      "   macro avg       0.60      0.59      0.57       294\n",
      "weighted avg       0.60      0.58      0.57       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6258503401360545 and f1 score is: 0.61646110056926\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.50      0.56       138\n",
      "           1       0.62      0.74      0.68       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6768707482993197 and f1 score is: 0.6762377270566962\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       138\n",
      "           1       0.70      0.68      0.69       156\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[01:33:08] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7074829931972789 and f1 score is: 0.7035178236397748\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67       138\n",
      "           1       0.70      0.78      0.74       156\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6802721088435374 and f1 score is: 0.6799017790956264\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67       138\n",
      "           1       0.71      0.67      0.69       156\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "----- Running Modality Combination EEG_GAZE\n",
      "Saved Directory: 2022_08_12_01_33\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7457627118644068 and f1 score is: 0.7399781405352044\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       131\n",
      "           1       0.75      0.80      0.78       164\n",
      "\n",
      "    accuracy                           0.75       295\n",
      "   macro avg       0.74      0.74      0.74       295\n",
      "weighted avg       0.74      0.75      0.74       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6915254237288135 and f1 score is: 0.6824016563146997\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.59      0.63       131\n",
      "           1       0.70      0.77      0.74       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.69      0.68      0.68       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7423728813559322 and f1 score is: 0.7367803137033907\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       131\n",
      "           1       0.75      0.80      0.78       164\n",
      "\n",
      "    accuracy                           0.74       295\n",
      "   macro avg       0.74      0.74      0.74       295\n",
      "weighted avg       0.74      0.74      0.74       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6474576271186441 and f1 score is: 0.6306106723174725\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.49      0.55       131\n",
      "           1       0.65      0.77      0.71       164\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.64      0.63      0.63       295\n",
      "weighted avg       0.65      0.65      0.64       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.688135593220339 and f1 score is: 0.680705882352941\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63       131\n",
      "           1       0.70      0.76      0.73       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.68      0.68      0.68       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7050847457627119 and f1 score is: 0.7031197584703119\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68       131\n",
      "           1       0.75      0.71      0.73       164\n",
      "\n",
      "    accuracy                           0.71       295\n",
      "   macro avg       0.70      0.70      0.70       295\n",
      "weighted avg       0.71      0.71      0.71       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[01:34:38] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7389830508474576 and f1 score is: 0.7324783002979661\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69       131\n",
      "           1       0.75      0.80      0.77       164\n",
      "\n",
      "    accuracy                           0.74       295\n",
      "   macro avg       0.74      0.73      0.73       295\n",
      "weighted avg       0.74      0.74      0.74       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7322033898305085 and f1 score is: 0.7294049346879534\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70       131\n",
      "           1       0.76      0.75      0.76       164\n",
      "\n",
      "    accuracy                           0.73       295\n",
      "   macro avg       0.73      0.73      0.73       295\n",
      "weighted avg       0.73      0.73      0.73       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7346938775510204 and f1 score is: 0.7310975609756099\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.65      0.70       141\n",
      "           1       0.71      0.82      0.76       153\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6564625850340136 and f1 score is: 0.6530872130381447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62       141\n",
      "           1       0.65      0.73      0.69       153\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6904761904761905 and f1 score is: 0.6865267671974411\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65       141\n",
      "           1       0.68      0.77      0.72       153\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6972789115646258 and f1 score is: 0.6947040498442367\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67       141\n",
      "           1       0.69      0.76      0.72       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6496598639455783 and f1 score is: 0.6451896375971036\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.61       141\n",
      "           1       0.64      0.73      0.69       153\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7142857142857143 and f1 score is: 0.7126768428890544\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       141\n",
      "           1       0.71      0.76      0.73       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[01:36:37] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7040816326530612 and f1 score is: 0.70075460661012\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67       141\n",
      "           1       0.69      0.78      0.73       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7074829931972789 and f1 score is: 0.7058358153387938\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68       141\n",
      "           1       0.71      0.75      0.73       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7346938775510204 and f1 score is: 0.7206140350877193\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66       128\n",
      "           1       0.73      0.85      0.78       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.74      0.72      0.72       294\n",
      "weighted avg       0.74      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7074829931972789 and f1 score is: 0.6929317464172942\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.56      0.63       128\n",
      "           1       0.71      0.82      0.76       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.69      0.69       294\n",
      "weighted avg       0.71      0.71      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7142857142857143 and f1 score is: 0.7050589977547413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65       128\n",
      "           1       0.73      0.79      0.76       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6564625850340136 and f1 score is: 0.6449232903248951\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.58       128\n",
      "           1       0.68      0.74      0.71       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7142857142857143 and f1 score is: 0.6991228070175439\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.56      0.63       128\n",
      "           1       0.71      0.83      0.77       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.70      0.70       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7312925170068028 and f1 score is: 0.7269681545135012\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69       128\n",
      "           1       0.76      0.76      0.76       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[01:38:33] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7108843537414966 and f1 score is: 0.7011730661150107\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.61      0.65       128\n",
      "           1       0.72      0.79      0.76       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7040816326530612 and f1 score is: 0.6982124948380626\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66       128\n",
      "           1       0.73      0.75      0.74       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7278911564625851 and f1 score is: 0.7160654787773433\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66       126\n",
      "           1       0.74      0.82      0.77       168\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.72      0.71      0.72       294\n",
      "weighted avg       0.73      0.73      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6258503401360545 and f1 score is: 0.611764705882353\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.51      0.54       126\n",
      "           1       0.66      0.71      0.69       168\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.61      0.61       294\n",
      "weighted avg       0.62      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7040816326530612 and f1 score is: 0.6898395721925135\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.57      0.62       126\n",
      "           1       0.71      0.80      0.76       168\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.673469387755102 and f1 score is: 0.6637438048036599\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       126\n",
      "           1       0.70      0.74      0.72       168\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6496598639455783 and f1 score is: 0.6316551313084624\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.50      0.55       126\n",
      "           1       0.67      0.76      0.71       168\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.65      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6836734693877551 and f1 score is: 0.6780074191838898\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64       126\n",
      "           1       0.73      0.71      0.72       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[01:40:28] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.673469387755102 and f1 score is: 0.6572261355355842\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.53      0.58       126\n",
      "           1       0.69      0.78      0.73       168\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7074829931972789 and f1 score is: 0.6987704918032787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65       126\n",
      "           1       0.73      0.77      0.75       168\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7108843537414966 and f1 score is: 0.7087785948188461\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68       137\n",
      "           1       0.72      0.75      0.73       157\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6462585034013606 and f1 score is: 0.6430205949656751\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       137\n",
      "           1       0.66      0.69      0.68       157\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6870748299319728 and f1 score is: 0.6853127326880118\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66       137\n",
      "           1       0.70      0.71      0.71       157\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6258503401360545 and f1 score is: 0.6033653846153846\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.42      0.51       137\n",
      "           1       0.61      0.81      0.70       157\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.61      0.60       294\n",
      "weighted avg       0.63      0.63      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6632653061224489 and f1 score is: 0.6618530351437699\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       137\n",
      "           1       0.69      0.68      0.68       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7040816326530612 and f1 score is: 0.7039137833238798\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70       137\n",
      "           1       0.74      0.68      0.71       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.71      0.70       294\n",
      "weighted avg       0.71      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[01:42:24] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7074829931972789 and f1 score is: 0.7055206149545772\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68       137\n",
      "           1       0.72      0.74      0.73       157\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6904761904761905 and f1 score is: 0.6894378213983076\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.68      0.67       137\n",
      "           1       0.71      0.70      0.71       157\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7244897959183674 and f1 score is: 0.7172640602182199\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67       128\n",
      "           1       0.74      0.78      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6700680272108843 and f1 score is: 0.6614149856934237\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       128\n",
      "           1       0.70      0.73      0.72       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7380952380952381 and f1 score is: 0.7318122045704945\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       128\n",
      "           1       0.76      0.79      0.77       166\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6666666666666666 and f1 score is: 0.6210542929292928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.37      0.49       128\n",
      "           1       0.65      0.90      0.75       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.69      0.63      0.62       294\n",
      "weighted avg       0.69      0.67      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6564625850340136 and f1 score is: 0.6474527170622247\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59       128\n",
      "           1       0.69      0.72      0.70       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7482993197278912 and f1 score is: 0.7473522853957637\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73       128\n",
      "           1       0.82      0.72      0.76       166\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.76      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[01:44:19] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7006802721088435 and f1 score is: 0.6931688804554079\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65       128\n",
      "           1       0.72      0.76      0.74       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7346938775510204 and f1 score is: 0.7301863704819276\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       128\n",
      "           1       0.77      0.77      0.77       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7619047619047619 and f1 score is: 0.7418205539943798\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67       111\n",
      "           1       0.79      0.84      0.81       183\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7108843537414966 and f1 score is: 0.6995924844026109\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.68      0.64       111\n",
      "           1       0.79      0.73      0.76       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.71      0.70       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7448979591836735 and f1 score is: 0.7317877169721814\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67       111\n",
      "           1       0.81      0.78      0.79       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.75      0.74      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6836734693877551 and f1 score is: 0.6694432690563985\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.63      0.60       111\n",
      "           1       0.76      0.72      0.74       183\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.69      0.68      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7312925170068028 and f1 score is: 0.7207977207977208\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67       111\n",
      "           1       0.81      0.74      0.77       183\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.72      0.73      0.72       294\n",
      "weighted avg       0.74      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7414965986394558 and f1 score is: 0.7302622048384759\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.71      0.68       111\n",
      "           1       0.81      0.76      0.79       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.74      0.73       294\n",
      "weighted avg       0.75      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[01:46:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7482993197278912 and f1 score is: 0.7331730769230769\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.68      0.67       111\n",
      "           1       0.80      0.79      0.80       183\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7312925170068028 and f1 score is: 0.719204497370489\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.69      0.66       111\n",
      "           1       0.80      0.75      0.78       183\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.74      0.73      0.73       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7619047619047619 and f1 score is: 0.7535919540229885\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71       127\n",
      "           1       0.77      0.83      0.80       167\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.76      0.75      0.75       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7074829931972789 and f1 score is: 0.6956375192604005\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.64       127\n",
      "           1       0.72      0.80      0.76       167\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.69      0.70       294\n",
      "weighted avg       0.71      0.71      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7482993197278912 and f1 score is: 0.7401710218315578\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69       127\n",
      "           1       0.76      0.81      0.79       167\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6768707482993197 and f1 score is: 0.6741223003955337\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       127\n",
      "           1       0.73      0.68      0.70       167\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.68      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6972789115646258 and f1 score is: 0.6836607628604243\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.57      0.62       127\n",
      "           1       0.71      0.80      0.75       167\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.70      0.70      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7142857142857143 and f1 score is: 0.7104127579737336\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.69      0.68       127\n",
      "           1       0.76      0.73      0.74       167\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[01:48:13] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7346938775510204 and f1 score is: 0.7267918414029737\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68       127\n",
      "           1       0.75      0.80      0.77       167\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7380952380952381 and f1 score is: 0.7334039922275216\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       127\n",
      "           1       0.77      0.77      0.77       167\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7517006802721088 and f1 score is: 0.7451885974806178\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.70       131\n",
      "           1       0.75      0.82      0.79       163\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.75       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6700680272108843 and f1 score is: 0.6628559944199464\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.61       131\n",
      "           1       0.69      0.74      0.71       163\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7244897959183674 and f1 score is: 0.7200559558935897\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68       131\n",
      "           1       0.74      0.77      0.76       163\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6530612244897959 and f1 score is: 0.6334523052852883\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.47      0.55       131\n",
      "           1       0.65      0.80      0.72       163\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.63       294\n",
      "weighted avg       0.65      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6768707482993197 and f1 score is: 0.6683961200090234\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62       131\n",
      "           1       0.69      0.75      0.72       163\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6904761904761905 and f1 score is: 0.685494962794033\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65       131\n",
      "           1       0.71      0.74      0.73       163\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[01:50:09] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7210884353741497 and f1 score is: 0.7152777777777777\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67       131\n",
      "           1       0.73      0.78      0.76       163\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7380952380952381 and f1 score is: 0.7343300747556067\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       131\n",
      "           1       0.76      0.77      0.77       163\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7108843537414966 and f1 score is: 0.7019144748613348\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.57      0.65       138\n",
      "           1       0.69      0.83      0.75       156\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.70      0.70       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6122448979591837 and f1 score is: 0.6049318685463718\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55       138\n",
      "           1       0.62      0.71      0.66       156\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.61      0.61      0.60       294\n",
      "weighted avg       0.61      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6700680272108843 and f1 score is: 0.6647583669342989\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.58      0.62       138\n",
      "           1       0.67      0.75      0.71       156\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6496598639455783 and f1 score is: 0.6496233815821445\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.65       138\n",
      "           1       0.69      0.62      0.65       156\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6156462585034014 and f1 score is: 0.6087617028793499\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.51      0.56       138\n",
      "           1       0.62      0.71      0.66       156\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.61      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6462585034013606 and f1 score is: 0.6414634146341465\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60       138\n",
      "           1       0.65      0.72      0.68       156\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[01:52:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7006802721088435 and f1 score is: 0.693168880455408\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.58      0.65       138\n",
      "           1       0.68      0.81      0.74       156\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.71      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6870748299319728 and f1 score is: 0.6817582831325302\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.64       138\n",
      "           1       0.68      0.77      0.72       156\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.68       294\n",
      "\n",
      "----- Running Modality Combination ECG_EDA_EEG\n",
      "Saved Directory: 2022_08_12_01_52\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7661016949152543 and f1 score is: 0.7612624763960074\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.73       131\n",
      "           1       0.77      0.82      0.80       164\n",
      "\n",
      "    accuracy                           0.77       295\n",
      "   macro avg       0.76      0.76      0.76       295\n",
      "weighted avg       0.77      0.77      0.77       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6542372881355932 and f1 score is: 0.6467314736545506\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.60       131\n",
      "           1       0.68      0.72      0.70       164\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.65      0.65      0.65       295\n",
      "weighted avg       0.65      0.65      0.65       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7220338983050848 and f1 score is: 0.7170892589820359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68       131\n",
      "           1       0.74      0.77      0.75       164\n",
      "\n",
      "    accuracy                           0.72       295\n",
      "   macro avg       0.72      0.72      0.72       295\n",
      "weighted avg       0.72      0.72      0.72       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.5898305084745763 and f1 score is: 0.587936507936508\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.59      0.56       131\n",
      "           1       0.64      0.59      0.62       164\n",
      "\n",
      "    accuracy                           0.59       295\n",
      "   macro avg       0.59      0.59      0.59       295\n",
      "weighted avg       0.59      0.59      0.59       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6711864406779661 and f1 score is: 0.6614611061816031\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60       131\n",
      "           1       0.69      0.76      0.72       164\n",
      "\n",
      "    accuracy                           0.67       295\n",
      "   macro avg       0.67      0.66      0.66       295\n",
      "weighted avg       0.67      0.67      0.67       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6847457627118644 and f1 score is: 0.6826452590544714\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66       131\n",
      "           1       0.73      0.69      0.71       164\n",
      "\n",
      "    accuracy                           0.68       295\n",
      "   macro avg       0.68      0.68      0.68       295\n",
      "weighted avg       0.69      0.68      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[01:54:11] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7389830508474576 and f1 score is: 0.7324783002979661\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69       131\n",
      "           1       0.75      0.80      0.77       164\n",
      "\n",
      "    accuracy                           0.74       295\n",
      "   macro avg       0.74      0.73      0.73       295\n",
      "weighted avg       0.74      0.74      0.74       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7254237288135593 and f1 score is: 0.7225544267053701\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69       131\n",
      "           1       0.76      0.74      0.75       164\n",
      "\n",
      "    accuracy                           0.73       295\n",
      "   macro avg       0.72      0.72      0.72       295\n",
      "weighted avg       0.73      0.73      0.73       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7074829931972789 and f1 score is: 0.7013888888888888\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66       141\n",
      "           1       0.68      0.82      0.74       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6972789115646258 and f1 score is: 0.6912748510412365\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.58      0.65       141\n",
      "           1       0.68      0.80      0.73       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7006802721088435 and f1 score is: 0.6995540691192865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68       141\n",
      "           1       0.70      0.73      0.72       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.5816326530612245 and f1 score is: 0.5810461681051962\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.60       141\n",
      "           1       0.62      0.52      0.57       153\n",
      "\n",
      "    accuracy                           0.58       294\n",
      "   macro avg       0.59      0.58      0.58       294\n",
      "weighted avg       0.59      0.58      0.58       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6904761904761905 and f1 score is: 0.6869961977186312\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.65       141\n",
      "           1       0.68      0.76      0.72       153\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7210884353741497 and f1 score is: 0.720623000973439\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       141\n",
      "           1       0.73      0.73      0.73       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[01:56:29] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7142857142857143 and f1 score is: 0.7120335820895523\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.69       141\n",
      "           1       0.71      0.77      0.74       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.717687074829932 and f1 score is: 0.7167399909457091\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       141\n",
      "           1       0.72      0.75      0.73       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7278911564625851 and f1 score is: 0.7183908045977012\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.67       128\n",
      "           1       0.74      0.81      0.77       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6496598639455783 and f1 score is: 0.6304684735255714\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.48      0.55       128\n",
      "           1       0.66      0.78      0.71       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.65      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7040816326530612 and f1 score is: 0.6916641552649028\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.58      0.63       128\n",
      "           1       0.71      0.80      0.75       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.608843537414966 and f1 score is: 0.5693816468190791\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.35      0.44       128\n",
      "           1       0.62      0.81      0.70       166\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.58      0.57       294\n",
      "weighted avg       0.60      0.61      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6700680272108843 and f1 score is: 0.6541889483065952\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58       128\n",
      "           1       0.68      0.78      0.73       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.65      0.65       294\n",
      "weighted avg       0.67      0.67      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.717687074829932 and f1 score is: 0.7096209912536442\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66       128\n",
      "           1       0.73      0.78      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[01:58:46] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7142857142857143 and f1 score is: 0.6991228070175439\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.56      0.63       128\n",
      "           1       0.71      0.83      0.77       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.70      0.70       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7210884353741497 and f1 score is: 0.7158281861473903\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.68       128\n",
      "           1       0.75      0.76      0.75       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7517006802721088 and f1 score is: 0.7439971372338523\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       126\n",
      "           1       0.77      0.81      0.79       168\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6360544217687075 and f1 score is: 0.6238296244036017\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.53      0.56       126\n",
      "           1       0.67      0.71      0.69       168\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.62      0.62       294\n",
      "weighted avg       0.63      0.64      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7244897959183674 and f1 score is: 0.7159420289855072\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67       126\n",
      "           1       0.75      0.79      0.77       168\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6054421768707483 and f1 score is: 0.5626122197711999\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.34      0.43       126\n",
      "           1       0.62      0.80      0.70       168\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.59      0.57      0.56       294\n",
      "weighted avg       0.60      0.61      0.58       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6360544217687075 and f1 score is: 0.6247629271783861\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56       126\n",
      "           1       0.67      0.71      0.69       168\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.62      0.62       294\n",
      "weighted avg       0.63      0.64      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6836734693877551 and f1 score is: 0.6785827641741216\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64       126\n",
      "           1       0.73      0.71      0.72       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.69      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[02:01:03] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7244897959183674 and f1 score is: 0.7152355100625396\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66       126\n",
      "           1       0.74      0.79      0.77       168\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7210884353741497 and f1 score is: 0.7163497740963856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68       126\n",
      "           1       0.76      0.74      0.75       168\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7244897959183674 and f1 score is: 0.7221463824425076\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70       137\n",
      "           1       0.73      0.76      0.75       157\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6530612244897959 and f1 score is: 0.6494107744107744\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.61       137\n",
      "           1       0.66      0.71      0.69       157\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6836734693877551 and f1 score is: 0.6820512820512821\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       137\n",
      "           1       0.70      0.71      0.70       157\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6326530612244898 and f1 score is: 0.630584512285927\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.60       137\n",
      "           1       0.65      0.66      0.66       157\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6462585034013606 and f1 score is: 0.6420175151032641\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.58      0.60       137\n",
      "           1       0.66      0.71      0.68       157\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7006802721088435 and f1 score is: 0.6995540691192865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68       137\n",
      "           1       0.72      0.71      0.72       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[02:03:20] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7006802721088435 and f1 score is: 0.6983208955223881\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67       137\n",
      "           1       0.71      0.74      0.72       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7040816326530612 and f1 score is: 0.7038040646169881\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.69       137\n",
      "           1       0.74      0.69      0.71       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.71      0.70       294\n",
      "weighted avg       0.71      0.70      0.70       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.717687074829932 and f1 score is: 0.7136285221391604\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68       128\n",
      "           1       0.75      0.74      0.75       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6530612244897959 and f1 score is: 0.64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57       128\n",
      "           1       0.67      0.75      0.71       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7108843537414966 and f1 score is: 0.7076338110558643\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68       128\n",
      "           1       0.75      0.72      0.74       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6292517006802721 and f1 score is: 0.629213093130619\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.71      0.63       128\n",
      "           1       0.72      0.57      0.63       166\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.64      0.64      0.63       294\n",
      "weighted avg       0.65      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6224489795918368 and f1 score is: 0.6087566388126266\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.50      0.54       128\n",
      "           1       0.65      0.72      0.68       166\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.62      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6632653061224489 and f1 score is: 0.6599567731760032\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63       128\n",
      "           1       0.71      0.67      0.69       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.67      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[02:05:37] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7142857142857143 and f1 score is: 0.7064612751390672\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66       128\n",
      "           1       0.73      0.78      0.75       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7312925170068028 and f1 score is: 0.7299145299145299\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.71       128\n",
      "           1       0.79      0.71      0.75       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.73      0.73       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7517006802721088 and f1 score is: 0.7334144856968958\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66       111\n",
      "           1       0.79      0.81      0.80       183\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7108843537414966 and f1 score is: 0.6940312213039486\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62       111\n",
      "           1       0.77      0.76      0.77       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.69      0.70      0.69       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.717687074829932 and f1 score is: 0.696895922093731\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.62       111\n",
      "           1       0.77      0.79      0.78       183\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6496598639455783 and f1 score is: 0.6378920683511305\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.62      0.57       111\n",
      "           1       0.74      0.67      0.70       183\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.66      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7142857142857143 and f1 score is: 0.6981371925878843\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       111\n",
      "           1       0.78      0.76      0.77       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.72      0.71      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7414965986394558 and f1 score is: 0.7259615384615384\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       111\n",
      "           1       0.80      0.79      0.79       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[02:07:54] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7448979591836735 and f1 score is: 0.7250452023193465\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65       111\n",
      "           1       0.78      0.81      0.80       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.72      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7653061224489796 and f1 score is: 0.7547482318805537\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70       111\n",
      "           1       0.83      0.78      0.81       183\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.75      0.76      0.75       294\n",
      "weighted avg       0.77      0.77      0.77       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7721088435374149 and f1 score is: 0.7661320004274164\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73       127\n",
      "           1       0.79      0.82      0.80       167\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.77      0.76      0.77       294\n",
      "weighted avg       0.77      0.77      0.77       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6870748299319728 and f1 score is: 0.6752941176470588\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.57      0.61       127\n",
      "           1       0.70      0.77      0.74       167\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.67      0.68       294\n",
      "weighted avg       0.68      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7380952380952381 and f1 score is: 0.7312263288494187\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       127\n",
      "           1       0.76      0.79      0.77       167\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6564625850340136 and f1 score is: 0.6410082814483467\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.52      0.57       127\n",
      "           1       0.68      0.76      0.72       167\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6768707482993197 and f1 score is: 0.6651520782630588\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60       127\n",
      "           1       0.70      0.76      0.73       167\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.66      0.67       294\n",
      "weighted avg       0.67      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7142857142857143 and f1 score is: 0.7099365750528541\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.69      0.67       127\n",
      "           1       0.75      0.74      0.75       167\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[02:10:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7551020408163265 and f1 score is: 0.747807853602745\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.70       127\n",
      "           1       0.77      0.81      0.79       167\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.75      0.76      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7346938775510204 and f1 score is: 0.7310975609756096\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70       127\n",
      "           1       0.78      0.75      0.76       167\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.73      0.74       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7278911564625851 and f1 score is: 0.7222222222222222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68       131\n",
      "           1       0.74      0.79      0.76       163\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6768707482993197 and f1 score is: 0.6668455895509036\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.61       131\n",
      "           1       0.69      0.77      0.72       163\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7142857142857143 and f1 score is: 0.7083333333333333\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67       131\n",
      "           1       0.73      0.77      0.75       163\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.608843537414966 and f1 score is: 0.605000292073135\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.57      0.57       131\n",
      "           1       0.65      0.64      0.64       163\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.61      0.61       294\n",
      "weighted avg       0.61      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6564625850340136 and f1 score is: 0.6496489882602796\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60       131\n",
      "           1       0.68      0.72      0.70       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6836734693877551 and f1 score is: 0.6796372455973847\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64       131\n",
      "           1       0.71      0.72      0.72       163\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[02:12:27] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7278911564625851 and f1 score is: 0.7222222222222222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68       131\n",
      "           1       0.74      0.79      0.76       163\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7278911564625851 and f1 score is: 0.7260656883298392\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.70       131\n",
      "           1       0.77      0.73      0.75       163\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.717687074829932 and f1 score is: 0.714084853597666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68       138\n",
      "           1       0.71      0.78      0.75       156\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.5952380952380952 and f1 score is: 0.5887241821152739\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.50      0.54       138\n",
      "           1       0.61      0.68      0.64       156\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.59      0.59      0.59       294\n",
      "weighted avg       0.59      0.60      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6938775510204082 and f1 score is: 0.6914645522388059\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66       138\n",
      "           1       0.70      0.74      0.72       156\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.608843537414966 and f1 score is: 0.6059945694607918\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.57       138\n",
      "           1       0.63      0.65      0.64       156\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.61      0.61      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.5884353741496599 and f1 score is: 0.5831839431965974\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.51      0.54       138\n",
      "           1       0.60      0.66      0.63       156\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.59      0.58      0.58       294\n",
      "weighted avg       0.59      0.59      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6768707482993197 and f1 score is: 0.6764177721137694\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.66       138\n",
      "           1       0.70      0.67      0.69       156\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[02:14:44] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.717687074829932 and f1 score is: 0.7136285221391605\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68       138\n",
      "           1       0.71      0.79      0.75       156\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7414965986394558 and f1 score is: 0.7400409530900969\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72       138\n",
      "           1       0.75      0.77      0.76       156\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "----- Running Modality Combination ECG_EDA_GAZE\n",
      "Saved Directory: 2022_08_12_02_15\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7593220338983051 and f1 score is: 0.7533241470279948\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71       131\n",
      "           1       0.76      0.82      0.79       164\n",
      "\n",
      "    accuracy                           0.76       295\n",
      "   macro avg       0.76      0.75      0.75       295\n",
      "weighted avg       0.76      0.76      0.76       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6610169491525424 and f1 score is: 0.6505732966928834\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.55      0.59       131\n",
      "           1       0.68      0.75      0.71       164\n",
      "\n",
      "    accuracy                           0.66       295\n",
      "   macro avg       0.66      0.65      0.65       295\n",
      "weighted avg       0.66      0.66      0.66       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6983050847457627 and f1 score is: 0.6926543751829091\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65       131\n",
      "           1       0.72      0.75      0.73       164\n",
      "\n",
      "    accuracy                           0.70       295\n",
      "   macro avg       0.69      0.69      0.69       295\n",
      "weighted avg       0.70      0.70      0.70       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6033898305084746 and f1 score is: 0.6033898305084747\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.68      0.60       131\n",
      "           1       0.68      0.54      0.60       164\n",
      "\n",
      "    accuracy                           0.60       295\n",
      "   macro avg       0.61      0.61      0.60       295\n",
      "weighted avg       0.62      0.60      0.60       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6711864406779661 and f1 score is: 0.6614611061816031\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60       131\n",
      "           1       0.69      0.76      0.72       164\n",
      "\n",
      "    accuracy                           0.67       295\n",
      "   macro avg       0.67      0.66      0.66       295\n",
      "weighted avg       0.67      0.67      0.67       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.711864406779661 and f1 score is: 0.7059030506327628\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66       131\n",
      "           1       0.73      0.77      0.75       164\n",
      "\n",
      "    accuracy                           0.71       295\n",
      "   macro avg       0.71      0.70      0.71       295\n",
      "weighted avg       0.71      0.71      0.71       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[02:16:26] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7254237288135593 and f1 score is: 0.7166186359269933\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67       131\n",
      "           1       0.73      0.81      0.77       164\n",
      "\n",
      "    accuracy                           0.73       295\n",
      "   macro avg       0.72      0.71      0.72       295\n",
      "weighted avg       0.73      0.73      0.72       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7322033898305085 and f1 score is: 0.7285982135578613\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.70       131\n",
      "           1       0.76      0.76      0.76       164\n",
      "\n",
      "    accuracy                           0.73       295\n",
      "   macro avg       0.73      0.73      0.73       295\n",
      "weighted avg       0.73      0.73      0.73       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7619047619047619 and f1 score is: 0.7593995510662177\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.73       141\n",
      "           1       0.74      0.83      0.78       153\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.77      0.76      0.76       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6938775510204082 and f1 score is: 0.6886765813253013\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.59      0.65       141\n",
      "           1       0.68      0.79      0.73       153\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7210884353741497 and f1 score is: 0.7177445792160353\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.69       141\n",
      "           1       0.71      0.80      0.75       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6020408163265306 and f1 score is: 0.5841383062322432\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.41      0.50       141\n",
      "           1       0.59      0.78      0.67       153\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.61      0.59      0.58       294\n",
      "weighted avg       0.61      0.60      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6904761904761905 and f1 score is: 0.6860264519838988\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65       141\n",
      "           1       0.68      0.78      0.72       153\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7551020408163265 and f1 score is: 0.7550566998380006\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       141\n",
      "           1       0.78      0.74      0.76       153\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.76      0.76      0.76       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[02:17:36] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7448979591836735 and f1 score is: 0.742029833284586\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.71       141\n",
      "           1       0.73      0.82      0.77       153\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7517006802721088 and f1 score is: 0.7508677028799611\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74       141\n",
      "           1       0.75      0.78      0.77       153\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7448979591836735 and f1 score is: 0.7349345450611273\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68       128\n",
      "           1       0.75      0.83      0.79       166\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6666666666666666 and f1 score is: 0.6511526540100737\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.52      0.58       128\n",
      "           1       0.68      0.78      0.72       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.67      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7142857142857143 and f1 score is: 0.7027157164869029\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.59      0.64       128\n",
      "           1       0.72      0.81      0.76       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6462585034013606 and f1 score is: 0.6414634146341464\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60       128\n",
      "           1       0.69      0.67      0.68       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6768707482993197 and f1 score is: 0.661319073083779\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.53      0.59       128\n",
      "           1       0.69      0.79      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6904761904761905 and f1 score is: 0.686526767197441\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65       128\n",
      "           1       0.73      0.71      0.72       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[02:18:46] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7278911564625851 and f1 score is: 0.7160654787773432\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.60      0.66       128\n",
      "           1       0.73      0.83      0.77       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.71      0.72       294\n",
      "weighted avg       0.73      0.73      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7551020408163265 and f1 score is: 0.749491124260355\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.71       128\n",
      "           1       0.77      0.80      0.79       166\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.75      0.76      0.75       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7346938775510204 and f1 score is: 0.7261262122008312\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68       126\n",
      "           1       0.75      0.80      0.77       168\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6836734693877551 and f1 score is: 0.6722015081943629\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.58      0.61       126\n",
      "           1       0.71      0.76      0.73       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7244897959183674 and f1 score is: 0.7184673767836667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.68       126\n",
      "           1       0.76      0.76      0.76       168\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6020408163265306 and f1 score is: 0.5727328058429701\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.40      0.46       126\n",
      "           1       0.63      0.76      0.68       168\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.59      0.58      0.57       294\n",
      "weighted avg       0.59      0.60      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6632653061224489 and f1 score is: 0.6510532184004509\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59       126\n",
      "           1       0.69      0.74      0.72       168\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6870748299319728 and f1 score is: 0.681173086897072\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64       126\n",
      "           1       0.73      0.72      0.72       168\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[02:19:56] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7448979591836735 and f1 score is: 0.7363291759838331\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69       126\n",
      "           1       0.76      0.81      0.78       168\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7380952380952381 and f1 score is: 0.7347534183978348\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.70       126\n",
      "           1       0.79      0.74      0.76       168\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.74      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7414965986394558 and f1 score is: 0.740294760332884\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72       137\n",
      "           1       0.76      0.76      0.76       157\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6598639455782312 and f1 score is: 0.6520710059171597\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60       137\n",
      "           1       0.66      0.76      0.70       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7006802721088435 and f1 score is: 0.6997911348340682\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68       137\n",
      "           1       0.73      0.71      0.72       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.5748299319727891 and f1 score is: 0.5582242417685456\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.41      0.47       137\n",
      "           1       0.58      0.72      0.64       157\n",
      "\n",
      "    accuracy                           0.57       294\n",
      "   macro avg       0.57      0.56      0.56       294\n",
      "weighted avg       0.57      0.57      0.56       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6496598639455783 and f1 score is: 0.6404715827466252\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.53      0.58       137\n",
      "           1       0.65      0.76      0.70       157\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6938775510204082 and f1 score is: 0.6929682060802971\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68       137\n",
      "           1       0.72      0.70      0.71       157\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[02:21:06] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7040816326530612 and f1 score is: 0.703501918462448\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69       137\n",
      "           1       0.73      0.70      0.72       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7108843537414966 and f1 score is: 0.7108542469367212\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71       137\n",
      "           1       0.77      0.66      0.71       157\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7312925170068028 and f1 score is: 0.7254187995791316\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.69       128\n",
      "           1       0.75      0.78      0.77       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6598639455782312 and f1 score is: 0.6488797592318349\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.59       128\n",
      "           1       0.68      0.74      0.71       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7414965986394558 and f1 score is: 0.7361111111111112\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       128\n",
      "           1       0.76      0.78      0.77       166\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.5850340136054422 and f1 score is: 0.5230319148936171\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.26      0.35       128\n",
      "           1       0.59      0.84      0.70       166\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.57      0.55      0.52       294\n",
      "weighted avg       0.57      0.59      0.55       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6598639455782312 and f1 score is: 0.650549137070318\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.59       128\n",
      "           1       0.69      0.73      0.71       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6870748299319728 and f1 score is: 0.6805555555555556\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63       128\n",
      "           1       0.72      0.73      0.73       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[02:22:16] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7312925170068028 and f1 score is: 0.7248462878060916\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68       128\n",
      "           1       0.75      0.78      0.77       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7380952380952381 and f1 score is: 0.7343300747556067\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70       128\n",
      "           1       0.77      0.76      0.77       166\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7653061224489796 and f1 score is: 0.7470415861337989\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68       111\n",
      "           1       0.80      0.83      0.82       183\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.75      0.74      0.75       294\n",
      "weighted avg       0.76      0.77      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6938775510204082 and f1 score is: 0.676575563487019\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60       111\n",
      "           1       0.76      0.74      0.75       183\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.70      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7210884353741497 and f1 score is: 0.6999701314217444\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62       111\n",
      "           1       0.77      0.79      0.78       183\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6802721088435374 and f1 score is: 0.628228583727938\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.41      0.49       111\n",
      "           1       0.70      0.85      0.77       183\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.66      0.63      0.63       294\n",
      "weighted avg       0.67      0.68      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7006802721088435 and f1 score is: 0.684795321637427\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.61       111\n",
      "           1       0.77      0.74      0.76       183\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.68      0.69      0.68       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7142857142857143 and f1 score is: 0.6991228070175438\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.63       111\n",
      "           1       0.78      0.75      0.77       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.72      0.71      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[02:23:26] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7653061224489796 and f1 score is: 0.7460281690140844\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68       111\n",
      "           1       0.80      0.84      0.82       183\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.75      0.74      0.75       294\n",
      "weighted avg       0.76      0.77      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7448979591836735 and f1 score is: 0.7300275482093664\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.68      0.67       111\n",
      "           1       0.80      0.79      0.79       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.75      0.74      0.75       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7210884353741497 and f1 score is: 0.7127811666031261\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66       127\n",
      "           1       0.74      0.78      0.76       167\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6768707482993197 and f1 score is: 0.661319073083779\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.54      0.59       127\n",
      "           1       0.69      0.78      0.73       167\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7312925170068028 and f1 score is: 0.7264794205970675\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       127\n",
      "           1       0.77      0.76      0.76       167\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6292517006802721 and f1 score is: 0.5954349774652511\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.39      0.48       127\n",
      "           1       0.64      0.81      0.71       167\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.60      0.60       294\n",
      "weighted avg       0.63      0.63      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6598639455782312 and f1 score is: 0.6470588235294117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58       127\n",
      "           1       0.68      0.75      0.71       167\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7108843537414966 and f1 score is: 0.706728004600345\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.69      0.67       127\n",
      "           1       0.75      0.73      0.74       167\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[02:24:36] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7380952380952381 and f1 score is: 0.7299695831096797\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68       127\n",
      "           1       0.75      0.80      0.78       167\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7414965986394558 and f1 score is: 0.7379924953095685\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.71       127\n",
      "           1       0.78      0.75      0.77       167\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7721088435374149 and f1 score is: 0.7666417883925081\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.73       131\n",
      "           1       0.77      0.83      0.80       163\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.77      0.76      0.77       294\n",
      "weighted avg       0.77      0.77      0.77       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6632653061224489 and f1 score is: 0.6551871201620642\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60       131\n",
      "           1       0.68      0.74      0.71       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7278911564625851 and f1 score is: 0.7222222222222222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68       131\n",
      "           1       0.74      0.79      0.76       163\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6258503401360545 and f1 score is: 0.6237434847356664\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.60       131\n",
      "           1       0.67      0.63      0.65       163\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.63      0.62       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6394557823129252 and f1 score is: 0.6326559479466265\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58       131\n",
      "           1       0.67      0.70      0.68       163\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7312925170068028 and f1 score is: 0.7269681545135012\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69       131\n",
      "           1       0.75      0.77      0.76       163\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[02:25:46] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7380952380952381 and f1 score is: 0.7323702223745966\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69       131\n",
      "           1       0.75      0.80      0.77       163\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7108843537414966 and f1 score is: 0.7084252161433722\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68       131\n",
      "           1       0.75      0.72      0.74       163\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7210884353741497 and f1 score is: 0.7195178704393149\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       138\n",
      "           1       0.73      0.75      0.74       156\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6530612244897959 and f1 score is: 0.6477801268498943\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.60       138\n",
      "           1       0.66      0.73      0.69       156\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7312925170068028 and f1 score is: 0.7286523745545885\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       138\n",
      "           1       0.73      0.78      0.76       156\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6904761904761905 and f1 score is: 0.6800794001937174\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.54      0.62       138\n",
      "           1       0.67      0.82      0.74       156\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.70      0.68      0.68       294\n",
      "weighted avg       0.70      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6496598639455783 and f1 score is: 0.6446233467510063\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60       138\n",
      "           1       0.65      0.72      0.69       156\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7142857142857143 and f1 score is: 0.7136363636363636\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70       138\n",
      "           1       0.74      0.72      0.73       156\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[02:26:57] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7074829931972789 and f1 score is: 0.7058358153387938\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68       138\n",
      "           1       0.72      0.74      0.73       156\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7006802721088435 and f1 score is: 0.7004584819154356\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.69       138\n",
      "           1       0.73      0.69      0.71       156\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "----- Running Modality Combination ECG_EEG_GAZE\n",
      "Saved Directory: 2022_08_12_02_27\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7627118644067796 and f1 score is: 0.7580380577427821\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72       131\n",
      "           1       0.77      0.81      0.79       164\n",
      "\n",
      "    accuracy                           0.76       295\n",
      "   macro avg       0.76      0.76      0.76       295\n",
      "weighted avg       0.76      0.76      0.76       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6610169491525424 and f1 score is: 0.6555991407490427\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61       131\n",
      "           1       0.69      0.71      0.70       164\n",
      "\n",
      "    accuracy                           0.66       295\n",
      "   macro avg       0.66      0.66      0.66       295\n",
      "weighted avg       0.66      0.66      0.66       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.752542372881356 and f1 score is: 0.7492110074648592\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72       131\n",
      "           1       0.78      0.78      0.78       164\n",
      "\n",
      "    accuracy                           0.75       295\n",
      "   macro avg       0.75      0.75      0.75       295\n",
      "weighted avg       0.75      0.75      0.75       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6271186440677966 and f1 score is: 0.6027957305131219\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.43      0.50       131\n",
      "           1       0.63      0.79      0.70       164\n",
      "\n",
      "    accuracy                           0.63       295\n",
      "   macro avg       0.62      0.61      0.60       295\n",
      "weighted avg       0.62      0.63      0.61       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6915254237288135 and f1 score is: 0.6873726257438657\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       131\n",
      "           1       0.72      0.73      0.72       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.69      0.69      0.69       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7288135593220338 and f1 score is: 0.7249417249417249\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69       131\n",
      "           1       0.75      0.76      0.76       164\n",
      "\n",
      "    accuracy                           0.73       295\n",
      "   macro avg       0.73      0.72      0.72       295\n",
      "weighted avg       0.73      0.73      0.73       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[02:28:44] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7186440677966102 and f1 score is: 0.714390696263808\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68       131\n",
      "           1       0.74      0.76      0.75       164\n",
      "\n",
      "    accuracy                           0.72       295\n",
      "   macro avg       0.72      0.71      0.71       295\n",
      "weighted avg       0.72      0.72      0.72       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7627118644067796 and f1 score is: 0.7612606363300036\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       131\n",
      "           1       0.81      0.76      0.78       164\n",
      "\n",
      "    accuracy                           0.76       295\n",
      "   macro avg       0.76      0.76      0.76       295\n",
      "weighted avg       0.77      0.76      0.76       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7244897959183674 and f1 score is: 0.7209743751977222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69       141\n",
      "           1       0.71      0.80      0.75       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6564625850340136 and f1 score is: 0.6530872130381447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62       141\n",
      "           1       0.65      0.73      0.69       153\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7108843537414966 and f1 score is: 0.7087785948188461\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68       141\n",
      "           1       0.70      0.76      0.73       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6802721088435374 and f1 score is: 0.6707491422035836\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.53      0.61       141\n",
      "           1       0.65      0.82      0.73       153\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.69      0.67      0.67       294\n",
      "weighted avg       0.69      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6768707482993197 and f1 score is: 0.6741223003955337\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.64       141\n",
      "           1       0.67      0.74      0.70       153\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.717687074829932 and f1 score is: 0.7162393162393161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.70       141\n",
      "           1       0.72      0.76      0.74       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[02:30:56] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7312925170068028 and f1 score is: 0.729637864201986\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71       141\n",
      "           1       0.73      0.78      0.75       153\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7210884353741497 and f1 score is: 0.7207653817642699\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71       141\n",
      "           1       0.74      0.73      0.73       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7414965986394558 and f1 score is: 0.7294653235180163\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67       128\n",
      "           1       0.74      0.84      0.79       166\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.717687074829932 and f1 score is: 0.7066608965343144\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65       128\n",
      "           1       0.72      0.81      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.70      0.71       294\n",
      "weighted avg       0.72      0.72      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7244897959183674 and f1 score is: 0.7166180758017493\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67       128\n",
      "           1       0.74      0.79      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7006802721088435 and f1 score is: 0.6910141881240148\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64       128\n",
      "           1       0.72      0.78      0.75       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7517006802721088 and f1 score is: 0.7433603979575975\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70       128\n",
      "           1       0.76      0.83      0.79       166\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7312925170068028 and f1 score is: 0.7264794205970675\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       128\n",
      "           1       0.76      0.77      0.76       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[02:33:09] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7278911564625851 and f1 score is: 0.7176470588235295\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.66       128\n",
      "           1       0.73      0.81      0.77       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7006802721088435 and f1 score is: 0.6938224852071005\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65       128\n",
      "           1       0.73      0.75      0.74       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7346938775510204 and f1 score is: 0.7214962351226621\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.60      0.66       126\n",
      "           1       0.74      0.83      0.78       168\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6700680272108843 and f1 score is: 0.6562232535712134\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.59       126\n",
      "           1       0.69      0.76      0.73       168\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.65      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7074829931972789 and f1 score is: 0.6964705882352942\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64       126\n",
      "           1       0.73      0.79      0.75       168\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.69      0.70       294\n",
      "weighted avg       0.71      0.71      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6904761904761905 and f1 score is: 0.6755793226381461\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61       126\n",
      "           1       0.70      0.79      0.75       168\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.67      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6836734693877551 and f1 score is: 0.6684491978609625\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60       126\n",
      "           1       0.70      0.79      0.74       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6938775510204082 and f1 score is: 0.6906565656565657\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.69      0.66       126\n",
      "           1       0.75      0.70      0.72       168\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.69      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[02:35:21] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7108843537414966 and f1 score is: 0.6987523356036405\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64       126\n",
      "           1       0.72      0.80      0.76       168\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.717687074829932 and f1 score is: 0.708928251923421\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.66       126\n",
      "           1       0.74      0.78      0.76       168\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7278911564625851 and f1 score is: 0.7266260635082988\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       137\n",
      "           1       0.75      0.75      0.75       157\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6598639455782312 and f1 score is: 0.6571828358208955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.63       137\n",
      "           1       0.67      0.70      0.69       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6700680272108843 and f1 score is: 0.6672617172459661\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.64       137\n",
      "           1       0.68      0.71      0.70       157\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6564625850340136 and f1 score is: 0.6466472303206997\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.53      0.59       137\n",
      "           1       0.65      0.77      0.71       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6700680272108843 and f1 score is: 0.6686842869590472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.65       137\n",
      "           1       0.69      0.69      0.69       157\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7108843537414966 and f1 score is: 0.7104790592596884\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70       137\n",
      "           1       0.74      0.70      0.72       157\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[02:37:33] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6564625850340136 and f1 score is: 0.6543471428405135\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.63       137\n",
      "           1       0.68      0.69      0.68       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7006802721088435 and f1 score is: 0.6995540691192865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68       137\n",
      "           1       0.72      0.71      0.72       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7210884353741497 and f1 score is: 0.7127811666031263\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66       128\n",
      "           1       0.74      0.79      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6836734693877551 and f1 score is: 0.6738593666129897\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62       128\n",
      "           1       0.70      0.76      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7040816326530612 and f1 score is: 0.6969826207484806\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65       128\n",
      "           1       0.73      0.76      0.74       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.673469387755102 and f1 score is: 0.6690431519699813\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       128\n",
      "           1       0.72      0.70      0.71       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6530612244897959 and f1 score is: 0.640948275862069\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58       128\n",
      "           1       0.68      0.74      0.71       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7108843537414966 and f1 score is: 0.7087785948188461\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.72      0.68       128\n",
      "           1       0.76      0.70      0.73       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[02:39:47] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6904761904761905 and f1 score is: 0.6808731436750761\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.59      0.63       128\n",
      "           1       0.71      0.77      0.74       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7619047619047619 and f1 score is: 0.7578595632530121\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       128\n",
      "           1       0.79      0.79      0.79       166\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.76      0.76      0.76       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7721088435374149 and f1 score is: 0.7513224173410258\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68       111\n",
      "           1       0.80      0.85      0.82       183\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.76      0.75      0.75       294\n",
      "weighted avg       0.77      0.77      0.77       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7312925170068028 and f1 score is: 0.7222667320363041\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67       111\n",
      "           1       0.82      0.73      0.77       183\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.72      0.73      0.72       294\n",
      "weighted avg       0.74      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7380952380952381 and f1 score is: 0.7208872230510314\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       111\n",
      "           1       0.79      0.79      0.79       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.717687074829932 and f1 score is: 0.6815815228028969\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57       111\n",
      "           1       0.74      0.85      0.79       183\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.70      0.68      0.68       294\n",
      "weighted avg       0.71      0.72      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7482993197278912 and f1 score is: 0.7373605678690425\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.72      0.68       111\n",
      "           1       0.82      0.77      0.79       183\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.73      0.74      0.74       294\n",
      "weighted avg       0.76      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7687074829931972 and f1 score is: 0.7606321839080459\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.72       111\n",
      "           1       0.85      0.77      0.80       183\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.76      0.77      0.76       294\n",
      "weighted avg       0.78      0.77      0.77       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[02:41:59] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7312925170068028 and f1 score is: 0.7125886327356424\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64       111\n",
      "           1       0.78      0.79      0.79       183\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7210884353741497 and f1 score is: 0.7097939137134052\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       111\n",
      "           1       0.80      0.74      0.77       183\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.72      0.71       294\n",
      "weighted avg       0.73      0.72      0.72       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7585034013605442 and f1 score is: 0.751603498542274\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       127\n",
      "           1       0.77      0.81      0.79       167\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.76      0.75      0.75       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6768707482993197 and f1 score is: 0.6623345221543856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.54      0.59       127\n",
      "           1       0.69      0.78      0.73       167\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7210884353741497 and f1 score is: 0.7127811666031261\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66       127\n",
      "           1       0.74      0.78      0.76       167\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6394557823129252 and f1 score is: 0.6248555469953775\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55       127\n",
      "           1       0.66      0.74      0.70       167\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.62      0.62       294\n",
      "weighted avg       0.64      0.64      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6972789115646258 and f1 score is: 0.6817214241403218\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61       127\n",
      "           1       0.70      0.81      0.75       167\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.70      0.70      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7006802721088435 and f1 score is: 0.6970917435489158\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66       127\n",
      "           1       0.75      0.71      0.73       167\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[02:44:14] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7517006802721088 and f1 score is: 0.7433603979575975\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70       127\n",
      "           1       0.76      0.82      0.79       167\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7414965986394558 and f1 score is: 0.7344173441734418\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       127\n",
      "           1       0.76      0.80      0.78       167\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7380952380952381 and f1 score is: 0.7312263288494188\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69       131\n",
      "           1       0.74      0.81      0.77       163\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6564625850340136 and f1 score is: 0.6482212033976615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59       131\n",
      "           1       0.68      0.73      0.70       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7244897959183674 and f1 score is: 0.7209743751977222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       131\n",
      "           1       0.75      0.75      0.75       163\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6428571428571429 and f1 score is: 0.6326530612244898\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.53      0.57       131\n",
      "           1       0.66      0.73      0.69       163\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6530612244897959 and f1 score is: 0.6427277926038886\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.54      0.58       131\n",
      "           1       0.67      0.74      0.70       163\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6938775510204082 and f1 score is: 0.6906565656565657\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66       131\n",
      "           1       0.73      0.72      0.72       163\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[02:46:27] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7312925170068028 and f1 score is: 0.7248462878060916\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68       131\n",
      "           1       0.74      0.80      0.77       163\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7517006802721088 and f1 score is: 0.7485324615979473\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72       131\n",
      "           1       0.77      0.78      0.78       163\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7278911564625851 and f1 score is: 0.7227592059974538\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.69       138\n",
      "           1       0.71      0.81      0.76       156\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6428571428571429 and f1 score is: 0.6388417665984206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.60       138\n",
      "           1       0.65      0.71      0.68       156\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6972789115646258 and f1 score is: 0.6924071614139442\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.65       138\n",
      "           1       0.69      0.78      0.73       156\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6258503401360545 and f1 score is: 0.6187939082464992\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.52      0.57       138\n",
      "           1       0.63      0.72      0.67       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6258503401360545 and f1 score is: 0.6224256292906178\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59       138\n",
      "           1       0.64      0.68      0.66       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.62      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6564625850340136 and f1 score is: 0.6539604479612171\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.62       138\n",
      "           1       0.67      0.70      0.68       156\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[02:48:40] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7142857142857143 and f1 score is: 0.7088971662973266\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.62      0.67       138\n",
      "           1       0.70      0.80      0.75       156\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7006802721088435 and f1 score is: 0.6986722571628232\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67       138\n",
      "           1       0.71      0.74      0.72       156\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "----- Running Modality Combination EDA_EEG_GAZE\n",
      "Saved Directory: 2022_08_12_02_49\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7627118644067796 and f1 score is: 0.7580380577427821\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72       131\n",
      "           1       0.77      0.81      0.79       164\n",
      "\n",
      "    accuracy                           0.76       295\n",
      "   macro avg       0.76      0.76      0.76       295\n",
      "weighted avg       0.76      0.76      0.76       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6610169491525424 and f1 score is: 0.6555991407490427\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61       131\n",
      "           1       0.69      0.71      0.70       164\n",
      "\n",
      "    accuracy                           0.66       295\n",
      "   macro avg       0.66      0.66      0.66       295\n",
      "weighted avg       0.66      0.66      0.66       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7559322033898305 and f1 score is: 0.7528393222863526\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       131\n",
      "           1       0.78      0.78      0.78       164\n",
      "\n",
      "    accuracy                           0.76       295\n",
      "   macro avg       0.75      0.75      0.75       295\n",
      "weighted avg       0.76      0.76      0.76       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6711864406779661 and f1 score is: 0.6515677321156773\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.49      0.57       131\n",
      "           1       0.67      0.82      0.73       164\n",
      "\n",
      "    accuracy                           0.67       295\n",
      "   macro avg       0.67      0.65      0.65       295\n",
      "weighted avg       0.67      0.67      0.66       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6915254237288135 and f1 score is: 0.6873726257438657\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       131\n",
      "           1       0.72      0.73      0.72       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.69      0.69      0.69       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7288135593220338 and f1 score is: 0.7249417249417249\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69       131\n",
      "           1       0.75      0.76      0.76       164\n",
      "\n",
      "    accuracy                           0.73       295\n",
      "   macro avg       0.73      0.72      0.72       295\n",
      "weighted avg       0.73      0.73      0.73       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[02:50:52] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7186440677966102 and f1 score is: 0.714390696263808\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68       131\n",
      "           1       0.74      0.76      0.75       164\n",
      "\n",
      "    accuracy                           0.72       295\n",
      "   macro avg       0.72      0.71      0.71       295\n",
      "weighted avg       0.72      0.72      0.72       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7627118644067796 and f1 score is: 0.7612606363300036\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       131\n",
      "           1       0.81      0.76      0.78       164\n",
      "\n",
      "    accuracy                           0.76       295\n",
      "   macro avg       0.76      0.76      0.76       295\n",
      "weighted avg       0.77      0.76      0.76       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7244897959183674 and f1 score is: 0.7209743751977222\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69       141\n",
      "           1       0.71      0.80      0.75       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6564625850340136 and f1 score is: 0.6530872130381447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62       141\n",
      "           1       0.65      0.73      0.69       153\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7108843537414966 and f1 score is: 0.7084252161433722\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68       141\n",
      "           1       0.70      0.77      0.74       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6904761904761905 and f1 score is: 0.6816326530612244\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.55      0.63       141\n",
      "           1       0.66      0.82      0.73       153\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.70      0.68      0.68       294\n",
      "weighted avg       0.70      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6768707482993197 and f1 score is: 0.6741223003955337\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.64       141\n",
      "           1       0.67      0.74      0.70       153\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.717687074829932 and f1 score is: 0.7162393162393161\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.70       141\n",
      "           1       0.72      0.76      0.74       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[02:53:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7312925170068028 and f1 score is: 0.729637864201986\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71       141\n",
      "           1       0.73      0.78      0.75       153\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7210884353741497 and f1 score is: 0.7207653817642699\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71       141\n",
      "           1       0.74      0.73      0.73       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7414965986394558 and f1 score is: 0.7294653235180163\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67       128\n",
      "           1       0.74      0.84      0.79       166\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.717687074829932 and f1 score is: 0.7066608965343144\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65       128\n",
      "           1       0.72      0.81      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.70      0.71       294\n",
      "weighted avg       0.72      0.72      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7278911564625851 and f1 score is: 0.7197865040030499\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.64      0.67       128\n",
      "           1       0.74      0.80      0.77       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6938775510204082 and f1 score is: 0.6854942233632864\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63       128\n",
      "           1       0.72      0.76      0.74       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7517006802721088 and f1 score is: 0.7433603979575975\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70       128\n",
      "           1       0.76      0.83      0.79       166\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7312925170068028 and f1 score is: 0.7264794205970675\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       128\n",
      "           1       0.76      0.77      0.76       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[02:55:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7278911564625851 and f1 score is: 0.7176470588235295\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.66       128\n",
      "           1       0.73      0.81      0.77       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7006802721088435 and f1 score is: 0.6938224852071005\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65       128\n",
      "           1       0.73      0.75      0.74       166\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7346938775510204 and f1 score is: 0.7214962351226621\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.60      0.66       126\n",
      "           1       0.74      0.83      0.78       168\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6700680272108843 and f1 score is: 0.6562232535712134\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.59       126\n",
      "           1       0.69      0.76      0.73       168\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.65      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7142857142857143 and f1 score is: 0.703529411764706\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.61      0.65       126\n",
      "           1       0.73      0.79      0.76       168\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6768707482993197 and f1 score is: 0.6668455895509036\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       126\n",
      "           1       0.71      0.74      0.72       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6836734693877551 and f1 score is: 0.6684491978609625\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60       126\n",
      "           1       0.70      0.79      0.74       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6938775510204082 and f1 score is: 0.6906565656565657\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.69      0.66       126\n",
      "           1       0.75      0.70      0.72       168\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.69      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[02:57:30] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7108843537414966 and f1 score is: 0.6987523356036405\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64       126\n",
      "           1       0.72      0.80      0.76       168\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.717687074829932 and f1 score is: 0.708928251923421\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.66       126\n",
      "           1       0.74      0.78      0.76       168\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7278911564625851 and f1 score is: 0.7266260635082988\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       137\n",
      "           1       0.75      0.75      0.75       157\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6598639455782312 and f1 score is: 0.6571828358208955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.63       137\n",
      "           1       0.67      0.70      0.69       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6802721088435374 and f1 score is: 0.6773455377574371\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65       137\n",
      "           1       0.69      0.73      0.71       157\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6224489795918368 and f1 score is: 0.6205128205128205\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.59       137\n",
      "           1       0.65      0.65      0.65       157\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.62      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6700680272108843 and f1 score is: 0.6686842869590472\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.65       137\n",
      "           1       0.69      0.69      0.69       157\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7108843537414966 and f1 score is: 0.7104790592596884\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70       137\n",
      "           1       0.74      0.70      0.72       157\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[02:59:42] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6564625850340136 and f1 score is: 0.6543471428405135\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.63       137\n",
      "           1       0.68      0.69      0.68       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7006802721088435 and f1 score is: 0.6995540691192865\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68       137\n",
      "           1       0.72      0.71      0.72       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7210884353741497 and f1 score is: 0.7127811666031263\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66       128\n",
      "           1       0.74      0.79      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6836734693877551 and f1 score is: 0.6738593666129897\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62       128\n",
      "           1       0.70      0.76      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7108843537414966 and f1 score is: 0.7039485375128833\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66       128\n",
      "           1       0.73      0.77      0.75       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6904761904761905 and f1 score is: 0.6891780424048795\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.72      0.67       128\n",
      "           1       0.76      0.67      0.71       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6530612244897959 and f1 score is: 0.640948275862069\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58       128\n",
      "           1       0.68      0.74      0.71       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7108843537414966 and f1 score is: 0.7087785948188461\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.72      0.68       128\n",
      "           1       0.76      0.70      0.73       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[03:01:55] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6904761904761905 and f1 score is: 0.6808731436750761\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.59      0.63       128\n",
      "           1       0.71      0.77      0.74       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7619047619047619 and f1 score is: 0.7578595632530121\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       128\n",
      "           1       0.79      0.79      0.79       166\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.76      0.76      0.76       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7721088435374149 and f1 score is: 0.7513224173410258\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68       111\n",
      "           1       0.80      0.85      0.82       183\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.76      0.75      0.75       294\n",
      "weighted avg       0.77      0.77      0.77       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7312925170068028 and f1 score is: 0.7222667320363041\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67       111\n",
      "           1       0.82      0.73      0.77       183\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.72      0.73      0.72       294\n",
      "weighted avg       0.74      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7380952380952381 and f1 score is: 0.7208872230510314\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65       111\n",
      "           1       0.79      0.79      0.79       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7006802721088435 and f1 score is: 0.6970917435489158\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.78      0.66       111\n",
      "           1       0.83      0.65      0.73       183\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.72      0.70       294\n",
      "weighted avg       0.74      0.70      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7482993197278912 and f1 score is: 0.7373605678690425\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.72      0.68       111\n",
      "           1       0.82      0.77      0.79       183\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.73      0.74      0.74       294\n",
      "weighted avg       0.76      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7687074829931972 and f1 score is: 0.7606321839080459\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.72       111\n",
      "           1       0.85      0.77      0.80       183\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.76      0.77      0.76       294\n",
      "weighted avg       0.78      0.77      0.77       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[03:04:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7312925170068028 and f1 score is: 0.7125886327356424\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64       111\n",
      "           1       0.78      0.79      0.79       183\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7210884353741497 and f1 score is: 0.7097939137134052\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       111\n",
      "           1       0.80      0.74      0.77       183\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.72      0.71       294\n",
      "weighted avg       0.73      0.72      0.72       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7585034013605442 and f1 score is: 0.751603498542274\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       127\n",
      "           1       0.77      0.81      0.79       167\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.76      0.75      0.75       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6768707482993197 and f1 score is: 0.6623345221543856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.54      0.59       127\n",
      "           1       0.69      0.78      0.73       167\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.67      0.68      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7108843537414966 and f1 score is: 0.7019144748613348\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       127\n",
      "           1       0.73      0.78      0.75       167\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6632653061224489 and f1 score is: 0.6398262612763115\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.47      0.55       127\n",
      "           1       0.67      0.81      0.73       167\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.64      0.64       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6972789115646258 and f1 score is: 0.6817214241403218\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61       127\n",
      "           1       0.70      0.81      0.75       167\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.70      0.70      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7006802721088435 and f1 score is: 0.6970917435489158\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66       127\n",
      "           1       0.75      0.71      0.73       167\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[03:06:19] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7517006802721088 and f1 score is: 0.7433603979575975\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70       127\n",
      "           1       0.76      0.82      0.79       167\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7414965986394558 and f1 score is: 0.7344173441734418\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       127\n",
      "           1       0.76      0.80      0.78       167\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7380952380952381 and f1 score is: 0.7312263288494188\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69       131\n",
      "           1       0.74      0.81      0.77       163\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6564625850340136 and f1 score is: 0.6482212033976615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59       131\n",
      "           1       0.68      0.73      0.70       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.717687074829932 and f1 score is: 0.7145130155016087\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68       131\n",
      "           1       0.75      0.74      0.74       163\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6020408163265306 and f1 score is: 0.6019993751952515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.69      0.61       131\n",
      "           1       0.68      0.53      0.60       163\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.61      0.61      0.60       294\n",
      "weighted avg       0.62      0.60      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6530612244897959 and f1 score is: 0.6427277926038886\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.54      0.58       131\n",
      "           1       0.67      0.74      0.70       163\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6938775510204082 and f1 score is: 0.6906565656565657\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66       131\n",
      "           1       0.73      0.72      0.72       163\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[03:08:31] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7312925170068028 and f1 score is: 0.7248462878060916\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68       131\n",
      "           1       0.74      0.80      0.77       163\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7517006802721088 and f1 score is: 0.7485324615979473\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72       131\n",
      "           1       0.77      0.78      0.78       163\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7278911564625851 and f1 score is: 0.7227592059974538\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.69       138\n",
      "           1       0.71      0.81      0.76       156\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6428571428571429 and f1 score is: 0.6388417665984206\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.60       138\n",
      "           1       0.65      0.71      0.68       156\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6938775510204082 and f1 score is: 0.6886765813253013\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.60      0.65       138\n",
      "           1       0.69      0.78      0.73       156\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6564625850340136 and f1 score is: 0.6474527170622247\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.53      0.59       138\n",
      "           1       0.65      0.77      0.70       156\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6258503401360545 and f1 score is: 0.6224256292906178\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59       138\n",
      "           1       0.64      0.68      0.66       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.62      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6564625850340136 and f1 score is: 0.6539604479612171\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.62       138\n",
      "           1       0.67      0.70      0.68       156\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[03:10:46] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7142857142857143 and f1 score is: 0.7088971662973266\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.62      0.67       138\n",
      "           1       0.70      0.80      0.75       156\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7006802721088435 and f1 score is: 0.6986722571628232\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67       138\n",
      "           1       0.71      0.74      0.72       156\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, mods in cols_run_ALL.items():\n",
    "    print(f\"----- Running Modality Combination {name}\")\n",
    "    kfoldValidation1('MatbII', 'ECG_EDA_Features_Combined_scld', 'ECG_EDA_Base2_Features_Combined', mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Running Modality Combination ECG_EDA_EEG_GAZE\n",
      "Saved Directory: 2022_08_12_10_39\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7796610169491526 and f1 score is: 0.7751023328368187\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74       131\n",
      "           1       0.79      0.83      0.81       164\n",
      "\n",
      "    accuracy                           0.78       295\n",
      "   macro avg       0.78      0.77      0.78       295\n",
      "weighted avg       0.78      0.78      0.78       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6847457627118644 and f1 score is: 0.6775728942636534\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63       131\n",
      "           1       0.70      0.75      0.73       164\n",
      "\n",
      "    accuracy                           0.68       295\n",
      "   macro avg       0.68      0.68      0.68       295\n",
      "weighted avg       0.68      0.68      0.68       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7457627118644068 and f1 score is: 0.7410008779631255\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71       131\n",
      "           1       0.76      0.79      0.78       164\n",
      "\n",
      "    accuracy                           0.75       295\n",
      "   macro avg       0.74      0.74      0.74       295\n",
      "weighted avg       0.74      0.75      0.74       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.5966101694915255 and f1 score is: 0.5531497816982981\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.32      0.41       131\n",
      "           1       0.60      0.82      0.69       164\n",
      "\n",
      "    accuracy                           0.60       295\n",
      "   macro avg       0.59      0.57      0.55       295\n",
      "weighted avg       0.59      0.60      0.57       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6745762711864407 and f1 score is: 0.6653431650595576\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61       131\n",
      "           1       0.69      0.76      0.72       164\n",
      "\n",
      "    accuracy                           0.67       295\n",
      "   macro avg       0.67      0.66      0.67       295\n",
      "weighted avg       0.67      0.67      0.67       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.711864406779661 and f1 score is: 0.7059030506327628\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66       131\n",
      "           1       0.73      0.77      0.75       164\n",
      "\n",
      "    accuracy                           0.71       295\n",
      "   macro avg       0.71      0.70      0.71       295\n",
      "weighted avg       0.71      0.71      0.71       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[10:40:48] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7694915254237288 and f1 score is: 0.7644876491030337\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73       131\n",
      "           1       0.78      0.82      0.80       164\n",
      "\n",
      "    accuracy                           0.77       295\n",
      "   macro avg       0.77      0.76      0.76       295\n",
      "weighted avg       0.77      0.77      0.77       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.752542372881356 and f1 score is: 0.7488014557500963\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72       131\n",
      "           1       0.77      0.79      0.78       164\n",
      "\n",
      "    accuracy                           0.75       295\n",
      "   macro avg       0.75      0.75      0.75       295\n",
      "weighted avg       0.75      0.75      0.75       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7142857142857143 and f1 score is: 0.7099365750528541\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.62      0.67       141\n",
      "           1       0.69      0.80      0.75       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6972789115646258 and f1 score is: 0.6943045738652959\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66       141\n",
      "           1       0.69      0.76      0.72       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7074829931972789 and f1 score is: 0.70517723880597\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68       141\n",
      "           1       0.70      0.76      0.73       153\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6632653061224489 and f1 score is: 0.6519545122986594\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59       141\n",
      "           1       0.64      0.81      0.71       153\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.67      0.66      0.65       294\n",
      "weighted avg       0.67      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6972789115646258 and f1 score is: 0.6947040498442367\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67       141\n",
      "           1       0.69      0.76      0.72       153\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7346938775510204 and f1 score is: 0.7344972907886815\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       141\n",
      "           1       0.75      0.73      0.74       153\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.74      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[10:43:21] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7244897959183674 and f1 score is: 0.7221463824425076\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70       141\n",
      "           1       0.71      0.78      0.75       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7244897959183674 and f1 score is: 0.7230769230769231\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.70       141\n",
      "           1       0.72      0.76      0.74       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7380952380952381 and f1 score is: 0.727105056958592\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.62      0.67       128\n",
      "           1       0.74      0.83      0.78       166\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.72      0.73       294\n",
      "weighted avg       0.74      0.74      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7074829931972789 and f1 score is: 0.6964705882352941\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.64       128\n",
      "           1       0.72      0.80      0.75       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.69      0.70       294\n",
      "weighted avg       0.71      0.71      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7448979591836735 and f1 score is: 0.7349345450611273\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68       128\n",
      "           1       0.75      0.83      0.79       166\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6190476190476191 and f1 score is: 0.6024916702882805\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.48      0.52       128\n",
      "           1       0.64      0.73      0.68       166\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.60      0.60       294\n",
      "weighted avg       0.61      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7210884353741497 and f1 score is: 0.7113505747126437\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66       128\n",
      "           1       0.73      0.80      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7244897959183674 and f1 score is: 0.7172640602182199\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67       128\n",
      "           1       0.74      0.78      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[10:45:54] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7346938775510204 and f1 score is: 0.7231638418079096\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.61      0.67       128\n",
      "           1       0.73      0.83      0.78       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7517006802721088 and f1 score is: 0.7439971372338521\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70       128\n",
      "           1       0.76      0.82      0.79       166\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7517006802721088 and f1 score is: 0.7433603979575975\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       126\n",
      "           1       0.77      0.82      0.79       168\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7006802721088435 and f1 score is: 0.6910141881240148\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.64       126\n",
      "           1       0.72      0.77      0.75       168\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7585034013605442 and f1 score is: 0.751603498542274\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71       126\n",
      "           1       0.78      0.81      0.79       168\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6190476190476191 and f1 score is: 0.5796568627450981\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.37      0.45       126\n",
      "           1       0.63      0.81      0.71       168\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.59      0.58       294\n",
      "weighted avg       0.61      0.62      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6972789115646258 and f1 score is: 0.6854556601392044\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.62       126\n",
      "           1       0.72      0.78      0.75       168\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.69      0.68      0.69       294\n",
      "weighted avg       0.69      0.70      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7244897959183674 and f1 score is: 0.7184673767836667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.68       126\n",
      "           1       0.76      0.76      0.76       168\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[10:48:27] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7551020408163265 and f1 score is: 0.7458823529411764\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70       126\n",
      "           1       0.76      0.83      0.79       168\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.75      0.74      0.75       294\n",
      "weighted avg       0.75      0.76      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7619047619047619 and f1 score is: 0.7564497041420118\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72       126\n",
      "           1       0.79      0.80      0.79       168\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.76      0.76      0.76       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7346938775510204 and f1 score is: 0.7329140461215933\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71       137\n",
      "           1       0.75      0.76      0.75       157\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6632653061224489 and f1 score is: 0.6615384615384614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       137\n",
      "           1       0.68      0.69      0.69       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7074829931972789 and f1 score is: 0.7068181818181818\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.71      0.69       137\n",
      "           1       0.74      0.71      0.72       157\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6292517006802721 and f1 score is: 0.6273504273504273\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       137\n",
      "           1       0.65      0.66      0.65       157\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6598639455782312 and f1 score is: 0.6582825793853735\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       137\n",
      "           1       0.68      0.68      0.68       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7244897959183674 and f1 score is: 0.7241035741180559\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71       137\n",
      "           1       0.76      0.71      0.73       157\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.73      0.72       294\n",
      "weighted avg       0.73      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[10:51:01] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6870748299319728 and f1 score is: 0.6858974358974359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.67       137\n",
      "           1       0.71      0.70      0.71       157\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.717687074829932 and f1 score is: 0.7174222685426437\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       137\n",
      "           1       0.75      0.70      0.73       157\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7448979591836735 and f1 score is: 0.7398383576190195\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.70       128\n",
      "           1       0.77      0.78      0.78       166\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6870748299319728 and f1 score is: 0.6769693784932882\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.59      0.62       128\n",
      "           1       0.71      0.77      0.73       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7142857142857143 and f1 score is: 0.7088971662973267\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.67       128\n",
      "           1       0.74      0.75      0.75       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6462585034013606 and f1 score is: 0.6319337442218798\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.52      0.56       128\n",
      "           1       0.67      0.75      0.70       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6700680272108843 and f1 score is: 0.658985734272424\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60       128\n",
      "           1       0.69      0.75      0.72       166\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7074829931972789 and f1 score is: 0.7035178236397748\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.68      0.67       128\n",
      "           1       0.75      0.73      0.74       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[10:53:34] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7346938775510204 and f1 score is: 0.7291666666666667\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69       128\n",
      "           1       0.76      0.78      0.77       166\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7380952380952381 and f1 score is: 0.7358675487416431\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       128\n",
      "           1       0.79      0.73      0.76       166\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7857142857142857 and f1 score is: 0.7681126760563379\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.70       111\n",
      "           1       0.81      0.85      0.83       183\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.77      0.76      0.77       294\n",
      "weighted avg       0.78      0.79      0.78       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7278911564625851 and f1 score is: 0.7152266563347539\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.66       111\n",
      "           1       0.80      0.75      0.78       183\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.71      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7653061224489796 and f1 score is: 0.7507709318754223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       111\n",
      "           1       0.81      0.81      0.81       183\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.77      0.77      0.77       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.5850340136054422 and f1 score is: 0.5800590081019061\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.63      0.53       111\n",
      "           1       0.71      0.56      0.63       183\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.59      0.59      0.58       294\n",
      "weighted avg       0.62      0.59      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7346938775510204 and f1 score is: 0.7223459899263851\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66       111\n",
      "           1       0.80      0.76      0.78       183\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.72      0.73      0.72       294\n",
      "weighted avg       0.74      0.73      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7721088435374149 and f1 score is: 0.7603970271618152\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71       111\n",
      "           1       0.83      0.80      0.81       183\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.76      0.76      0.76       294\n",
      "weighted avg       0.78      0.77      0.77       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[10:56:06] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7585034013605442 and f1 score is: 0.7444260789715335\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68       111\n",
      "           1       0.81      0.80      0.80       183\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.74      0.75      0.74       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7482993197278912 and f1 score is: 0.7349415204678363\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.69      0.68       111\n",
      "           1       0.81      0.78      0.79       183\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.73      0.74      0.73       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7789115646258503 and f1 score is: 0.7725947521865889\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.73       127\n",
      "           1       0.79      0.83      0.81       167\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.78      0.77      0.77       294\n",
      "weighted avg       0.78      0.78      0.78       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6632653061224489 and f1 score is: 0.6528180354267312\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.59       127\n",
      "           1       0.69      0.74      0.71       167\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7585034013605442 and f1 score is: 0.7532244907609917\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72       127\n",
      "           1       0.78      0.80      0.79       167\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6564625850340136 and f1 score is: 0.6509339696944761\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.61       127\n",
      "           1       0.70      0.69      0.69       167\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6938775510204082 and f1 score is: 0.6831896551724137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.59      0.62       127\n",
      "           1       0.71      0.77      0.74       167\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.68      0.68       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7006802721088435 and f1 score is: 0.6961240310077519\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       127\n",
      "           1       0.74      0.72      0.73       167\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[10:58:38] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7619047619047619 and f1 score is: 0.7535919540229885\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71       127\n",
      "           1       0.77      0.83      0.80       167\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.76      0.75      0.75       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7448979591836735 and f1 score is: 0.7387781213348971\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       127\n",
      "           1       0.77      0.79      0.78       167\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7380952380952381 and f1 score is: 0.7334039922275216\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70       131\n",
      "           1       0.75      0.79      0.77       163\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6632653061224489 and f1 score is: 0.6551871201620642\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60       131\n",
      "           1       0.68      0.74      0.71       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7210884353741497 and f1 score is: 0.7181537598204264\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.69       131\n",
      "           1       0.75      0.74      0.75       163\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6326530612244898 and f1 score is: 0.610576923076923\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.44      0.52       131\n",
      "           1       0.64      0.79      0.70       163\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.61      0.61       294\n",
      "weighted avg       0.63      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6564625850340136 and f1 score is: 0.6496489882602796\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60       131\n",
      "           1       0.68      0.72      0.70       163\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.65      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7278911564625851 and f1 score is: 0.7246288577717417\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       131\n",
      "           1       0.75      0.75      0.75       163\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[11:01:11] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7482993197278912 and f1 score is: 0.7430555555555556\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71       131\n",
      "           1       0.76      0.80      0.78       163\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7551020408163265 and f1 score is: 0.7534591194968554\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73       131\n",
      "           1       0.79      0.75      0.77       163\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.75      0.76      0.75       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7482993197278912 and f1 score is: 0.7444679351656096\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.71       138\n",
      "           1       0.74      0.82      0.78       156\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6292517006802721 and f1 score is: 0.6256089724867107\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59       138\n",
      "           1       0.64      0.69      0.66       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7142857142857143 and f1 score is: 0.7108603006603288\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.64      0.68       138\n",
      "           1       0.71      0.78      0.74       156\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.5884353741496599 and f1 score is: 0.5776413739062296\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.46      0.51       138\n",
      "           1       0.59      0.71      0.65       156\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.59      0.58      0.58       294\n",
      "weighted avg       0.59      0.59      0.58       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6326530612244898 and f1 score is: 0.6301886792452831\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.59      0.60       138\n",
      "           1       0.65      0.67      0.66       156\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6768707482993197 and f1 score is: 0.674517253032828\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65       138\n",
      "           1       0.69      0.72      0.70       156\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[11:03:41] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7517006802721088 and f1 score is: 0.7481311098332375\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72       138\n",
      "           1       0.74      0.82      0.78       156\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7312925170068028 and f1 score is: 0.7301655532965436\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71       138\n",
      "           1       0.75      0.75      0.75       156\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "----- Running Modality Combination ECG_EDA\n",
      "Saved Directory: 2022_08_12_11_04\n",
      "1\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7491525423728813 and f1 score is: 0.7446903068862276\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71       131\n",
      "           1       0.76      0.79      0.78       164\n",
      "\n",
      "    accuracy                           0.75       295\n",
      "   macro avg       0.75      0.74      0.74       295\n",
      "weighted avg       0.75      0.75      0.75       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6542372881355932 and f1 score is: 0.6427044742091763\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.53      0.58       131\n",
      "           1       0.67      0.75      0.71       164\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.65      0.64      0.64       295\n",
      "weighted avg       0.65      0.65      0.65       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7254237288135593 and f1 score is: 0.7179565869146964\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67       131\n",
      "           1       0.73      0.80      0.76       164\n",
      "\n",
      "    accuracy                           0.73       295\n",
      "   macro avg       0.72      0.72      0.72       295\n",
      "weighted avg       0.72      0.73      0.72       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6033898305084746 and f1 score is: 0.5874421773586258\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.46      0.51       131\n",
      "           1       0.62      0.72      0.67       164\n",
      "\n",
      "    accuracy                           0.60       295\n",
      "   macro avg       0.60      0.59      0.59       295\n",
      "weighted avg       0.60      0.60      0.60       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6542372881355932 and f1 score is: 0.6417857142857143\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.53      0.58       131\n",
      "           1       0.67      0.76      0.71       164\n",
      "\n",
      "    accuracy                           0.65       295\n",
      "   macro avg       0.65      0.64      0.64       295\n",
      "weighted avg       0.65      0.65      0.65       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.688135593220339 and f1 score is: 0.6846532812790482\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65       131\n",
      "           1       0.72      0.71      0.72       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.68      0.68      0.68       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 1 ---\n",
      "[11:05:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.7288135593220338 and f1 score is: 0.7234720659917511\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.69       131\n",
      "           1       0.74      0.78      0.76       164\n",
      "\n",
      "    accuracy                           0.73       295\n",
      "   macro avg       0.73      0.72      0.72       295\n",
      "weighted avg       0.73      0.73      0.73       295\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 1 ---\n",
      "Test Subject: 1\n",
      "----- Classification Report ------\n",
      "Test accuracy for 1 is: 0.6915254237288135 and f1 score is: 0.6863205618069431\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65       131\n",
      "           1       0.72      0.74      0.73       164\n",
      "\n",
      "    accuracy                           0.69       295\n",
      "   macro avg       0.69      0.69      0.69       295\n",
      "weighted avg       0.69      0.69      0.69       295\n",
      "\n",
      "2\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7517006802721088 and f1 score is: 0.7489090377303305\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.67      0.72       141\n",
      "           1       0.73      0.82      0.78       153\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.76      0.75      0.75       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6564625850340136 and f1 score is: 0.6482212033976615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.52      0.59       141\n",
      "           1       0.64      0.78      0.70       153\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.717687074829932 and f1 score is: 0.7159486421362635\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       141\n",
      "           1       0.71      0.76      0.74       153\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.6020408163265306 and f1 score is: 0.6019993751952515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60       141\n",
      "           1       0.62      0.59      0.61       153\n",
      "\n",
      "    accuracy                           0.60       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.60      0.60      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.673469387755102 and f1 score is: 0.6673110471969447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62       141\n",
      "           1       0.66      0.78      0.71       153\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7414965986394558 and f1 score is: 0.7414846353202518\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       141\n",
      "           1       0.77      0.72      0.74       153\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.74      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 2 ---\n",
      "[11:06:18] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7346938775510204 and f1 score is: 0.7322654462242564\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71       141\n",
      "           1       0.72      0.80      0.76       153\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.74      0.73      0.73       294\n",
      "weighted avg       0.74      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 2 ---\n",
      "Test Subject: 2\n",
      "----- Classification Report ------\n",
      "Test accuracy for 2 is: 0.7278911564625851 and f1 score is: 0.7277777777777777\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       141\n",
      "           1       0.75      0.72      0.73       153\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.73      0.73       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "3\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7244897959183674 and f1 score is: 0.7112299465240641\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.59      0.65       128\n",
      "           1       0.72      0.83      0.77       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.73      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.608843537414966 and f1 score is: 0.587416256848939\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.44      0.49       128\n",
      "           1       0.63      0.74      0.68       166\n",
      "\n",
      "    accuracy                           0.61       294\n",
      "   macro avg       0.60      0.59      0.59       294\n",
      "weighted avg       0.60      0.61      0.60       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6836734693877551 and f1 score is: 0.6722015081943629\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.57      0.61       128\n",
      "           1       0.70      0.77      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6326530612244898 and f1 score is: 0.6131578947368421\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.47      0.53       128\n",
      "           1       0.65      0.76      0.70       166\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.61      0.61       294\n",
      "weighted avg       0.63      0.63      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6224489795918368 and f1 score is: 0.6030458211188283\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.46      0.52       128\n",
      "           1       0.64      0.75      0.69       166\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.60      0.60       294\n",
      "weighted avg       0.62      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6802721088435374 and f1 score is: 0.671516188846099\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.62       128\n",
      "           1       0.70      0.75      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 3 ---\n",
      "[11:07:13] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.6904761904761905 and f1 score is: 0.6745690965929134\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.54      0.60       128\n",
      "           1       0.69      0.81      0.75       166\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.67      0.67       294\n",
      "weighted avg       0.69      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 3 ---\n",
      "Test Subject: 3\n",
      "----- Classification Report ------\n",
      "Test accuracy for 3 is: 0.7210884353741497 and f1 score is: 0.7134502923976609\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67       128\n",
      "           1       0.74      0.78      0.76       166\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "4\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7448979591836735 and f1 score is: 0.7356463775760991\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69       126\n",
      "           1       0.76      0.82      0.79       168\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6224489795918368 and f1 score is: 0.6066059912000481\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.49      0.53       126\n",
      "           1       0.65      0.72      0.69       168\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.62      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6666666666666666 and f1 score is: 0.6567384674037362\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60       126\n",
      "           1       0.70      0.73      0.72       168\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.5884353741496599 and f1 score is: 0.5766763848396501\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.49      0.51       126\n",
      "           1       0.63      0.66      0.65       168\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.58      0.58      0.58       294\n",
      "weighted avg       0.59      0.59      0.59       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6394557823129252 and f1 score is: 0.6248555469953776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.52      0.55       126\n",
      "           1       0.67      0.73      0.70       168\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.62      0.62       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.6836734693877551 and f1 score is: 0.6753772543246228\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.62       126\n",
      "           1       0.72      0.74      0.73       168\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.67      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 4 ---\n",
      "[11:08:08] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7346938775510204 and f1 score is: 0.7247058823529411\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67       126\n",
      "           1       0.75      0.81      0.78       168\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.73      0.72      0.72       294\n",
      "weighted avg       0.73      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 4 ---\n",
      "Test Subject: 4\n",
      "----- Classification Report ------\n",
      "Test accuracy for 4 is: 0.7244897959183674 and f1 score is: 0.7172640602182199\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67       126\n",
      "           1       0.75      0.77      0.76       168\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "5\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6870748299319728 and f1 score is: 0.6858974358974359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.67       137\n",
      "           1       0.71      0.70      0.71       157\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6394557823129252 and f1 score is: 0.627812544785745\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.50      0.56       137\n",
      "           1       0.63      0.76      0.69       157\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6768707482993197 and f1 score is: 0.6755155387743247\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65       137\n",
      "           1       0.70      0.69      0.70       157\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.5748299319727891 and f1 score is: 0.5700497221409769\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.50      0.52       137\n",
      "           1       0.60      0.64      0.62       157\n",
      "\n",
      "    accuracy                           0.57       294\n",
      "   macro avg       0.57      0.57      0.57       294\n",
      "weighted avg       0.57      0.57      0.57       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6394557823129252 and f1 score is: 0.627812544785745\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.50      0.56       137\n",
      "           1       0.63      0.76      0.69       157\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6870748299319728 and f1 score is: 0.6856199730345436\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       137\n",
      "           1       0.71      0.71      0.71       157\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 5 ---\n",
      "[11:09:02] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.6598639455782312 and f1 score is: 0.6567505720823799\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.62       137\n",
      "           1       0.67      0.71      0.69       157\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 5 ---\n",
      "Test Subject: 5\n",
      "----- Classification Report ------\n",
      "Test accuracy for 5 is: 0.7006802721088435 and f1 score is: 0.7003335804299481\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.72      0.69       137\n",
      "           1       0.73      0.69      0.71       157\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "6\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7108843537414966 and f1 score is: 0.7051501386348888\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66       128\n",
      "           1       0.74      0.75      0.75       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6394557823129252 and f1 score is: 0.6248555469953776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55       128\n",
      "           1       0.66      0.74      0.70       166\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.62      0.62       294\n",
      "weighted avg       0.64      0.64      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7074829931972789 and f1 score is: 0.701388888888889\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       128\n",
      "           1       0.74      0.75      0.74       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6462585034013606 and f1 score is: 0.6297946532351801\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.55       128\n",
      "           1       0.66      0.76      0.71       166\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.65      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6394557823129252 and f1 score is: 0.6248555469953776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55       128\n",
      "           1       0.66      0.74      0.70       166\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.63      0.62      0.62       294\n",
      "weighted avg       0.64      0.64      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6564625850340136 and f1 score is: 0.6520791591971599\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61       128\n",
      "           1       0.70      0.68      0.69       166\n",
      "\n",
      "    accuracy                           0.66       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.66      0.66      0.66       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 6 ---\n",
      "[11:09:57] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.6802721088435374 and f1 score is: 0.6707491422035837\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.61       128\n",
      "           1       0.70      0.75      0.73       166\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 6 ---\n",
      "Test Subject: 6\n",
      "----- Classification Report ------\n",
      "Test accuracy for 6 is: 0.7074829931972789 and f1 score is: 0.7048054919908466\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.68       128\n",
      "           1       0.76      0.71      0.73       166\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.71      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "7\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7278911564625851 and f1 score is: 0.7061322404917787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.63       111\n",
      "           1       0.77      0.80      0.79       183\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.71      0.70      0.71       294\n",
      "weighted avg       0.72      0.73      0.73       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6938775510204082 and f1 score is: 0.6666666666666666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57       111\n",
      "           1       0.74      0.79      0.76       183\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.67      0.66      0.67       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7142857142857143 and f1 score is: 0.6949604743083003\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.62       111\n",
      "           1       0.77      0.78      0.77       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.70      0.69      0.69       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6190476190476191 and f1 score is: 0.5869128863910076\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.45      0.47       111\n",
      "           1       0.68      0.72      0.70       183\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.59      0.59      0.59       294\n",
      "weighted avg       0.61      0.62      0.62       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.6870748299319728 and f1 score is: 0.6592592592592592\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.56       111\n",
      "           1       0.73      0.78      0.76       183\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.66      0.66      0.66       294\n",
      "weighted avg       0.68      0.69      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7108843537414966 and f1 score is: 0.6950467985405202\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63       111\n",
      "           1       0.78      0.75      0.76       183\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.69      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 7 ---\n",
      "[11:10:52] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7414965986394558 and f1 score is: 0.7219235364396654\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65       111\n",
      "           1       0.78      0.81      0.80       183\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 7 ---\n",
      "Test Subject: 7\n",
      "----- Classification Report ------\n",
      "Test accuracy for 7 is: 0.7482993197278912 and f1 score is: 0.7357784794753461\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68       111\n",
      "           1       0.81      0.78      0.79       183\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.73      0.74      0.74       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "8\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7210884353741497 and f1 score is: 0.7134502923976608\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67       127\n",
      "           1       0.74      0.78      0.76       167\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.71      0.71       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6326530612244898 and f1 score is: 0.6166883963494132\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.54       127\n",
      "           1       0.66      0.74      0.69       167\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6802721088435374 and f1 score is: 0.6691091954022987\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61       127\n",
      "           1       0.70      0.76      0.73       167\n",
      "\n",
      "    accuracy                           0.68       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.68      0.68      0.68       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.5884353741496599 and f1 score is: 0.5200161910544424\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.24      0.34       127\n",
      "           1       0.60      0.85      0.70       167\n",
      "\n",
      "    accuracy                           0.59       294\n",
      "   macro avg       0.58      0.55      0.52       294\n",
      "weighted avg       0.58      0.59      0.54       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.6326530612244898 and f1 score is: 0.6155559860519179\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.49      0.53       127\n",
      "           1       0.66      0.74      0.70       167\n",
      "\n",
      "    accuracy                           0.63       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.63      0.63      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7006802721088435 and f1 score is: 0.6970917435489158\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66       127\n",
      "           1       0.75      0.71      0.73       167\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 8 ---\n",
      "[11:11:47] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7108843537414966 and f1 score is: 0.7011730661150106\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.65       127\n",
      "           1       0.73      0.78      0.76       167\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.70      0.70       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 8 ---\n",
      "Test Subject: 8\n",
      "----- Classification Report ------\n",
      "Test accuracy for 8 is: 0.7244897959183674 and f1 score is: 0.7195548489666136\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68       127\n",
      "           1       0.76      0.75      0.76       167\n",
      "\n",
      "    accuracy                           0.72       294\n",
      "   macro avg       0.72      0.72      0.72       294\n",
      "weighted avg       0.72      0.72      0.72       294\n",
      "\n",
      "9\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7551020408163265 and f1 score is: 0.75\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       131\n",
      "           1       0.76      0.81      0.79       163\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.75      0.76      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6530612244897959 and f1 score is: 0.6399999999999999\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.52      0.57       131\n",
      "           1       0.66      0.76      0.71       163\n",
      "\n",
      "    accuracy                           0.65       294\n",
      "   macro avg       0.65      0.64      0.64       294\n",
      "weighted avg       0.65      0.65      0.65       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7414965986394558 and f1 score is: 0.7350094876660341\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.69       131\n",
      "           1       0.75      0.81      0.78       163\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.74      0.73      0.74       294\n",
      "weighted avg       0.74      0.74      0.74       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6156462585034014 and f1 score is: 0.606425702811245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.52      0.55       131\n",
      "           1       0.64      0.69      0.67       163\n",
      "\n",
      "    accuracy                           0.62       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.61      0.62      0.61       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6428571428571429 and f1 score is: 0.6278705322162619\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.55       131\n",
      "           1       0.65      0.76      0.70       163\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.64       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.6666666666666666 and f1 score is: 0.6659090909090909\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.69      0.65       131\n",
      "           1       0.72      0.64      0.68       163\n",
      "\n",
      "    accuracy                           0.67       294\n",
      "   macro avg       0.67      0.67      0.67       294\n",
      "weighted avg       0.67      0.67      0.67       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 9 ---\n",
      "[11:12:42] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7108843537414966 and f1 score is: 0.7067280046003451\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67       131\n",
      "           1       0.73      0.75      0.74       163\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.71      0.71      0.71       294\n",
      "weighted avg       0.71      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 9 ---\n",
      "Test Subject: 9\n",
      "----- Classification Report ------\n",
      "Test accuracy for 9 is: 0.7517006802721088 and f1 score is: 0.7501716973005692\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73       131\n",
      "           1       0.79      0.75      0.77       163\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "10\n",
      "--------------------------------------------\n",
      "---- Training classifier RandomForestClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7517006802721088 and f1 score is: 0.7498922049620678\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73       138\n",
      "           1       0.75      0.79      0.77       156\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.75      0.75      0.75       294\n",
      "weighted avg       0.75      0.75      0.75       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LinearDiscriminantAnalysis for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6360544217687075 and f1 score is: 0.6280988804426212\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.52      0.57       138\n",
      "           1       0.64      0.74      0.68       156\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier GradientBoostingClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6938775510204082 and f1 score is: 0.6918238993710691\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.67       138\n",
      "           1       0.70      0.73      0.72       156\n",
      "\n",
      "    accuracy                           0.69       294\n",
      "   macro avg       0.69      0.69      0.69       294\n",
      "weighted avg       0.69      0.69      0.69       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier MLPClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.5238095238095238 and f1 score is: 0.5230148797107496\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50       138\n",
      "           1       0.55      0.53      0.54       156\n",
      "\n",
      "    accuracy                           0.52       294\n",
      "   macro avg       0.52      0.52      0.52       294\n",
      "weighted avg       0.53      0.52      0.52       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LogisticRegression for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.6360544217687075 and f1 score is: 0.6273234531044531\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.51      0.57       138\n",
      "           1       0.63      0.74      0.68       156\n",
      "\n",
      "    accuracy                           0.64       294\n",
      "   macro avg       0.64      0.63      0.63       294\n",
      "weighted avg       0.64      0.64      0.63       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier SVC for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7142857142857143 and f1 score is: 0.7141666666666666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       138\n",
      "           1       0.75      0.69      0.72       156\n",
      "\n",
      "    accuracy                           0.71       294\n",
      "   macro avg       0.72      0.72      0.71       294\n",
      "weighted avg       0.72      0.71      0.71       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier XGBClassifier for fold: 10 ---\n",
      "[11:13:38] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7040816326530612 and f1 score is: 0.7030889061720083\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.69       138\n",
      "           1       0.72      0.72      0.72       156\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.70      0.70      0.70       294\n",
      "\n",
      "--------------------------------------------\n",
      "---- Training classifier LGBMClassifier for fold: 10 ---\n",
      "Test Subject: 10\n",
      "----- Classification Report ------\n",
      "Test accuracy for 10 is: 0.7006802721088435 and f1 score is: 0.700624855357556\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.76      0.70       138\n",
      "           1       0.75      0.65      0.70       156\n",
      "\n",
      "    accuracy                           0.70       294\n",
      "   macro avg       0.70      0.70      0.70       294\n",
      "weighted avg       0.71      0.70      0.70       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols_run_two = {\"ECG_EDA_EEG_GAZE\": config2.SELECTFOUR, \"ECG_EDA\": config2.SELECTECGEDA}\n",
    "\n",
    "for name, mods in cols_run_two.items():\n",
    "    print(f\"----- Running Modality Combination {name}\")\n",
    "    kfoldValidation1('MatbII', 'ECG_EDA_Features_Combined_scld', 'ECG_EDA_Base2_Features_Combined', mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('cogl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53c5d10f2d357fa99b102bf19ea4315b5e88b2494122f39f87103d7730d67975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
